\documentclass{treatise}

\title{The Catalogue}
\date{}

\begin{document}

\maketitle
\tableofcontents

\chapter{Mathematical Logic I}
\section{Propositional Logic}
\begin{shaded}
List of preliminary references:
\begin{enumerate}
    \item \href{https://www3.cs.stonybrook.edu/~cse541/chapter9new.pdf}{Two Proofs of Completeness Theorem}
    \item \href{https://www3.cs.stonybrook.edu/~cse541/chapter8.pdf}{Hilbert Proof Systems, Formal Proofs,Deduction Theorem}
\end{enumerate}
\hrulefill
\end{shaded}
\subsection{Language}
The symbols $\Sigma$ of propositional logic are divided into 3 type
\begin{enumerate}
    \item The collection of countably many letters $\Sigma_A$: say $p_1, p_2, p_3$ and so on.
    \item The collection of parentheses $\Sigma_O$: for example, ``('' and ``)'', or ``['' and ``]''.
    \item The collection of connectives $\Sigma_C$, which consists of $\neg$ and $\to$.
\end{enumerate}
\begin{definition}
The language $L$ of propositional logic, consisting of \emph{well-formed formulas} (or wffs), is recursively constructed as follows
\begin{enumerate}
    \item The letters in $\Sigma_A$ are wffs. Specifically, these are said to be \emph{atomic}.
    \item Given a wff $\alpha$, then $\neg \left( \alpha \right)$ is a wff.
    \item Given 2 wffs $\alpha$ and $\beta$, then $\left( \alpha \right) \to \left( \beta \right)$ is a wff.
\end{enumerate}
The wffs that are not atomic is then called \emph{compound} formula.
\end{definition}
\underline{Note:} parentheses can sometimes be removed for clarity (especially if the formula inside is atomic), given that we usually evaluate negation ($\neg$) first, then implication ($\to$) from left to right.

\subsection{Hilbert system}
The Hilbert system is a deductive system (over the language of propositional logic) such that
\begin{enumerate}
    \item The followings are \emph{axioms} for given wffs $\alpha, \beta, \gamma$
    \begin{enumerate}
        \item[(IP1)] \label{HPL-A-IP1} $\alpha \to (\beta \to \alpha)$
        \item[(IP2)] \label{HPL-A-IP2} $[\alpha \to (\beta \to \gamma)] \to [(\alpha \to \beta) \to (\alpha \to \gamma)]$
        \item[(PNC)] \label{HPL-A-PNC} $(\neg \alpha \to \neg \beta) \to [(\neg \alpha \to \beta) \to \alpha]$
    \end{enumerate}
    \item \label{HPL-R-MP} The following is an \emph{inference rule} for given wffs $\alpha$ and $\beta$
    \begin{align*}
        \alpha, \alpha \to \beta \vdash \beta
    \end{align*}
    That is, from $\alpha$ and $\alpha \to \beta$, deduce $\beta$. The schema of these rules is termed \emph{modus ponens}.
\end{enumerate}

\subsection{Proof}
Let $\Gamma$ be a collection of wffs, called \emph{hypothesis}. A \emph{proof} (or \emph{derivation}) of a wff $\varphi$ from $\Gamma$ is a finite sequence of wffs, or \emph{steps}, $(\lambda_1, \lambda_2, \hdots, \lambda_n)$ (with $\lambda_n = \varphi$) , where each is either an axiom, belongs to $\Gamma$, or a result of \hyperref[HPL-R-MP]{MP} from previous steps (i.e. $\lambda_i, \lambda_j \vdash_{MP} \lambda_k$ for some $i, j < k$).
\\
\\
If there is such proof, we say $\Gamma$ \emph{syntactically entails} $\varphi$, and denote $\Gamma \vdash \varphi$. If $\Gamma$ is empty, then we called $\varphi$ a \emph{theorem} (of propositional logic), and denote $\vdash \varphi$.
\begin{remark} \label{logic-proof-props} \ 
\begin{enumerate}
    \item If $(\lambda_1, \lambda_2, \hdots, \lambda_n)$ is a proof of $\varphi$ from $\Gamma$, then $(\lambda_1, \lambda_2, \hdots, \lambda_{i - 1})$ is a proof of $\lambda_i$ (albeit there can be shorter one).
    \item If $\Delta$ contains every wff in $\Gamma$ (i.e. $\Delta \supseteq \Gamma$), then any proof of $\varphi$ from $\Gamma$ is also a proof of $\Delta$. In other words, $\Delta \vdash \varphi$ whenever $\Gamma \vdash \varphi$.
	\\
	\\
	Thus, in particular, any theorem of propositional logic is syntactically entailed by arbitrary collection of hypothesis $\Gamma$.
    \item Suppose $(\lambda_1, \lambda_2, \hdots, \lambda_n = \varphi)$ is a sequence of steps where each is either provable from $\Gamma$, or an application of \hyperref[HPL-R-MP]{MP} to some previous steps, then we can concatenate the proofs of $\lambda_i$ into a proof of $\varphi$! This allows us to use theorems to prove other theorems, rather than starting from scratch (i.e. axioms).
\end{enumerate}
\end{remark}
\begin{lemma}[Reflexivity] \label{HPL-T-RX}
For each $\varphi$, we have $\varphi \to \varphi$.
\end{lemma}
\begin{proof} \ 
\begin{enumerate}
    \item Substitute $\alpha, \gamma := \varphi$ into \hyperref[HPL-A-IP2]{IP2}
    \begin{align*}
        [\varphi \to (\beta \to \varphi)] \to [(\varphi \to \beta) \to (\varphi \to \varphi)]
    \end{align*}
    \item Apply \hyperref[HPL-R-MP]{MP} to \hyperref[HPL-A-IP1]{IP1} and step (1),
    \begin{align*}
        (\varphi \to \beta) \to (\varphi \to \varphi)
    \end{align*}
    \item Substitute $\beta := \theta \to \varphi$ (say for an atomic formula $\theta := p$) into step (2)
    \begin{align*}
        [\varphi \to (\theta \to \varphi)] \to (\varphi \to \varphi)
    \end{align*}
    \item Apply \hyperref[HPL-R-MP]{MP} to \hyperref[HPL-A-IP1]{IP1} and step (3), we finally get $\varphi \to \varphi$.
\end{enumerate}
\end{proof}
\begin{theorem}[Deduction Metatheorem] \label{logic-deduct-metathm}
$\Gamma, \varphi \vdash \psi$ if and only if $\Gamma \vdash \varphi \to \psi$. In fact, we can construct a proof of $\varphi \to \psi$ from $\Gamma$ based on a proof of $\psi$ from $\Gamma$ and $\varphi$.
\end{theorem}
\begin{proof}
If $\Gamma \vdash \varphi \to \psi$, then by \hyperref[HPL-R-MP]{MP}, we get $\Gamma, \varphi \vdash \psi$. More precisely, given a proof of $\varphi \to \psi$ from $\Gamma$, then add $\varphi$ and $\psi$ to it to get a proof of $\psi$ from $\Gamma$ and $\varphi$, with $\psi$ being the result of \hyperref[HPL-R-MP]{MP} applying to $\varphi \to \psi$ and $\varphi$.
\\
\\
Vice versa, suppose $(\lambda_1, \lambda_2, \hdots, \lambda_n = \psi)$ is a proof of $\psi$ from $\Gamma$ and $\varphi$. We will convert each $\lambda_i$ to $\varphi \to \lambda_i$, with some steps in between so that $\varphi \to \lambda_i$ is provable from $\Gamma$.
\\
\\
Inductively, for any given $i$, suppose we already construct $\theta_1, \theta_2, \hdots, \theta_{s_i}$ where some $\theta_t$ is of the form $\varphi \to \lambda_j$ (for $j < i$) and vice versa, then
\begin{enumerate}
    \item If $\lambda_i$ is an axiom, or belongs to $\Gamma$:
    \begin{enumerate}
        \item Set $\theta_{s_i + 1} := \lambda_i$ as first step.
        \item Next, from \hyperref[HPL-A-IP1]{IP1}, denote $\theta_{s_i + 2} := \lambda_i \to (\varphi \to \lambda_i)$ as the next step.
        \item Finally, apply \hyperref[HPL-R-MP]{MP} to previous ones to get $\theta_{s_i + 3} := \varphi \to \lambda_i$ as the resultant step.
    \end{enumerate}
    \item If $\lambda_i$ is $\varphi$: since $\varphi \to \varphi$ is a theorem, we let $\theta_{s_i + 1} := \varphi \to \lambda_i$.
    \item If $\lambda_i$ is an employment of \hyperref[HPL-R-MP]{MP} to $\lambda_j$ and $\lambda_k$ (for some $j, k < i$): without loss of generality (WLOG), $\lambda_k$ must be of the form $\lambda_j \to \lambda_i$. So we already get $\theta_{t_j} := \varphi \to \lambda_j$ and $\theta_{t_k} := \varphi \to (\lambda_j \to \lambda_i)$ from previous steps (by induction hypothesis), let the following steps be a proof of $\varphi \to \lambda_i$ based on those.
    \begin{enumerate}
        \item From \hyperref[HPL-A-IP2]{IP2}, we set $\theta_{s_i + 1} := [\varphi \to (\lambda_j \to \lambda_i)] \to [(\varphi \to \lambda_j) \to (\varphi \to \lambda_i)]$.
        \item Apply \hyperref[HPL-R-MP]{MP} to previous step $\theta_{s_i + 1}$ and $\theta_{t_k}$, we get the next step $\theta_{s_i + 2} := (\varphi \to \lambda_j) \to (\varphi \to \lambda_i)$.
        \item Apply \hyperref[HPL-R-MP]{MP} again, but this time to $\theta_{s_i + 2}$ and $\theta_{t_j}$ to get $\theta_{s_i + 3} := \varphi \to \lambda_i$.
    \end{enumerate}
\end{enumerate}
After the final step $\theta_m := \varphi \to \psi$, we get a sequence $(\theta_1, \theta_2, \hdots, \theta_m)$ where each $\theta_i$ is either
\begin{enumerate}
    \item An axiom, or belongs to $\Gamma$: this occurs in (1a), (1b), and (3a).
    \item An application of \hyperref[HPL-R-MP]{MP} to previous steps: this occurs in (1c), (3b), and (3c).
    \item $\varphi \to \varphi$: this occurs in (2).
\end{enumerate}
Since each $\theta_i$ does not depend on the hypothesis $\varphi$ but only $\Gamma$, by \hyperref[logic-proof-props]{Remark \ref*{logic-proof-props}} and \hyperref[HPL-T-RX]{Lemma \ref*{HPL-T-RX}}, such sequence can serve as a proof of $\varphi \to \psi$ from $\Gamma$ only.
\end{proof}
\begin{remark}
If there are multiple usages of deduction metatheorem, we convert the proof one at a time, the former to the latter. For example, if $\Gamma, \varphi, \psi \vdash \xi$ and we want to show that $\Gamma \vdash \varphi \to (\psi \to \xi)$, first convert the proof of $\xi$ from $\Gamma, \varphi$ and $\psi$, to a proof of $\psi \to \xi$ from $\Gamma$ and $\varphi$. Then convert such proof to a proof of $\varphi \to (\psi \to \xi)$ from $\Gamma$.
\end{remark}
\begin{proposition}[Hypothetical Syllogism - HS] \label{HPL-T-HS}
Given $\varphi, \psi, \xi$, then the followings hold
\begin{enumerate}
    \item $(\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \xi)]$
    \item $(\psi \to \xi) \to [(\varphi \to \psi) \to (\varphi \to \xi)]$
\end{enumerate}
\end{proposition}
\begin{proof}
Applying \hyperref[HPL-R-MP]{MP} repeatedly to $\varphi, \varphi \to \psi$ and $\psi \to \xi$, we get $\varphi, \varphi \to \psi, \psi \to \xi \vdash \xi$. So by \hyperref[logic-deduct-metathm]{deduction theorem}, we get
\begin{align*}
    \varphi \to \psi, \psi \to \xi & \vdash \varphi \to \xi
    \\
    \varphi \to \psi & \vdash (\psi \to \xi) \to (\varphi \to \xi)
    \\
    & \vdash (\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \xi)]
\end{align*}
Similarly, $(\psi \to \xi) \to [(\varphi \to \psi) \to (\varphi \to \xi)]$.
\\
\\
*To produce a proof of $(\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \xi)]$, first note that the following sequence is a proof for $\varphi, \varphi \to \psi, \psi \to \xi \vdash \xi$.
\begin{enumerate}
    \item From the hypothesis, $\varphi$.
    \item From the hypothesis, $\varphi \to \psi$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (1) and (2), we get $\psi$.
    \item From the hypothesis, $\psi \to \xi$.
    \item Finally, apply \hyperref[HPL-R-MP]{MP} to steps (3) and (4), we get $\xi$.
\end{enumerate}
*Hence, the following is a proof for $\varphi \to \psi, \psi \to \xi \vdash \varphi \to \xi$
\begin{enumerate}
    \item By \hyperref[HPL-T-RX]{RX}, $\varphi \to \varphi$.
    \\
    \item From the hypothesis, $\varphi \to \psi$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $(\varphi \to \psi) \to [\varphi \to (\varphi \to \psi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (2) and (3), $\varphi \to (\varphi \to \psi)$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $[\varphi \to (\varphi \to \psi)] \to [(\varphi \to \varphi) \to (\varphi \to \psi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (4) and (5), $(\varphi \to \varphi) \to (\varphi \to \psi)$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (1) and (6), $\varphi \to \psi$.
    \\
    \item From the hypothesis, $\psi \to \xi$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $(\psi \to \xi) \to [\varphi \to (\psi \to \xi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (8) and (9), $\varphi \to (\psi \to \xi)$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $[\varphi \to (\psi \to \xi)] \to [(\varphi \to \psi) \to (\varphi \to \xi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (10) and (11), $(\varphi \to \psi) \to (\varphi \to \xi)$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (7) and (12), $\varphi \to \xi$.
\end{enumerate}
Removing some redundancy (steps 1 to 7), we get another proof for $\varphi \to \psi, \psi \to \xi \vdash \varphi \to \xi$
\begin{enumerate}
    \item From the hypothesis, $\lambda_1 := \varphi \to \psi$.
    \item From the hypothesis, $\lambda_2 := \psi \to \xi$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_3 := \lambda_2 \to (\varphi \to \lambda_2)$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (2) and (3), $\lambda_4 := \varphi \to (\psi \to \xi)$.
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_4 \to [\lambda_1 \to (\varphi \to \xi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (4) and (5), $\lambda_1 \to (\varphi \to \xi)$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (1) and (6), $\varphi \to \xi$.
\end{enumerate}
*From the proof above, we get a proof for $\varphi \to \psi \vdash (\psi \to \xi) \to (\varphi \to \xi)$
\begin{enumerate}
    \item From the hypothesis, $\varphi \to \psi$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $(\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \psi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (1) and (2), $(\psi \to \xi) \to (\varphi \to \psi)$.
    \\
    \item By \hyperref[HPL-T-RX]{RX}, $(\psi \to \xi) \to (\psi \to \xi)$.
    \\
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_5 := (\psi \to \xi) \to [\varphi \to (\psi \to \xi)]$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_5 \to [(\psi \to \xi) \to \lambda_5]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (5) and (6), $\lambda_7 := (\psi \to \xi) \to \lambda_5$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_7 \to [[(\psi \to \xi) \to (\psi \to \xi)] \to \lambda_5]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (7) and (8), $[(\psi \to \xi) \to (\psi \to \xi)] \to \lambda_5$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (4) and (9), $\lambda_5 = (\psi \to \xi) \to (\varphi \to (\psi \to \xi))$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{11} := [\varphi \to (\psi \to \xi)] \to [(\varphi \to \psi) \to (\varphi \to \xi)]$.
    \item By \hyperref[HPL-A-IP2]{IP1}, $\lambda_{11} \to [(\psi \to \xi) \to \lambda_{11}]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (11) and (12), $\lambda_{13} := (\psi \to \xi) \to \lambda_{11}$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{13} \to [\lambda_5 \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (13) and (14), $[(\psi \to \xi) \to (\varphi \to (\psi \to \xi))] \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (10) and (15), $\lambda_{16} := (\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{16} \to [((\psi \to \xi) \to (\varphi \to \psi)) \to ((\psi \to \xi) \to (\varphi \to \xi))]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (16) and (17), $[(\psi \to \xi) \to (\varphi \to \psi)] \to [(\psi \to \xi) \to (\varphi \to \xi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (3) and (18), $(\psi \to \xi) \to (\varphi \to \xi)$.
\end{enumerate}
After removing some redundancy (steps 4 to 10),
\begin{enumerate}
    \item From the hypothesis, $\lambda_1 := \varphi \to \psi$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_1 \to [(\psi \to \xi) \to \lambda_1]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (1) and (2), $\lambda_3 := (\psi \to \xi) \to \lambda_1$.
    \\
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_4 := (\psi \to \xi) \to (\varphi \to (\psi \to \xi))$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_5 := [\varphi \to (\psi \to \xi)] \to [(\varphi \to \psi) \to (\varphi \to \xi)]$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_5 \to [(\psi \to \xi) \to \lambda_5]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (5) and (6), $\lambda_7 := (\psi \to \xi) \to\lambda_5$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_7 \to [\lambda_4 \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (7) and (8), $\lambda_4 \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (4) and (9), $\lambda_{10} := (\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{10} \to [\lambda_3 \to ((\psi \to \xi) \to (\varphi \to \xi))]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (10) and (11), $\lambda_3 \to [(\psi \to \xi) \to (\varphi \to \xi)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (3) and (12), $(\psi \to \xi) \to (\varphi \to \xi)$.
\end{enumerate}
*Finally, we obtain a proof for $\vdash (\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \xi)]$ (with some redundancy being removed)
\begin{enumerate}
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_1 := (\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \psi)]$.
    \\
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_2 := (\psi \to \xi) \to (\varphi \to (\psi \to \xi))$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_2 \to [(\varphi \to \psi) \to \lambda_2]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (2) and (3), $\lambda_4 := (\varphi \to \psi) \to \lambda_2$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_5 := [\varphi \to (\psi \to \xi)] \to [(\varphi \to \psi) \to (\varphi \to \xi)]$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_5 \to [(\varphi \to \psi) \to \lambda_5]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (5) and (6), $\lambda_7 := (\varphi \to \psi) \to \lambda_5$.
    \\
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_8 := \lambda_5 \to [(\psi \to \xi) \to \lambda_5]$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_8 \to [(\varphi \to \psi) \to \lambda_8]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (8) and (9), $\lambda_{10} := (\varphi \to \psi) \to \lambda_8$
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{10} \to [\lambda_7 \to [(\varphi \to \psi) \to ((\psi \to \xi) \to \lambda_5)]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (10) and (11), $\lambda_7 \to [(\varphi \to \psi) \to ((\psi \to \xi) \to \lambda_5)]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (7) and (12), $\lambda_{13} := (\varphi \to \psi) \to [(\psi \to \xi) \to \lambda_5]$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{14} := [(\psi \to \xi) \to \lambda_5] \to [\lambda_2 \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_{14} \to [(\varphi \to \psi) \to \lambda_{14}]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (14) and (15), $\lambda_{16} := (\varphi \to \psi) \to \lambda_{14}$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{16} \to [\lambda_{13} \to [(\varphi \to \psi) \to [[\lambda_2 \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]]]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (16) and (17), $\lambda_{13} \to [(\varphi \to \psi) \to [[\lambda_2 \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (13) and (18), $\lambda_{19} := (\varphi \to \psi) \to [[\lambda_2 \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]]$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{19} \to [\lambda_4 \to [(\varphi \to \psi) \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (19) and (20), $\lambda_4 \to [(\varphi \to \psi) \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (4) and (21), $\lambda_{22} := (\varphi \to \psi) \to [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))]$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{23} := [(\psi \to \xi) \to ((\varphi \to \psi) \to (\varphi \to \xi))] \to [[(\psi \to \xi) \to (\varphi \to \psi)] \to ((\psi \to \xi) \to (\varphi \to \xi))]$.
    \item By \hyperref[HPL-A-IP1]{IP1}, $\lambda_{23} \to [(\varphi \to \psi) \to \lambda_{23}]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (23) and (24), $\lambda_{25} := (\varphi \to \psi) \to \lambda_{23}$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{25} \to [\lambda_{22} \to [(\varphi \to \psi) \to [[(\psi \to \xi) \to (\varphi \to \psi)] \to ((\psi \to \xi) \to (\varphi \to \xi))]]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (25) and (26), $\lambda_{22} \to [(\varphi \to \psi) \to [[(\psi \to \xi) \to (\varphi \to \psi)] \to ((\psi \to \xi) \to (\varphi \to \xi))]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (22) and (27), $\lambda_{28} := (\varphi \to \psi) \to [[(\psi \to \xi) \to (\varphi \to \psi)] \to ((\psi \to \xi) \to (\varphi \to \xi))]$.
    \\
    \item By \hyperref[HPL-A-IP2]{IP2}, $\lambda_{28} \to [\lambda_1 \to [(\varphi \to \psi) \to ((\psi \to \xi) \to (\varphi \to \xi))]]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (28) and (29), $\lambda_1 \to [(\varphi \to \psi) \to ((\psi \to \xi) \to (\varphi \to \xi))]$.
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (1) and (30), $(\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \xi)]$.
\end{enumerate}
*Similar proof for $(\psi \to \xi) \to [(\varphi \to \psi) \to (\varphi \to \xi)]$.
\end{proof}
\begin{proposition}[Antecedent Switch - AS] \label{HPL-T-AS}
Given wff $\varphi, \psi, \xi$, then $[\varphi \to (\psi \to \xi)] \to [\psi \to (\varphi \to \xi)]$ holds.
\end{proposition}
\begin{proof}
Suppose $\varphi \to (\psi \to \xi)$ and $\psi$, we will show that $\varphi \to \xi$. Indeed,
\begin{enumerate}
    \item Substitute $\alpha := \psi$ and $\beta := \varphi$ into \hyperref[HPL-A-IP1]{IP1}
    \begin{align*}
        \psi \to (\varphi \to \psi)
    \end{align*}
    \item Apply \hyperref[HPL-R-MP]{MP} to step (1) and the hypothesis $\psi$
    \begin{align*}
        \varphi \to \psi
    \end{align*}
    \item Substitute $\alpha := \varphi$, $\beta := \psi$, and $\gamma := \xi$ into \hyperref[HPL-A-IP2]{IP2}
    \begin{align*}
        [\varphi \to (\psi \to \xi)] \to [(\varphi \to \psi) \to (\varphi \to \xi)]
    \end{align*}
    \item Apply \hyperref[HPL-R-MP]{MP} to step (3) and the hypothesis $\varphi \to (\psi \to \xi)$.
    \begin{align*}
        (\varphi \to \psi) \to (\varphi \to \xi)
    \end{align*}
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (2) and (4)
    \begin{align*}
        \varphi \to \xi
    \end{align*}
\end{enumerate}
Thus, $\varphi \to (\psi \to \xi), \psi \vdash \varphi \to \xi$. But by deduction metatheorem, we get
\begin{align*}
    \varphi \to (\psi \to \xi) & \vdash \psi \to (\varphi \to \xi)
    \\
    & \vdash [\varphi \to (\psi \to \xi)] \to [\psi \to (\varphi \to \xi)]
\end{align*}
\end{proof}
\begin{proposition} \label{logic-sufficient-completeness}
Let $\varphi, \psi, \xi$ be wffs. The followings are theorems of propositional logic
\begin{enumerate}
    \item \label{HPL-T-DN} [DN] Double negation: $\varphi \to \neg \neg \varphi$ and $\neg \neg \varphi \to \varphi$
    \item \label{HPL-T-EXP} [EXP] Principle of explosion: $\neg \varphi \to (\varphi \to \psi)$
    \item \label{HPL-T-CTP} [CTP] Contraposition: $(\neg \psi \to \neg \varphi) \to (\varphi \to \psi)$ and $(\varphi \to \psi) \to (\neg \psi \to \neg \varphi)$.
    \item \label{HPL-T-MI} [MI] Material implication: $\varphi \to [\neg \psi \to \neg(\varphi \to \psi)]$
    \item \label{HPL-T-EXH} [EXH] Proof by exhaustion: $(\varphi \to \psi) \to [(\neg \varphi \to \psi) \to \psi]$
\end{enumerate}
\end{proposition}
\begin{proof} \ 
\begin{enumerate}
    \item For $\neg \neg \varphi \to \varphi$
    \begin{enumerate}
        \item Substitute $\alpha := \varphi$ and $\beta := \neg \varphi$ into \hyperref[HPL-A-PNC]{PNC}
        \begin{align*}
            (\neg \varphi \to \neg \neg \varphi) \to [(\neg \varphi \to \neg \varphi) \to \varphi]
        \end{align*}
        \item Substitute $\varphi := \neg \varphi \to \neg \neg \varphi$, $\psi := \neg \varphi \to \neg \varphi$ and $\xi := \varphi$ into \hyperref[HPL-T-AS]{AS}
        \begin{align*}
            [(\neg \varphi \to \neg \neg \varphi) \to ((\neg \varphi \to \neg \varphi) \to \varphi)] \to [(\neg \varphi \to \neg \varphi) \to ((\neg \varphi \to \neg \neg \varphi) \to \varphi)]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (a) and (b)
        \begin{align*}
            (\neg \varphi \to \neg \varphi) \to [(\neg \varphi \to \neg \neg \varphi) \to \varphi]
        \end{align*}
        \item Substitute $\varphi := \neg \varphi$ into \hyperref[HPL-T-RX]{RX}
        \begin{align*}
            \neg \varphi \to \neg \varphi
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (c) and (d)
        \begin{align*}
            (\neg \varphi \to \neg \neg \varphi) \to \varphi
        \end{align*}
        \item Substitute $\alpha := \neg \neg \varphi$ and $\beta := \neg \varphi$ into \hyperref[HPL-A-IP1]{IP1}
        \begin{align*}
            \neg \neg \varphi \to (\neg \varphi \to \neg \neg \varphi)
        \end{align*}
        \item Substitute $\varphi := \neg \neg \varphi$, $\psi := \neg \varphi \to \neg \neg \varphi$ and $\xi := \varphi$ into \hyperref[HPL-T-HS]{HS}
        \begin{align*}
            [\neg \neg \varphi \to (\neg \varphi \to \neg \neg \varphi)] \to [[(\neg \varphi \to \neg \neg \varphi) \to \varphi] \to (\neg \neg \varphi \to \varphi)]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (f) and (g)
        \begin{align*}
            [(\neg \varphi \to \neg \neg \varphi) \to \varphi] \to (\neg \neg \varphi \to \varphi)
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (e) and (h)
        \begin{align*}
            \neg \neg \varphi \to \varphi
        \end{align*}
    \end{enumerate}
    For $\varphi \to \neg \neg \varphi$
    \begin{enumerate}
        \item Substitute $\alpha := \neg \neg \varphi$ and $\beta := \varphi$ into \hyperref[HPL-A-PNC]{PNC}
        \begin{align*}
            (\neg \neg \neg \varphi \to \neg \varphi) \to [(\neg \neg \neg \varphi \to \varphi) \to \neg \neg \varphi]
        \end{align*}
        \item Substitute $\varphi := \neg \varphi$ into the previous result
        \begin{align*}
            \neg \neg \neg \varphi \to \neg \varphi
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (a) and (b)
        \begin{align*}
            (\neg \neg \neg \varphi \to \varphi) \to \neg \neg \varphi
        \end{align*}
        \item Substitute $\alpha := \varphi$ and $\beta := \neg \neg \neg \varphi$ into \hyperref[HPL-A-IP1]{IP1}
        \begin{align*}
            \varphi \to (\neg \neg \neg \varphi \to \varphi)
        \end{align*}
        \item Substitute $\varphi := \varphi$, $\psi := \neg \neg \neg \varphi \to \varphi$, and $\xi := \neg \neg \varphi$ into \hyperref[HPL-T-HS]{HS}
        \begin{align*}
            [\varphi \to (\neg \neg \neg \varphi \to \varphi)] \to [[(\neg \neg \neg \varphi \to \varphi) \to \neg \neg \varphi] \to (\varphi \to \neg \neg \varphi)]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (d) and (e)
        \begin{align*}
            [(\neg \neg \neg \varphi \to \varphi) \to \neg \neg \varphi] \to (\varphi \to \neg \neg \varphi)
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (c) and (f)
        \begin{align*}
            \varphi \to \neg \neg \varphi
        \end{align*}
    \end{enumerate}
    \item Suppose $\neg \varphi$ and $\varphi$, we will show that $\psi$
    \begin{enumerate}
        \item Substitute $\alpha := \varphi$ and $\beta := \neg \psi$ into \hyperref[HPL-A-IP1]{IP1}
        \begin{align*}
            \varphi \to (\neg \psi \to \varphi)
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (a) and the hypothesis $\varphi$
        \begin{align*}
            \neg \psi \to \varphi
        \end{align*}
        \item Substitute $\varphi := \neg \varphi$ into previous result
        \begin{align*}
            \neg \psi \to \neg \varphi
        \end{align*}
        \item Substitute $\alpha := \psi$ and $\beta := \varphi$ into \hyperref[HPL-A-PNC]{PNC}
        \begin{align*}
            (\neg \psi \to \neg \varphi) \to [(\neg \psi \to \varphi) \to \psi]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (c) and (d)
        \begin{align*}
            (\neg \psi \to \varphi) \to \psi
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (b) and (e)
        \begin{align*}
            \psi
        \end{align*}
    \end{enumerate}
    Thus, $\neg \varphi, \varphi \vdash \psi$. Applying deduction metatheorem twice, we get $\vdash \neg \varphi \to (\varphi \to \psi)$.
    \item For $(\neg \psi \to \neg \varphi) \to (\varphi \to \psi)$: suppose $\neg \psi \to \neg \varphi$
    \begin{enumerate}
        \item Substitute $\alpha := \psi$ and $\beta := \varphi$ into \hyperref[HPL-A-PNC]{PNC}
        \begin{align*}
            (\neg \psi \to \neg \varphi) \to [(\neg \psi \to \varphi) \to \psi]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (a) and hypothesis $\neg \psi \to \neg \varphi$
        \begin{align*}
            (\neg \psi \to \varphi) \to \psi
        \end{align*}
        \item Substitute $\alpha := \varphi$ and $\beta := \neg \psi$ into \hyperref[HPL-A-IP1]{IP1}
        \begin{align*}
            \varphi \to (\neg \psi \to \varphi)
        \end{align*}
        \item Substitute $\varphi := \varphi$, $\psi := \neg \psi \to \varphi$ and $\xi := \psi$ into \hyperref[HPL-T-HS]{HS}
        \begin{align*}
            [\varphi \to (\neg \psi \to \varphi)] \to [[(\neg \psi \to \varphi) \to \psi] \to (\varphi \to \psi)]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (c) and (d)
        \begin{align*}
            [(\neg \psi \to \varphi) \to \psi] \to (\varphi \to \psi)
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (b) and (e)
        \begin{align*}
            \varphi \to \psi
        \end{align*}
    \end{enumerate}
    For $(\varphi \to \psi) \to (\neg \psi \to \neg \varphi)$: suppose $\varphi \to \psi$
    \begin{enumerate}
        \item Substitute $\varphi := \neg \neg \varphi$, $\psi := \varphi$, and $\xi := \psi$ into \hyperref[HPL-T-HS]{HS}
        \begin{align*}
            (\neg \neg \varphi \to \varphi) \to [(\varphi \to \psi) \to (\neg \neg \varphi \to \psi)]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (a) and \hyperref[HPL-T-DN]{DN}
        \begin{align*}
            (\varphi \to \psi) \to (\neg \neg \varphi \to \psi)
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (b) and the hypothesis $\varphi \to \psi$
        \begin{align*}
            \neg \neg \varphi \to \psi
        \end{align*}
        \item Substitute $\varphi := \neg \neg \varphi$, $\psi := \psi$, and $\xi := \neg \neg \psi$ into \hyperref[HPL-T-HS]{HS}
        \begin{align*}
            (\neg \neg \varphi \to \psi) \to [(\psi \to \neg \neg \psi) \to (\neg \neg \varphi \to \neg \neg \psi)]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (c) and (d)
        \begin{align*}
            (\psi \to \neg \neg \psi) \to (\neg \neg \varphi \to \neg \neg \psi)
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (e) and \hyperref[HPL-T-DN]{DN}
        \begin{align*}
            \neg \neg \varphi \to \neg \neg \psi
        \end{align*}
        \item Substitute $\varphi := \neg \psi$ and $\psi := \neg \varphi$ into previous result $(\neg \psi \to \neg \varphi) \to (\varphi \to \psi)$
        \begin{align*}
            (\neg \neg \varphi \to \neg \neg \psi) \to (\neg \psi \to \neg \varphi)
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (f) and (g)
        \begin{align*}
            \neg \psi \to \neg \varphi
        \end{align*}
    \end{enumerate}
    \item
    \begin{enumerate}
        \item Apply deduction metatheorem twice to \hyperref[HPL-R-MP]{MP}
        \begin{align*}
            \varphi \to [(\varphi \to \psi) \to \psi]
        \end{align*}
        \item Substitute $\varphi := \varphi \to \psi$ and $\psi := \psi$ to \hyperref[HPL-T-CTP]{CTP}
        \begin{align*}
            [(\varphi \to \psi) \to \psi] \to [\neg \psi \to \neg (\varphi \to \psi)]
        \end{align*}
        \item Substitute $\varphi := \varphi$, $\psi := (\varphi \to \psi) \to \psi$ and $\xi := \neg \psi \to \neg (\varphi \to \psi)$ to \hyperref[HPL-T-HS]{HS}
        \begin{align*}
            & [\varphi \to ((\varphi \to \psi) \to \psi)] \to [[((\varphi \to \psi) \to \psi) \to (\neg \psi \to \neg (\varphi \to \psi))]
            \\
            & \qquad \to [\varphi \to (\neg \psi \to \neg (\varphi \to \psi))]]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (a) and (c)
        \begin{align*}
            & [((\varphi \to \psi) \to \psi) \to (\neg \psi \to \neg (\varphi \to \psi))] \to [\varphi \to (\neg \psi \to \neg (\varphi \to \psi))]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (b) and (d)
        \begin{align*}
            \varphi \to [\neg \psi \to \neg (\varphi \to \psi)]
        \end{align*}
    \end{enumerate}
    \item Suppose $\varphi \to \psi$ and $\neg \varphi \to \psi$:
    \begin{enumerate}
        \item Apply \hyperref[HPL-R-MP]{MP} to \hyperref[HPL-T-CTP]{CTP} and the hypothesis $\varphi \to \psi$
        \begin{align*}
            \neg \psi \to \neg \varphi
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to \hyperref[HPL-T-CTP]{CTP} and the hypothesis $\neg \varphi \to \psi$
        \begin{align*}
            \neg \psi \to \neg \neg \varphi
        \end{align*}
        \item Substitute $\alpha := \psi$ and $\beta := \neg \varphi$ into \hyperref[HPL-A-PNC]{PNC}
        \begin{align*}
            (\neg \psi \to \neg \neg \varphi) \to [(\neg \psi \to \neg \varphi) \to \psi]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (b) and (c)
        \begin{align*}
            (\neg \psi \to \neg \varphi) \to \psi
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to steps (a) and (d)
        \begin{align*}
            \psi
        \end{align*}
    \end{enumerate}
    We thus get $\varphi \to \psi, \neg \varphi \to \psi \vdash \psi$. Apply the deduction metatheorem twice, we should have $(\varphi \to \psi) \to [(\neg \varphi \to \psi) \to \psi]$.
    \item
    \begin{enumerate}
        \item Substitute $\alpha, \beta := \varphi$ into \hyperref[HPL-A-PNC]{PNC}
        \begin{align*}
            (\neg \varphi \to \neg \varphi) \to [(\neg \varphi \to \varphi) \to \varphi]
        \end{align*}
        \item Apply \hyperref[HPL-R-MP]{MP} to step (a) and \hyperref[HPL-T-RX]{RX}
        \begin{align*}
            (\neg \varphi \to \varphi) \to \varphi
        \end{align*}
    \end{enumerate}
\end{enumerate}
\end{proof}

\subsection{Truth values}
Without a set-theoretic framework, this section is very informal. However, it is crucial in translating the \textit{validity} of a formula into a formal proof of it.
\\
\\
Let $F_0$ denote the collection of all well-formed formulas of propositional logic. A \emph{valuation} on $F_0$ is a function $\mathfrak{v}: F_0 \to \{ 0, 1 \}$ which assigns each formula to either $0$ (false) or $1$ (true).
\\
\\
If $\Gamma$ is a collection of wffs (i.e. $\Gamma \subseteq F_0$), we then say that $\mathfrak{v}$ \emph{interprets}, or \emph{satisfies}, $\Gamma$ (denoted as $\mathfrak{v} \vDash \Gamma$) if
\begin{enumerate}
    \item $\mathfrak{v}(\varphi \to \psi) = 0$ if and only if $\mathfrak{v}(\varphi) = 1$ and $\mathfrak{v}(\psi) = 0$.
    \item $\mathfrak{v}(\varphi) = 1 - \mathfrak{v}(\neg \varphi)$. Equivalently,
    \begin{enumerate}
        \item $\mathfrak{v}(\varphi) = 0$ if and only if $\mathfrak{v}(\neg \varphi) = 1$.
        \item $\mathfrak{v}(\varphi) = 1$ if and only if $\mathfrak{v}(\neg \varphi) = 0$.
    \end{enumerate}
    \item $\mathfrak{v}(\varphi) = 1$ for all $\varphi$ in $\Gamma$.
\end{enumerate}
\begin{remark} \label{logic-gen-val}
Such $\mathfrak{v}$ may not exist for arbitrary $\Gamma$. However, when $\Gamma$ is empty, we do have a way to construct such valuation. Let $A_0$ be the collection of atomic formulas (i.e. $A_0 = \Sigma_A \cap F_0$). For each map $v: A_0 \to \{ 0, 1 \}$, we can inductively extend it to another map $\overline{v}: F_0 \to \{ 0, 1 \}$ as follows
\begin{enumerate}
    \item $\overline{v} (p) = v(p)$ whenever $p \in A_0$.
    \item $\overline{v} (\varphi \to \psi) = 0$ if and only if $\overline{v} (\varphi) = 1$ and $\overline{v} (\psi) = 0$.
    \item $\overline{v} (\neg\varphi) = 0$ if and only if $\overline{v} (\varphi) = 1$, and vice versa.
\end{enumerate}
In fact, by the principle of induction, if $\mathfrak{v}, \mathfrak{w}$ are valuations which interpret propositional logic (i.e. when $\Gamma$ is empty) such that they agrees on atomic formulas, then they are the same
\begin{center}
    $\mathfrak{v} = \mathfrak{w}$ whenever $\mathfrak{v} \mid_{A_0} = \mathfrak{w} \mid_{A_0}$
\end{center}
\end{remark}
If $\mathfrak{v} \vDash \varphi$ whenever $\mathfrak{v} \vDash \Gamma$, then we say that $\Gamma$ \emph{semantically entails} $\varphi$, and write $\Gamma \vDash \varphi$.
\begin{remark}
If there is no such $\mathfrak{v}$ (that interprets $\Gamma$), then by convention, we vacuously have $\Gamma \vDash \varphi$ for arbitrary $\varphi$. This can be explained intuitively as follows: by an abuse of notation, $\Gamma \vDash \varphi \leftrightarrow \left( \forall \mathfrak{v}: \mathfrak{v} \vDash \Gamma \rightarrow \mathfrak{v} \vDash \varphi \right)$. So if there is no $\mathfrak{v}$ satisfying $\Gamma$, then the precedent is always false, which means the whole implication is vacuously true. By equivalence, $\Gamma \vDash \varphi$.
\end{remark}
\begin{lemma} \label{logic-propositional-semantics-compatibility}
If $\mathfrak{v}$ interprets $\Gamma$, then
\begin{enumerate}
    \item $\mathfrak{v}(\alpha) = 1$ whenever $\alpha$ is an axiom.
    \item If $\mathfrak{v}(\alpha) = \mathfrak{v}(\alpha \to \beta) = 1$, then $\mathfrak{v}(\beta) = 1$.
\end{enumerate}
\end{lemma}
\begin{proof}
\underline{Part 1:} the following truth tables should verify $\mathfrak{v}(\alpha) = 1$ no matter what values $\mathfrak{v}$ assigns to wff inside each axiom.
\begin{center}
    \begin{tabular}{|c|cccc|}
        \hline
        $\alpha$ & $0$ & $0$ & $1$ & $1$ \\
        $\beta$ & $0$ & $1$ & $0$ & $1$ \\
        \hline
        $\beta \to \alpha$ & $1$ & $0$ & $1$ & $1$ \\
        $\alpha \to (\beta \to \alpha)$ & $1$ & $1$ & $1$ & $1$ \\
        \hline
    \end{tabular}
    \ \\
    \ \\
    \ \\
    \begin{tabular}{|c|cccccccc|}
        \hline
        $\alpha$ & $0$ & $0$ & $0$ & $0$ & $1$ & $1$ & $1$ & $1$ \\
        $\beta$ & $0$ & $0$ & $1$ & $1$ & $0$ & $0$ & $1$ & $1$ \\
        $\gamma$ & $0$ & $1$ & $0$ & $1$ & $0$ & $1$ & $0$ & $1$ \\
        \hline
        $\beta \to \gamma$ & $1$ & $1$ & $0$ & $1$ & $1$ & $1$ & $0$ & $1$ \\
        $\alpha \to (\beta \to \gamma)$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $0$ & $1$ \\
        \hline
        $\alpha \to \beta$ & $1$ & $1$ & $1$ & $1$ & $0$ & $0$ & $1$ & $1$ \\
        $\alpha \to \gamma$ & $1$ & $1$ & $1$ & $1$ & $0$ & $1$ & $0$ & $1$ \\
        $(\alpha \to \beta) \to (\alpha \to \gamma)$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $0$ & $1$ \\
        \hline
        $[\alpha \to (\beta \to \gamma)] \to [(\alpha \to \beta) \to (\alpha \to \gamma)]$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ \\
        \hline
    \end{tabular}
    \ \\
    \ \\
    \ \\
    \begin{tabular}{|c|cccc|}
        \hline
        $\alpha$ & $0$ & $0$ & $1$ & $1$ \\
        $\beta$ & $0$ & $1$ & $0$ & $1$ \\
        \hline
        $\neg \alpha$ & $1$ & $1$ & $0$ & $0$ \\
        $\neg \beta$ & $1$ & $0$ & $1$ & $0$ \\
        $\neg \alpha \to \neg \beta$ & $1$ & $0$ & $1$ & $1$ \\
        \hline
        $\neg \alpha \to \beta$ & $0$ & $1$ & $1$ & $1$ \\
        $(\neg \alpha \to \beta) \to \alpha$ & $1$ & $0$ & $1$ & $1$ \\
        \hline
        $(\neg \alpha \to \neg \beta) \to [(\neg \alpha \to \beta) \to \alpha]$ & $1$ & $1$ & $1$ & $1$ \\
        \hline
    \end{tabular}
\end{center}
\underline{Part 2:} suppose $\mathfrak{v}(\alpha) = \mathfrak{v}(\alpha \to \beta) = 1$, if $\mathfrak{v}(\beta) = 0$ then $\mathfrak{v}(\alpha \to \beta) = 0$ by definition. Therefore, $\mathfrak{v}(\beta) = 1$.
\end{proof}
\begin{theorem}[Soundness theorem]
If $\Gamma \vdash \varphi$, then $\Gamma \vDash \varphi$.
\end{theorem}
\begin{proof}
We do induction on the length of proof of $\varphi$ from $\Gamma$.
\begin{enumerate}
    \item The base case: when the proof of $\varphi$ is only $\varphi$. Then $\varphi$ must be either an axiom, or belongs to $\Gamma$.
    \begin{enumerate}
        \item If $\varphi$ is an axiom, then $\mathfrak{v}(\varphi) = 1$ by previous \hyperref[logic-propositional-semantics-compatibility]{Lemma \ref*{logic-propositional-semantics-compatibility}}.
        \item If $\varphi \in \Gamma$, then $\mathfrak{v}(\varphi) = 1$ also since $\mathfrak{v} \vDash \Gamma$.
    \end{enumerate}
    \item The inductive case, suppose $(\lambda_1, \hdots, \lambda_n = \varphi)$ is a proof of $\varphi$ from $\Gamma$ such that $\mathfrak{v}(\lambda_i) = 1$ for $1 \leq i < n$.
    \begin{enumerate}
        \item If $\varphi$ is an axiom, or belongs to $\Gamma$: we get $\mathfrak{v}(\varphi) = 1$ from base case.
        \item If $\varphi$ is an application of \hyperref[HPL-R-MP]{MP} to some $\lambda_i$ and $\lambda_j$ for $i, j < n$. WLOG, we suppose $\lambda_j$ is of the form $\lambda_i \to \varphi$. Then by induction hypothesis, we have $\mathfrak{v}(\lambda_i) = \mathfrak{v}(\lambda_i \to \varphi) = 1$. By \hyperref[logic-propositional-semantics-compatibility]{Lemma \ref*{logic-propositional-semantics-compatibility}}, we should get $\mathfrak{v}(\varphi) = 1$.
    \end{enumerate}
\end{enumerate}
Thus, any $\mathfrak{v}$ that inteprets $\Gamma$ must also satisfy $\varphi$. By definition $\Gamma \vDash \varphi$.
\end{proof}
\begin{remark} \
\begin{enumerate}
	\item Equivalently (to the soundness theorem), if there exists an interpretation $\mathfrak{v}$ that satisfies $\Gamma$ yet not $\varphi$ (i.e. $\mathfrak{v}$ satisfies $\neg \varphi$), then $\varphi$ is not derivable from $\Gamma$.
	\item Moreover, if there also exists interpretation $\mathfrak{v}$ that satisfies $\Gamma$ and $\varphi$, then $\varphi$ is said to be \emph{independent} from $\Gamma$ (as $\Gamma$ cannot refute $\varphi$).
	\item As for the case where every $\mathfrak{v}$ that satisfies $\Gamma$ does not satisfy $\varphi$, then $\Gamma$ actually refutes $\varphi$ (i.e. it proves the negation of $\varphi$). This is called completeness, and we will prove it when $\Gamma$ is empty, which is sufficient enough as a foundation of everything else.
\end{enumerate}
\end{remark}

\subsection{Propositional substitution}
Let $p_1, p_2, \hdots, p_n$ be the only atomic formulas (or \emph{propositional variables}) that involved in a wff $\varphi$. For wff $\theta_1, \hdots, \theta_n$ (which matches the number of variables in $\varphi$), we can then define the \emph{substitution} $\varphi[p_1 := \theta_1, \hdots, p_n := \theta_n]$ where we replace every occurrence of $p_i$ in $\varphi$ by respective $\theta_i$. The \emph{schema} of $\varphi$ is defined as the collection of all substitutions into $\varphi$.
\begin{remark}[Principle of Uniform Substitution]\label{logic-prin-uni-sub} A recursive definition is given as follows
\begin{enumerate}
	\item $p[p := \theta]$ is the same as $\varphi$.
	\item $\varphi[p := \theta] \to \psi[p := \theta]$ is the same as $(\varphi \to \psi)[p := \theta]$.
	\item $\neg (\varphi[p := \theta])$ is the same as $(\neg \varphi)[p := \theta]$.
\end{enumerate}
\end{remark}
\begin{example} \ 
\begin{enumerate}
    \item The schema of $p \to (q \to p)$ is all $\alpha \to (\beta \to \alpha)$ for arbitrary wff $\alpha, \beta$.
    \item The schema of $[p \to (q \to r)] \to [(p \to q) \to (p \to r)]$ is all $[\alpha \to (\beta \to \gamma)] \to [(\alpha \to \beta) \to (\alpha \to \gamma)]$ for arbitrary wff $\alpha, \beta, \gamma$.
    \item The schema of $(\neg p \to \neg q) \to [(\neg p \to q) \to p]$ is all $(\neg \alpha \to \neg \beta) \to [(\neg \alpha \to \beta) \to \alpha]$ for arbitrary wff $\alpha, \beta$.
\end{enumerate}
\end{example}
\begin{theorem}[Uniformness Theorem]
Suppose $\varphi$ is a theorem (of propositional logic). Then each formula in the schema of $\varphi$ is also a theorem.
\end{theorem}
\begin{proof}
Assume $p_i$ ($1 \leq i \leq n$) are propositional variables in $\varphi$. Let $\theta_1, \theta_2, \hdots, \theta_n$ be wffs that are to substitute into $\varphi$. Since $\varphi$ is a theorem, there is a proof $(\lambda_1, \lambda_2, \hdots, \lambda_m = \varphi)$ of it. We will show that the sequence $(\lambda_j [p_i := \theta_i])_{1 \leq j \leq m}$ is a proof for $\varphi[p_i := \theta_i]$. By definition, each $\lambda_j$ ($j = \overline{1, m}$) is either
\begin{enumerate}
    \item An axiom: we will show that $\lambda_j[p_i := \theta_i]$ is also an axiom if $\lambda_j$ is of the form $\alpha \to (\beta \to \alpha)$, and the other 2 cases follows similarly. By \hyperref[logic-prin-uni-sub]{Remark \ref*{logic-prin-uni-sub}}, $\lambda_j[p_i := \theta_i]$ is the same as $(\alpha \to (\beta \to \alpha))[p_i := \theta_i]$, or $\mu \to (\nu \to \mu)$ where $\mu := \alpha[p_i := \theta_i]$ and $\nu := \beta[p_i := \theta_i]$. Note that $\mu \to (\nu \to \mu)$ is itself an axiom, so we conclude that $\lambda_j [p_i := \theta_i]$ is an axiom.
    \item An application of \hyperref[HPL-R-MP]{MP} to $\lambda_k$ and $\lambda_l := \lambda_k \to \lambda_j$: then $\lambda_j[p_i := \theta_i]$ is an application of \hyperref[HPL-R-MP]{MP} to $\lambda_k [p_i := \theta_i]$ and $\lambda_k [p_i := \theta_i] \to \lambda_j [p_i := \theta_i]$, where the latter is the same as $\lambda_l [p_i := \theta_i]$ (due to \hyperref[logic-prin-uni-sub]{Remark \ref*{logic-prin-uni-sub}}). In other words, $\lambda_j [p_i := \theta_i]$ is an application of \hyperref[HPL-R-MP]{MP} to $\lambda_k[p_i := \theta_i]$ and $\lambda_l[p_i := \theta_i]$
\end{enumerate}
In summary, each $\eta_j := \lambda_j [p_i := \theta_i]$ is either
\begin{enumerate}
    \item An axiom of propositional logic
    \item An application of \hyperref[HPL-R-MP]{MP} to some $\eta_k$ and $\eta_l$ ($k, l < j$).
\end{enumerate}
Note that $\eta_m$ is the same as $\varphi[p_i := \theta_i]$, so by definition, $(\eta_1, \hdots, \eta_m)$ is a proof of $\varphi[p_i := \theta_i]$
\end{proof}
\begin{remark}
This provides a uniform proof for each formula in the schema of $\varphi$, assuming $\varphi$ is a theorem (i.e. there exists a proof of it).
\end{remark}

\subsection{Completeness}
The converse of \emph{soundness}, i.e. $\Gamma \vdash \varphi$ whenever $\Gamma \vDash \varphi$, is called the \emph{completeness} property, and in propositional logic, this does hold. In fact, this holds in arbitrary logic (with the same language as propositional logic) whenenever
\begin{enumerate}
    \item The inference rule modus ponens holds
    \item The followings statements (or wffs) are provable, given wffs $\varphi, \psi, \xi$:
    \begin{enumerate}
        \item $\varphi \to (\psi \to \varphi)$
        \item $[\varphi \to (\psi \to \xi)] \to [(\varphi \to \psi) \to (\varphi \to \xi)]$
        \item $\varphi \to \varphi$
        \item $\varphi \to \neg \neg \varphi$
        \item $\neg \varphi \to (\varphi \to \psi)$
        \item $\varphi \to [\neg \psi \to \neg (\varphi \to \psi)]$
        \item $(\varphi \to \psi) \to [(\neg \varphi \to \psi) \to \psi]$
    \end{enumerate}
\end{enumerate}
However, \textit{constructively}, it is only possible to construct a proof for $\Gamma \vdash \varphi$ from $\Gamma \vDash \varphi$ when there are only finitely many atomic formulas (or \emph{propositional variables}) involved in formulas belong to $\Gamma$. We will only deal with the case when $\Gamma$ is empty, as the remaining ones will be discussed in more detail much later.
\begin{remark}
Those statements are the result of
\begin{enumerate}
    \item The axioms \hyperref[HPL-A-IP1]{IP1}, \hyperref[HPL-A-IP2]{IP2}.
    \item Reflexivity \hyperref[HPL-T-RX]{RX}
    \item \hyperref[logic-sufficient-completeness]{Proposition \ref*{logic-sufficient-completeness}}
\end{enumerate}
\end{remark}
\begin{lemma} [KalmÃ¡r lemma] \label{logic-interpretation-cascade}
Suppose $\mathfrak{v}: F_0 \to \{ 0, 1 \}$ is an interpretion of propositional logic, and $p_1, p_2, \hdots, p_n$ are atomic wffs involved in a wff $\varphi$. We then construct the following formulas $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n}, \overline{\varphi}$
\begin{enumerate}
    \item For each $p_i$, if $\mathfrak{v}(p_i) = 1$ then $\overline{p_i} := p_i$. Otherwise, $\overline{p_i} := \neg p_i$.
    \item If $\mathfrak{v}(\varphi) = 1$, then $\overline{\varphi} := \varphi$. Otherwise, $\overline{\varphi} := \neg \varphi$.
\end{enumerate}
It is then true that $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\varphi}$.
\end{lemma}
\begin{proof}
We do an induction on the number of connectives in $\varphi$
\begin{enumerate}
    \item Base case: if $\varphi$ does not have any connective, then it is just an atomic formula by (inductive) definition. Thus $\overline{\varphi}$ is the same as $\varphi$, and so $\overline{\varphi} \vdash \varphi$ trivially (as the proof only has one step $\overline{\varphi}$).
    \item Inductive case, when $\varphi := \neg \psi$: then $\psi$ and $\varphi$ have the same propositional variables (which are $p_1, p_2, \hdots, p_n$). But $\psi$ has one less connectives, so by induction
    \begin{align*}
        \overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\psi}
    \end{align*}
    We divide into 2 cases
    \begin{enumerate}
        \item If $\mathfrak{v}(\psi) = 1$, then $\overline{\psi} = \psi$, $\mathfrak{v}(\varphi) = \mathfrak{v}(\neg \psi) = 0$, and $\overline{\varphi} = \neg \varphi = \neg \neg \psi$. By \hyperref[HPL-T-DN]{DN}, $\vdash \psi \to \neg \neg \psi$, so we should get $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\psi} \to \overline{\varphi}$.
        \item If $\mathfrak{v}(\psi) = 0$, then $\overline{\psi} = \neg\psi$, $\mathfrak{v}(\varphi) = \mathfrak{v}(\neg \psi) = 1$, and $\overline{\varphi} =  \varphi = \neg \psi$. By \hyperref[HPL-T-RX]{RX}, $\vdash \neg \psi \to \neg \psi$, so we should get $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\psi} \to \overline{\varphi}$.
    \end{enumerate}
    In either case, $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\psi} \to \overline{\varphi}$. So by applying \hyperref[HPL-R-MP]{MP}, we obtain $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\varphi}$.
    \item Inductive case, when $\varphi := \psi \to \xi$: let $q_1, q_2, \hdots, q_m$ be the variables involved in $\psi$, and $r_1, r_2, \hdots, r_p$ be the variables involved in $\xi$. By assumption, these variables must be from $p_1, p_2, \hdots, p_n$. But since
    \begin{align*}
        \overline{q_1}, \overline{q_2}, \hdots, \overline{q_m} & \vdash \overline{\psi}
        \\
        \overline{r_1}, \overline{r_2}, \hdots, \overline{r_p} & \vdash \overline{\xi}
    \end{align*}
    by induction hypothesis (as the connectives of $\psi$ and $\xi$ together are still one less than those of $\varphi$), we get $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\psi}, \overline{\xi}$ by \hyperref[logic-proof-props]{monotonicity}.
    \\
    \\
    To show this, as a result, proves $\overline{\varphi}$, we divide into the following cases
    \begin{enumerate}
        \item If $\mathfrak{v}(\psi) = 0$: then $\overline{\psi} = \neg \psi$, and $\mathfrak{v}(\varphi) = 1$, $\overline{\varphi} = \varphi = \psi \to \xi$. From \hyperref[HPL-T-EXP]{EXP}, we get
        \begin{align*}
            \overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} & \vdash \neg \psi \to (\psi \to \xi) \mbox{ or}
            \\
            \overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} & \vdash \overline{\psi} \to \overline{\varphi}
        \end{align*}
        So we get $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\varphi}$ with an application of \hyperref[HPL-R-MP]{MP}.
        \item If $\mathfrak{v}(\psi) = 1$, $\mathfrak{v}(\xi) = 0$: then $\overline{\psi} = \psi$, $\overline{\xi} = \neg \xi$, and $\mathfrak{v}(\varphi) = 0$, $\overline{\varphi} = \neg \varphi = \neg (\psi \to \xi)$. But by \hyperref[HPL-T-MI]{MI},
        \begin{align*}
            \overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} & \vdash \psi \to [\neg \xi \to \neg (\psi \to \xi)] \mbox{ or}
            \\
            \overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} & \vdash \overline{\psi} \to (\overline{\xi} \to \overline{\varphi})
        \end{align*}
        So applying \hyperref[HPL-R-MP]{MP} twice to $\overline{\psi} \to (\overline{\xi} \to \overline{\varphi})$ and $\overline{\psi}, \overline{\xi}$ (from induction hypothesis), and we will get $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\varphi}$.
        \item If $\mathfrak{v}(\psi) = 1$, $\mathfrak{v}(\xi) = 1$: then $\overline{\psi} = \psi$, $\overline{\xi} = \xi$, and $\mathfrak{v}(\varphi) = 1$, $\overline{\varphi} = \varphi = \psi \to \xi$. But by \hyperref[HPL-A-IP1]{IP1},
        \begin{align*}
            \overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} & \vdash \xi \to (\psi \to \xi) \mbox{ or}
            \\
            \overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} & \vdash \overline{\xi} \to \overline{\varphi}
        \end{align*}
        So by applying \hyperref[HPL-R-MP]{MP} once, we should get $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\varphi}$.
    \end{enumerate}
\end{enumerate}
\end{proof}
\begin{remark}
To illustrate the process of proof construction, we take $(\neg \varphi \to \varphi) \to \varphi$ (which holds in every interpretation) as an example to show that
\begin{center}
    $\varphi \vdash (\neg \varphi \to \varphi) \to \varphi$ (when $\mathfrak{v}(\varphi) = 1$)
\end{center}
Indeed
\begin{enumerate}[label = (\alph*)]
    \item By \hyperref[HPL-T-DN]{DN}
    \begin{align*}
        \varphi \to \neg \neg \varphi
    \end{align*}
    \item Apply \hyperref[HPL-R-MP]{MP} to step (a) and the hypothesis $\varphi$
    \begin{align*}
        \neg \neg \varphi
    \end{align*}
    \item Since $\mathfrak{v}(\varphi) = 1$, $\mathfrak{v}(\neg\varphi) = 0$. So by \hyperref[HPL-T-EXP]{EXP}
    \begin{align*}
        \neg \neg \varphi \to (\neg \varphi \to \varphi)
    \end{align*}
    \item Apply \hyperref[HPL-R-MP]{MP} to steps (b) and (c)
    \begin{align*}
        \neg \varphi \to \varphi
    \end{align*}
    \item Since $\mathfrak{v}(\neg \varphi \to \varphi) = 1$, we now use \hyperref[HPL-A-IP1]{IP1} to get
    \begin{align*}
        \varphi \to [(\neg \varphi \to \varphi) \to \varphi]
    \end{align*}
    \item We then apply \hyperref[HPL-R-MP]{MP} to step (e) and the hypothesis $\varphi$
    \begin{align*}
        (\neg \varphi \to \varphi) \to \varphi
    \end{align*}
\end{enumerate}
Note that there may be redundancy (e.g. steps (a) to (d)), but this is how the proof is constructed based on the lemma.
\end{remark}
\begin{theorem}[Completeness theorem]
Given a wff $\varphi$, then $\vDash \varphi$ implies $\vdash \varphi$.
\end{theorem}
\begin{proof}
Let $p_1, p_2, \hdots, p_n$ be propositional variables in $\varphi$, $\mathfrak{v}$ be any valuation. We will denote $\overline{\theta}^\mathfrak{v}$ to be either $\theta$ or $\neg \theta$ based on the value of $\theta$ under $\mathfrak{v}$. Since $\vDash \varphi$, we get $\overline{\varphi}^\mathfrak{v} = \varphi$. By \hyperref[logic-interpretation-cascade]{Lemma \ref*{logic-interpretation-cascade}}
\begin{align*}
    \overline{p_1}^\mathfrak{v}, \overline{p_2}^\mathfrak{v}, \hdots, \overline{p_n}^\mathfrak{v} \vdash \varphi
\end{align*}
We will show that $\vdash \varphi$ by induction on the number of variables in $\varphi$.
\begin{enumerate}
    \item Base case: $\overline{p_1}^\mathfrak{v} \vdash \varphi$ (for any $\mathfrak{v}$). Since a valuation is uniquely specified by its value on the atomic formulas (\hyperref[logic-gen-val]{Remark \ref*{logic-gen-val}}), let there exists 2 valuation $\mathfrak{v}_0$ and $\mathfrak{v}_1$ such that $\mathfrak{v}_0 (p_1) = 0$ and $\mathfrak{v}_1 (p_1) = 1$. Hence,
    \begin{align*}
        p_1 & \vdash \varphi
        \\
        \neg p_1 & \vdash \varphi
    \end{align*}
    So by deduction metatheorem, $\vdash p_1 \to \varphi$ and $\vdash \neg p_1 \to \varphi$. By \hyperref[HPL-T-EXH]{EXH}
    \begin{align*}
        \vdash (p_1 \to \varphi) \to [(\neg p_1 \to \varphi) \to \varphi]
    \end{align*}
    We then apply \hyperref[HPL-R-MP]{MP} twice to get $\vdash \varphi$.
    \item Induction case: suppose we can construct a proof $\varphi$ whenever $\overline{p_1}^\mathfrak{v}, \overline{p_2}^\mathfrak{v}, \hdots, \overline{p_n}^\mathfrak{v} \vdash \varphi$ for all valuation $\mathfrak{v}$. We will show that there is also a proof of $\varphi$ whenever $\overline{p_1}^\mathfrak{v}, \overline{p_2}^\mathfrak{v}, \hdots, \overline{p_{n + 1}}^\mathfrak{v} \vdash \varphi$ for all valuation $\mathfrak{v}$.
    \\
    \\
    This is similar to the base case. Let $\mathfrak{v}$ be any valuation, and denote $\mathfrak{w}_0$ and $\mathfrak{w}_1$ such that $\mathfrak{v}(p_i) = \mathfrak{w}_0 (p_i) = \mathfrak{w}_1 (p_i)$ for $1 \leq i \leq n$, yet $\mathfrak{w}_0 (p_{n + 1}) = 0$ and $\mathfrak{w}_1 (p_{n + 1}) = 1$.
    We thus have
    \begin{align*}
        \overline{p_1}^\mathfrak{w_0}, \overline{p_2}^\mathfrak{w_0}, \hdots, \overline{p_n}^\mathfrak{w_0}, p_{n + 1} & \vdash \varphi
        \\
        \overline{p_1}^\mathfrak{w_1}, \overline{p_2}^\mathfrak{w_1}, \hdots, \overline{p_n}^\mathfrak{w_1}, \neg p_{n + 1} & \vdash \varphi
    \end{align*}
    By \hyperref[logic-deduct-metathm]{deduction theorem}, we get $\overline{p_1}^\mathfrak{v}, \overline{p_2}^\mathfrak{v}, \hdots, \overline{p_n}^\mathfrak{v} \vdash p_{n + 1} \to \varphi, \neg p_{n + 1} \to \varphi$ (note that $\mathfrak{v}, \mathfrak{w_0}, \mathfrak{w_1}$ all agree on $p_i$ for $i = \overline{1, n}$). Yet
    \begin{align*}
        \overline{p_1}^\mathfrak{v}, \overline{p_2}^\mathfrak{v}, \hdots, \overline{p_n}^\mathfrak{v} \vdash (p_{n + 1} \to \varphi) \to [(\neg p_{n + 1} \to \varphi) \to \varphi]
    \end{align*}
    So we can deduce $\overline{p_1}^\mathfrak{v}, \overline{p_2}^\mathfrak{v}, \hdots, \overline{p_n}^\mathfrak{v} \vdash \varphi$ by applying \hyperref[HPL-R-MP]{MP}. As $\mathfrak{v}$ varies, we conclude that $\vdash \varphi$ by induction hypothesis.
\end{enumerate}
\end{proof}
\begin{remark}
The completeness property, with deduction metatheorem, can be extended with finitely many hypotheses, i.e.
\begin{center}
    If $\lambda_1, \lambda_2, \hdots, \lambda_n \vDash \varphi$ then $\lambda_1, \lambda_2, \hdots, \lambda_n \vdash \varphi$.
\end{center}
Beyond that, for arbitrary collection of hypothesis $\Gamma$, then a proof of $\varphi$ will not be constructive (even when $\Gamma \vDash \varphi$).
\end{remark}
\begin{example}
Note that the proof of completeness theorem does not use \hyperref[HPL-T-CTP]{CTP}, but only
\begin{enumerate}
    \item \hyperref[HPL-T-RX]{RX}, \hyperref[HPL-T-DN]{DN}, \hyperref[HPL-T-EXP]{EXP}, \hyperref[HPL-T-MI]{MI}, \hyperref[HPL-T-EXH]{EXH}, \hyperref[HPL-A-IP1]{IP1}.
    \item \hyperref[HPL-R-MP]{MP} as an inference rule.
    \item \hyperref[logic-deduct-metathm]{Deduction metatheorem}.
\end{enumerate}
So we will illustrate the proof of \hyperref[HPL-T-CTP]{CTP} using just these basic principles. In particular, we shall prove $\theta_0 := [(\varphi \to \psi) \to (\neg \psi \to \neg \varphi)]$.
\begin{enumerate}
    \item By \hyperref[logic-interpretation-cascade]{Lemma \ref*{logic-interpretation-cascade}}
    \begin{align*}
        \varphi, \psi & \vdash \theta_0
        \\
        \varphi, \neg \psi & \vdash \theta_0
        \\
        \neg \varphi, \psi & \vdash \theta_0
        \\
        \neg \varphi, \neg \psi & \vdash \theta_0
    \end{align*}
    \item By deduction metatheorem
    \begin{align*}
        \varphi & \vdash \psi \to \theta_0
        \\
        \varphi & \vdash \neg \psi \to \theta_0
    \end{align*}
    But since $\vdash (\psi \to \theta_0) \to [(\neg \psi \to \theta_0) \to \theta_0]$ (\hyperref[HPL-T-EXH]{EXH}), we get $\varphi \vdash \theta_0$ by applying \hyperref[HPL-R-MP]{MP} twice. Similarly, $\neg \varphi \vdash \theta_0$.
    \item Again, by deduction metatheorem
    \begin{align*}
        & \vdash \varphi \to \theta_0
        \\
        & \vdash \neg \varphi \to \theta_0
    \end{align*}
    With the same argument as in (2), we finally obtain $\vdash \theta_0$.
\end{enumerate}
\end{example}

\subsection{Consistency}
Given a collection $\Gamma$ of wffs, we say that $\Gamma$ is \emph{(syntactically) inconsistent} if there exists a wff $\delta$ such that $\Gamma \vdash \delta$ and $\Gamma \vdash \neg\delta$. More specifically, there exists a wff $\delta$, a proof of it, and a proof of the negation of it from $\Gamma$.
\begin{theorem} \ 
\begin{enumerate}
    \item $\Gamma$ is inconsistent if and only if $\Gamma \vdash \varphi$ for all wff $\varphi$ (i.e. there is a proof of each wff).
    \item $\Gamma \vdash \varphi$ if and only if $\Gamma \cup \{ \neg \varphi \}$ is inconsistent.
\end{enumerate}
\end{theorem}
\begin{proof} \ \\
\underline{Part 1:} suppose $\Gamma$ is inconsistent, and let $\delta$ be a wff such that $\Gamma \vdash \delta$ and $\Gamma \vdash \neg \delta$. Then apply \hyperref[HPL-R-MP]{MP} twice to \hyperref[HPL-T-EXP]{EXP} (and the previous assumptions), we get $\Gamma \vdash \varphi$ for any wff $\varphi$. Vice versa, if $\Gamma \vdash \varphi$ for any wff $\varphi$, then fix a formula $\delta$, and we will get both $\Gamma \vdash \delta$ and $\Gamma \vdash \neg\delta$.
\\
\underline{Part 2:} suppose $\Gamma \vdash \varphi$, then $\Gamma \cup \{ \neg \varphi \}$ is inconsistent by definition. Vice versa, if $\Gamma \cup \{ \neg \varphi \}$, then there exists some formula $\delta$ such that $\Gamma, \neg \varphi \vdash \delta$ and $\Gamma, \neg \varphi \vdash \neg \delta$.
\begin{enumerate}
    \item By \hyperref[logic-deduct-metathm]{deduction theorem}, we get $\Gamma \vdash \neg \varphi \to \delta$ and $\Gamma \vdash \neg \varphi \to \neg \delta$.
    \item Using truth table, we get a schema $\vdash (\neg \alpha \to \beta) \to [(\neg \alpha \to \neg \beta) \to \beta]$ (i.e. reductio ad impossibile).
    \item Finally, we apply \hyperref[HPL-R-MP]{MP} to arrive at $\Gamma \vdash \varphi$.
\end{enumerate}
\end{proof}
\begin{remark}
The above theorem provides a general way to produce a proof of $\varphi$ from $\Gamma$ whenever $\Gamma \cup \{ \neg \varphi \}$ is inconsistent. More precisely, from a proof of $\Gamma, \neg \varphi \vdash \delta$ and a proof of $\Gamma, \neg \varphi \vdash \neg \delta$ (for some fixed $\delta$), we can algorithmically get a proof of $\Gamma \vdash \varphi$ (regardless of whether $\Gamma$ is inconsistent or not).
\end{remark}

\subsection{Equivalence - Leibniz rule}
Given 2 wffs $\varphi$ and $\psi$, if $\Gamma \vdash \varphi \to \psi$ and $\Gamma \vdash \psi \to \varphi$, then we say that $\varphi$ and $\psi$ are \emph{propositionally equivalent} under $\Gamma$, and write $\varphi \equiv \psi \pmod{\Gamma}$. If $\Gamma$ is empty (i.e. $\varphi \to \psi$ and $\psi \to \varphi$ will be theorems of propositional logic), then we can simply write $\varphi \equiv \psi$.
\begin{remark} \ 
\begin{enumerate}
    \item If $\varphi \equiv \psi \pmod{\Gamma}$ and $\Gamma \subseteq \Delta$, then $\varphi \equiv \psi \pmod{\Delta}$. In particular, $\varphi \equiv \varphi \pmod{\Gamma}$ for any collection $\Gamma$ of formulas.
    \item If $\Gamma \vdash \varphi$, and $\varphi \equiv \psi \pmod{\Gamma}$, then $\Gamma \vdash \psi$.
    \item If $\Gamma \vdash \varphi$ and $\Gamma \vdash \psi$, then $\varphi \equiv \psi \pmod{\Gamma}$.
    \item If $\mathfrak{v} \vDash \Gamma$ and $\varphi \equiv \psi \pmod{\Gamma}$, then $\mathfrak{v}(\varphi) = \mathfrak{v}(\psi)$.
\end{enumerate}
\end{remark}
\begin{proof}
\underline{Part 1:} since $\Gamma \subseteq \Delta$ and $\Gamma \vdash \varphi \to \psi$, we get $\Delta \vdash \varphi \to \psi$ (\hyperref[logic-proof-props]{Remark \ref*{logic-proof-props}}). Similarly, $\Delta \vdash \psi \to \varphi$, so by definition $\varphi \equiv \psi \pmod{\Delta}$.
\\
\underline{Part 2:} since $\Gamma \vdash \varphi$ and $\Gamma \varphi \to \psi$, we get $\Gamma \vdash \psi$ by \hyperref[HPL-R-MP]{MP}.
\\
\underline{Part 3:} from \hyperref[HPL-A-IP1]{IP1}, we get $\Gamma \psi \to (\varphi \to \psi)$, so apply \hyperref[HPL-R-MP]{MP} to it and $\Gamma \vdash \psi$, we get $\Gamma \vdash \varphi \to \psi$. Similarly, $\Gamma \vdash \psi \to \varphi$, so by definition, $\varphi \equiv \psi \pmod{\Gamma}$.
\\
\underline{Part 4:} since $\Gamma \vdash \varphi \to \psi$, $\Gamma \vDash \varphi \to \psi$ by soundness theorem. Thus, $\mathfrak{v}(\varphi \to \psi) = 1$ by definition (whenever $\mathfrak{v}$ interprets $\Gamma$). Similarly, $\mathfrak{v}(\psi \to \varphi) = 1$. Now, suppose $\mathfrak{v}(\varphi) \neq \mathfrak{v}(\psi)$. WLOG, set $\mathfrak{v}(\varphi) = 1$ and $\mathfrak{v}(\psi) = 0$ (since there are only 2 values we can assign each formula to). But then $\mathfrak{v}(\varphi \to \psi) = 0$, a contradiction. We conclude that $\mathfrak{v}(\varphi) = \mathfrak{v}(\psi)$.
\end{proof}
\begin{example} \label{prev-res-log-equiv} \ 
\begin{enumerate}
    \item Double Negation: $\varphi \equiv \neg \neg \varphi$
    \item Contraposition: $\varphi \to \psi \equiv \neg \psi \to \neg \varphi$
    \item Antecedent Swap: $\varphi \to (\psi \to \xi) \equiv \psi \to (\varphi \to \xi)$
\end{enumerate}
\end{example}
\begin{proof} \ \\
\underline{Part 1:} a result of \hyperref[HPL-T-DN]{DN}.
\\
\underline{Part 2:} a result of \hyperref[HPL-T-CTP]{CTP}.
\\
\underline{Part 3:} a result of \hyperref[HPL-T-AS]{AS}.
\end{proof}
\begin{theorem}[Leibniz rule of substitution - LS] \label{HPL-R-LS}
Let $\varphi, \psi$ be wffs. We then have
\begin{enumerate}
    \item $\varphi \equiv \psi \pmod{\Gamma}$ if and only if $\varphi \to \xi \equiv \psi \to \xi \pmod{\Gamma}$ for any wff $\xi$.
    \item $\varphi \equiv \psi \pmod{\Gamma}$ if and only if $\xi \to \varphi \equiv \xi \to \psi \pmod{\Gamma}$ for any wff $\xi$.
    \item $\varphi \equiv \psi \pmod{\Gamma}$ if and only if $\neg \varphi \equiv \neg \psi \pmod{\Gamma}$.
\end{enumerate}
\end{theorem}
\begin{proof}
\underline{Part 1:} suppose $\varphi \equiv \psi \pmod{\Gamma}$. In particular, $\Gamma \vdash \varphi \to \psi$. By \hyperref[HPL-T-HS]{HS} and \hyperref[logic-proof-props]{Remark \ref*{logic-proof-props}}, we have $\Gamma \vdash (\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \xi)]$. Apply \hyperref[HPL-R-MP]{MP} to the previous 2 results, we get $\Gamma \vdash (\psi \to \xi) \to (\varphi \to \xi)$. Similarly, $\Gamma \vdash (\varphi \to \xi) \to (\psi \to \xi)$, and so $\varphi \to \xi \equiv \psi \to \xi \pmod{\Gamma}$.
\\
\\
Vice versa, if $\varphi \to \xi \equiv \psi \to \xi \pmod{\Gamma}$ for any wff $\xi$. Then we let $\xi := \psi$ to get $\varphi \to \psi \equiv \psi \to \psi \pmod{\Gamma}$. But $\Gamma \vdash \psi \to \psi$ by \hyperref[HPL-T-RX]{RX} and \hyperref[logic-proof-props]{Remark \ref*{logic-proof-props}}, so we must have $\Gamma \vdash \varphi \to \psi$ (\hyperref[HPL-R-LS]{Theorem \ref*{HPL-R-LS}}). Similarly, $\Gamma \vdash \psi \to \varphi$ (by setting $\xi := \varphi$), so we must have $\varphi \equiv \psi \pmod{\Gamma}$.
\\
\underline{Part 2:} same as part (1).
\\
\underline{Part 3:} suppose $\varphi \equiv \psi \pmod{\Gamma}$. By \hyperref[HPL-T-DN]{DN}, we get $\Gamma \vdash (\varphi \to \psi) \to (\neg \psi \to \neg \varphi)$ and $\Gamma \vdash (\psi \to \varphi) \to (\neg \varphi \to \neg \psi)$. Then apply \hyperref[HPL-R-MP]{MP}, we should get $\Gamma \vdash \neg \psi \to \neg \varphi$ and $\Gamma \vdash \neg \varphi \to \neg \psi$, or equivalently, $\neg \varphi \equiv \neg \psi \pmod{\Gamma}$.
\\
\\
Vice versa, suppose $\neg \varphi \equiv \neg \psi \pmod{\Gamma}$. With the same \hyperref[HPL-T-DN]{DN} (and some slice of \hyperref[HPL-R-MP]{MP}), it is then true that $\varphi \equiv \psi \pmod{\Gamma}$.
\end{proof}
\begin{remark}
A significance of this rule is that we can replace $\varphi$ with its double negation $\neg \neg \varphi$ at any point in the formula by repeated application of \hyperref[HPL-R-LS]{LS}, without changing syntactical meaning because of \hyperref[HPL-R-MP]{MP}.
\end{remark}
\begin{proposition}[Properties of Equivalence] \label{HPL-T-EQUIV} \
\begin{enumerate}
    \item Reflexivity: $\varphi \equiv \varphi \pmod{\Gamma}$
    \item Symmetry: if $\varphi \equiv \psi \pmod{\Gamma}$, then $\psi \equiv \varphi \pmod{\Gamma}$.
    \item Transitivity: if $\varphi \equiv \psi \pmod{\Gamma}$ and $\psi \equiv \xi \pmod{\Gamma}$, then $\varphi \equiv \xi \pmod{\Gamma}$.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} this follows from \hyperref[HPL-T-RX]{RX} and \hyperref[logic-proof-props]{Remark \ref*{logic-proof-props}}.
\\
\underline{Part 2:} this follows vacuously from the symmetry in the definition of $\varphi \equiv \psi \pmod{\Gamma}$.
\\
\underline{Part 3:} suppose $\varphi \equiv \psi \pmod{\Gamma}$ and $\psi \equiv \xi \pmod{\Gamma}$. In particular, $\Gamma \vdash \varphi \to \psi$ and $\Gamma \vdash \psi \to \xi$. But by \hyperref[HPL-T-HS]{HS}, $\Gamma \vdash (\varphi \to \psi) \to [(\psi \to \xi) \to (\varphi \to \xi)]$. We then apply \hyperref[HPL-R-MP]{MP} twice in order to get $\Gamma \vdash \varphi \to \xi$. By symmetry, we also get $\Gamma \vdash \xi \to \varphi$ similarly, so $\varphi \equiv \xi \pmod{\Gamma}$.
\end{proof}

\subsection{Additional Connectives}
Given wffs $\varphi$ and $\psi$, we can define a few more logical connectives
\begin{enumerate}
    \item Disjunction: $\varphi \vee \psi := \neg \varphi \to \psi$
    \item Conjunction: $\varphi \wedge \psi := \neg (\varphi \to \neg \psi)$
    \item Biconditional: $\varphi \leftrightarrow \psi := (\varphi \to \psi) \wedge (\psi \to \varphi) \equiv \neg [(\varphi \to \psi) \to \neg (\psi \to \varphi)]$
\end{enumerate}
The following propositions are left as an exercise (since we will not even refer to them explicitly most of the time, as long as they are tautological).
\begin{proposition}[Properties of logical connectives] \label{logic-propositional-properties}
Let $1$ denote any theorem in (propositional logic), and $0 \equiv \neg 1$ (note this does not depends on the choice of theorem because of \hyperref[prev-res-log-equiv]{Example \ref*{prev-res-log-equiv}})
\begin{enumerate}
    \item De Morgan law
    \begin{enumerate}
        \item $\neg(\varphi \wedge \psi) \equiv \neg \varphi \vee \neg \psi$
        \item $\neg(\varphi \vee \psi) \equiv \neg \varphi \wedge \neg \psi$
    \end{enumerate}
    \item Commutativity
    \begin{gather*}
        \varphi \wedge \psi \equiv \psi \wedge \varphi
        \\
        \varphi \vee \psi \equiv \psi \vee \varphi
    \end{gather*}
    \item Associativity
    \begin{gather*}
        (\varphi \wedge \psi) \wedge \xi \equiv \varphi \wedge (\psi \wedge \xi)
        \\
        (\varphi \vee \psi) \vee \xi \equiv \varphi \vee (\psi \vee \xi)
    \end{gather*}
    \item Identity: $\varphi \wedge 1 \equiv \varphi \vee 0 \equiv 1 \to \varphi \equiv \varphi$
    \item Idempotent: $\varphi \wedge \varphi \equiv \varphi \vee \varphi \equiv \varphi$
    \item Domination
    \begin{gather*}
        \varphi \wedge 0 \equiv 0
        \\
        \varphi \vee 1 \equiv 1
        \\
        \varphi \to 1 \equiv 0 \to \varphi \equiv 1
    \end{gather*}
    \item Distributivity
    \begin{gather*}
        (\varphi \wedge \psi) \vee \xi \equiv (\varphi \vee \xi) \wedge (\psi \vee \xi)
        \\
        (\varphi \vee \psi) \wedge \xi \equiv (\varphi \wedge \xi) \vee (\psi \wedge \xi)
    \end{gather*}
    \item Absorption: $\varphi \wedge (\varphi \vee \psi) \equiv \varphi \vee (\varphi \wedge \psi) \equiv \varphi$
    \item Complementary
    \begin{gather*}
        \varphi \wedge \neg \varphi \equiv 0
        \\
        \varphi \vee \neg \varphi \equiv 1
    \end{gather*}
    \item Material implication: $\varphi \to \psi \equiv \neg \varphi \vee \psi$
    \item Biconditionality: $\varphi \leftrightarrow \psi \equiv (\varphi \to \psi) \wedge (\psi \to \varphi) \equiv (\varphi \wedge \psi) \vee (\neg \varphi \wedge \neg \psi)$
    \item Implicative Negation: $\varphi \to 0 \equiv \neg \varphi$
    \item Left self-distributivity: $\varphi \to (\psi \to \xi) \equiv (\varphi \to \psi) \to (\varphi \to \xi)$
    \item Conditional distributivity
    \begin{gather*}
        (\varphi \wedge \psi) \to \xi \equiv (\varphi \to \xi) \vee (\psi \to \xi)
        \\
        (\varphi \vee \psi) \to \xi \equiv (\varphi \to \xi) \wedge (\psi \to \xi)
        \\
        \varphi \to (\psi \wedge \xi) \equiv (\varphi \to \psi) \wedge (\varphi \to \xi)
        \\
        \varphi \to (\psi \vee \xi) \equiv (\varphi \to \psi) \vee (\varphi \to \xi)
    \end{gather*}
\end{enumerate}
\underline{Note:} many authors, especially logicians, use $\bot$ for $0$ and $\top$ for $1$ instead.
\end{proposition}
\begin{remark}
Since associativity holds for both conjunction and disjunction, we usually remove parentheses and simply write $\varphi \wedge \psi \wedge \xi$ (and $\varphi \vee \psi \vee \xi$) without any ambiguity. There is also a general rule (albeit we will not use it liberally) for implication: we interpret $\varphi_1 \to \varphi_2 \to \cdots \to \varphi_n$ as $\varphi_1 \to (\varphi_2 \to (\cdots \to \varphi_n))$. This is called \emph{right-associativity}.
\end{remark}
\begin{proposition}[Laws of logic] \label{logic-propositional-laws} \ 
\begin{enumerate}
    \item Laws of identity: $\varphi \equiv \varphi$
    \item Law of excluded middle: $\varphi \vee \neg \varphi$
    \item Law of non-contradiction: $\neg(\varphi \wedge \neg \varphi)$
    \item Principle of explosion: $(\varphi \wedge \neg \varphi) \to \psi$
    \item Disjunctive introduction: $\varphi \to (\varphi \vee \psi)$
    \\
    Disjunctive syllogism: $\neg\varphi \to ((\varphi \vee \psi) \to \psi)$
    \item Conjunctive simplification: $(\varphi \wedge \psi) \to \varphi$
    \\
    Conjunctive introduction: $\varphi \to (\psi \to (\varphi \wedge \psi))$
    \item Reductio ad absurdum: $[(\varphi \to \psi) \wedge (\varphi \to \neg \psi)] \to \neg \varphi$
    \item Modus ponens: $[(\varphi \to \psi) \wedge \varphi] \to \psi$
    \item Modus tollens: $[(\varphi \to \psi) \wedge \neg \psi] \to \neg \varphi$
    \item Hypothetical syllogism: $[(\varphi \to \psi) \wedge (\psi \to \xi)] \to (\varphi \to \xi)$
    \item Disjunctive syllogism: $[(\varphi \vee \psi) \wedge \neg \varphi] \to \psi$
    \item Resolution: $[(\varphi \vee \psi) \wedge (\neg \varphi \vee \xi)] \to (\psi \vee \xi)$
    \item Exportation: $(\varphi \wedge \psi) \to \xi \equiv \varphi \to (\psi \to \xi)$
    \item Proof by case: $[(\varphi \vee \psi) \wedge (\varphi \to \xi) \wedge (\psi \to \xi)] \to \xi$
    \item Proof by contradiction: $[\neg \varphi \to (\psi \wedge \neg \psi)] \to \varphi$
    \item Gentzen's cut-elimination:
    \begin{align*}
        [(\varphi \to (\psi \wedge \xi)) \wedge ((\psi \wedge \chi) \to \gamma)] \to [(\varphi \wedge \chi) \to (\xi \wedge \gamma)]
    \end{align*}
\end{enumerate}
\end{proposition}

\newpage

\section{Predicate Logic}
\begin{shaded}
List of preliminary references:
\begin{enumerate}
    \item Herbert B. Enderton. \textit{A Mathematical Introduction to Logic}, 2nd edition (5 January 2001). Academic Press.
\end{enumerate}
\hrulefill
\end{shaded}
\subsection{Language}
The symbols $\Sigma$ of predicate logic consists of
\begin{enumerate}
    \item The countably infinite collection of \emph{variables} $\Sigma_V$: for examples, $x_1, x_2, \hdots$
    \item The collection of letters $\Sigma_A$, with each of them is associated with a counting number $n \geq 1$ called \emph{arity}, and each counting number is associated with countably infinitely many letters: say $\varphi_1, \varphi_2, \hdots$.
    \item The collection of parentheses $\Sigma_O$
    \item The collection of logical symbols $\Sigma_L = \{ \neg, \to, \forall \}$
\end{enumerate}
The language $L$ of predicate logic, consisting of well-formed formulas, is recursively constructed as follows
\begin{enumerate}
    \item If $\alpha \in \Sigma_A$ with arity $n$, and $x_1, x_2, \hdots, x_n$ are variables (possibly some of them are the same), then $\alpha(x_1, x_2, \hdots, x_n)$ is a wff. Such wff is called \emph{atomic}.
    \item If $\varphi$ is a wff, and $x$ is a variable, then $\forall x (\varphi)$ is a wff.
    \item If $\varphi$ is a wff, then $\neg (\varphi)$ is a wff.
    \item If $\varphi, \psi$ are wffs, then $(\varphi) \to (\psi)$ is a wff.
\end{enumerate}
Formulas that are not atomic (i.e. not of the form $\alpha(x_1, x_2, \hdots, x_n)$ where $\alpha \in \Sigma_A$ and $x_i \in \Sigma_V$) are called \emph{compound}.
\\
\underline{Note:} as usual, we can omit some parentheses (e.g. multiple $\neg$ and $\forall$ stacked consecutively) to reduce the accumulation of them.

\subsection{Free Variables}
Along with each wff $\varphi$, there are an additional collection associated with $\varphi$, $FV(\varphi)$, which contains \emph{free variables} in $\varphi$. It is defined inductively as follows
\begin{enumerate}
    \item If $\varphi := \alpha(x_1, x_2, \hdots, x_n)$ (where $\alpha \in \Sigma_A$), then $FV(\varphi) = \{ x_1, x_2, \hdots, x_n \}$.
    \item If $\varphi := \forall x (\lambda)$, then $FV(\varphi) = FV(\lambda) \setminus \{ x \}$ (i.e. the free variables of $\varphi$ are those of $\lambda$ except $x$).
    \item If $\varphi := \lambda \to \kappa$, then $FV(\varphi) = FV(\lambda) \cup FV(\kappa)$ (i.e. the free variables of $\varphi$ are exactly the ones of either $\lambda$ or $\kappa$).
    \item If $\varphi := \neg \lambda$, then $FV(\varphi) = FV(\lambda)$.
\end{enumerate}
From there, the \emph{arity} of a general expression $\varphi$ is defined as the cardinality of $FV(\varphi)$. In other words, the arity of $\varphi$ is exactly the number of free variables inside $\varphi$.
\\
\underline{Note:} this concept of arity for each wff is very similar yet different to the arity of each symbol inside $\Sigma_A$ (the symbol will become predicate/wff once we apply the correct number of variables to it!). They are the same, however, when considering atomic formulas.
\begin{example}
Suppose $\alpha, \beta, \lambda \in \sigma$ (we don't designate the arity and let the context sorts them out)
\begin{enumerate}
    \item $\varphi := \alpha(x, x, z) \wedge \forall w (\beta(x, y, w, w))$. The free variables are $x, y, z$, so the arity of $\varphi$ is $3$. Once the free variables are identified, we usually write $\varphi$ as $\varphi(x, y, z)$ for a clear view of what are the (free) variables that determines the truth value of $\varphi$ (the order of appearance may vary, but one needs to include all free variables).
    \begin{align*}
        \varphi(x, y, z) := \alpha(x, x, z) \wedge \forall w (\beta(x, y, w, w))
    \end{align*}
    \item $\varphi := \forall x (\alpha(x)) \wedge \forall x (\beta(x, y)) \wedge \forall z \forall y (\lambda(y, z, x))$. Even though we use the same variable for different context/scope, following the inductive rules above, it should be clear that $FV(\varphi) = \{ x, y \}$ and $BV(\varphi) = \varnothing$.
    \begin{align*}
        \varphi(x, y) := \forall x (\alpha(x)) \wedge \forall x (\beta(x, y)) \wedge \forall z \forall y (\lambda(y, z, x))
    \end{align*}
    \item $\varphi := \forall y \forall z \forall x \forall w (\alpha(x, z, t, w, s, y))$. Here, $FV(\varphi) = \{ t, s \}$ and $BV(\varphi) = \{  x, y, z, w \}$
    \begin{align*}
        \varphi(t, s) := \forall y \forall z \forall x \forall w (\alpha(x, z, t, w, s, y))
    \end{align*}
\end{enumerate}
\end{example}
If a wff has arity of $0$ (i.e. no free variable), we call it a \emph{sentence}.

\subsection{Substitution}
The \emph{substitution} of a variable $y$ of $\varphi$ (which may not even occur in the formula) for $t$, written $\varphi[y := t]$, is defined inductively as follows
\begin{enumerate}
    \item If $\varphi := \alpha(x_1, \hdots, x_i, y, x_{i + 1}, \hdots, x_n)$ is an atomic predicate, then $\varphi[y := t] := \alpha(x_1, \hdots, x_i, t, x_{i + 1}, \hdots, x_n)$. Otherwise, if $\varphi := \alpha(x_1, \hdots, x_n)$ such that $y$ is distinct from $x_i$, then $\varphi[y := t] := \varphi$ simply.
    \item If $\varphi := \forall x (\lambda)$, then
    \begin{enumerate}
        \item $\varphi[y := t] := \varphi$, given $y = x$.
        \item $\varphi[y := t] := \forall x (\lambda[y := t])$, given $y \neq x$.
    \end{enumerate}
    \item If $\varphi := \lambda \to \kappa$, then $\varphi[y := t] := \lambda[y := t] \to \kappa [y := t]$.
    \item If $\varphi := \neg\lambda$, then $\varphi[y := t] := \neg(\lambda[y := t])$.
\end{enumerate}
\begin{remark} \ 
\begin{enumerate}
    \item $\varphi[y := t]$ is always a well-formed formula.
    \item $\varphi[y := y] = \varphi$, i.e. the substitution of $y$ for the same variable will not affect the formula.
    \item $\varphi[y := t] = \varphi$, given $y$ is not free in $\varphi$. In other words, substitution of a non-free variable will not affect the formula.
    \item After substitution, the free variables should be
    \begin{enumerate}
        \item If $y \notin FV(\varphi)$, then $FV(\varphi[y := t]) = FV(\varphi)$. This follows from the previous point.
        \item If $\varphi := \alpha(x_1, \hdots, x_i, y, x_{i + 1}, \hdots, x_n)$, then
        \begin{align*}
            FV(\varphi[y := t]) = \{ x_1, \hdots, x_i, t, x_{i + 1}, \hdots, x_n \} = (FV(\varphi) \setminus \{ y \}) \cup \{ t \}
        \end{align*}
        \item If $\varphi := \forall x (\lambda)$, $FV(\varphi[y := t]) = FV(\lambda[y := t]) \setminus \{ x \}$
        \item If $\varphi := \lambda \to \kappa$, then $FV(\varphi[y := t]) = FV(\lambda[y := t]) \cup FV(\kappa [y := t])$.
        \item If $\varphi := \neg\lambda$, then $FV(\varphi[y := t]) = FV(\lambda[y := t])$.
    \end{enumerate}
\end{enumerate}
\end{remark}
\ \\
There can be a downside to arbitrary substitution, however. Take $\varphi(y) := \neg \forall t (y = t)$, for example. The sentence $\forall y (\varphi(y))$ (i.e. for all $y$, there exists $t$ such that $y \neq t$) is valid when it is interpreted in a model with at least 2 elements. However, a particular instance of it, $\varphi(t) = \neg \forall t (t = t)$, is not valid in any structure since it says that there exists $t$ such that $t \neq t$. This is due to the substituted variable (which is $t$) is captured immediately by quantifier, so in a way, $t$ is not \textit{substitutable} for $y$ in $\varphi$.
\\
\\
In general, given a wff $\varphi$ and variables $y, t$, we say that $t$ is \emph{substitutable} for $y$ in $\varphi$ if, inductively,
\begin{enumerate}
    \item If $\varphi$ is atomic, then $t$ is always substitutable for $y$ (even when $y$ is not free in $\varphi$).
    \item If $\varphi := \forall x (\lambda)$, then $t$ is substitutable for $y$ if either
    \begin{enumerate}
        \item $y$ does not occur free in $\varphi$ (or $\forall x (\lambda)$).
        \item $t \neq x$ and $t$ is substitutable for $y$ in $\lambda$.
    \end{enumerate}
    \item If $\varphi := \neg \lambda$, then $t$ is substitutable for $y$ in $\varphi$ if and only if it is substitutable in $\lambda$.
    \item If $\varphi := \lambda \to \kappa$, then $t$ is substitutable for $y$ in $\varphi$ if and only if it is substitutable in both $\lambda$ and $\kappa$.
\end{enumerate}

\subsection{Hilbert system}
The Hilbert system (for predicate logic) is a deductive system such that
\begin{enumerate}
    \item Given wffs $\alpha, \beta, \gamma$, the followings are axioms (for propositional part):
    \begin{enumerate}
        \item[(IP1)] \label{EHPRL-A-IP1} $\alpha \to (\beta \to \alpha)$
        \item[(IP2)] \label{EHPRL-A-IP2} $[\alpha \to (\beta \to \gamma)] \to [(\alpha \to \beta) \to (\alpha \to \gamma)]$
        \item[(PNC)] \label{EHPRL-A-PNC} $(\neg \alpha \to \neg \beta) \to [(\neg \alpha \to \beta) \to \alpha]$
    \end{enumerate}
    \item Given variables $x, t$ and wffs $\alpha, \beta$, the followings are axioms (for quantified part):
    \begin{enumerate}
        \item[(UE)] \label{EHPRL-A-UE} $\forall x (\alpha) \to \alpha[x := t]$, as long as $t$ is substitutable for $x$ in $\alpha$.
        \item[(UI)] \label{EHPRL-A-UI} $\forall x (\alpha \to \beta) \to [\forall x (\alpha) \to \forall x (\beta)]$.
        \item[(UG)] \label{EHPRL-A-UG} $\alpha \to \forall x (\alpha)$, given $x$ is not free in $\alpha$.
    \end{enumerate}
    \item (GR) \label{EHPRL-A-GR} $\forall x (\alpha)$ is an axiom whenever $\alpha$ is an axiom and $x$ is a variable.
    \item (MP) \label{EHPRL-R-MP} Modus ponens hold, i.e. $\alpha, \alpha \to \beta \vdash \beta$ given wffs $\alpha$ and $\beta$.
\end{enumerate}
Since it contains axioms (and reference rule) of propositional logic, everything from previous section still holds here, and that includes the truth table method: if a formula is a tautology, then it is a theorem. The atomic formulas in predicate logic served the same role as the atomic formulas in propositional logic.
\begin{shaded}	
\begin{lemma}
Suppose $\varphi \equiv \psi \pmod{\Gamma}$, then we have the following
\begin{enumerate}
    \item $\varphi[x := t] \equiv \psi[x := t] \pmod{\Gamma}$, where $x$ is not free in $\Gamma$.
    \item $t$ is substitutable for $x$ in $\varphi$ if and only if it is substitutable for $x$ in $\psi$, given $x$ is not free in $\Gamma$.
    \item $FV(\varphi) \setminus \bigcup_{\lambda \in \Gamma} FV(\lambda) = FV(\psi) \setminus \bigcup_{\lambda \in \Gamma} FV(\lambda)$.
\end{enumerate}
\end{lemma}
\begin{proof}
\underline{Part 1:} since $\Gamma \vdash \varphi \to \psi$,
\end{proof}
\ \\
\begin{theorem} \ 
\begin{enumerate}
    \item If $\Gamma \vdash \varphi$, and $x$ is a variable that is not free in any formula belong to $\Gamma$, then $\Gamma \vdash \forall x (\varphi)$.
    \item If $\Gamma \vdash \varphi$, and $x$ is a variable that is not free in $\Gamma$, then there exists a variable $t$ not free in $\varphi$ such that $\Gamma \vdash \forall t (\varphi[x := t])$.
    \item If $\Gamma, \varphi[x := t] \vdash \psi$, and $t$ is not free in $\varphi, \psi, \Gamma$, then $\Gamma, \exists x (\varphi) \vdash \psi$.
    \\
    \item If $\varphi \equiv \psi \pmod{\Gamma}$, and $x$ is a variable that is not free in $\Gamma$, then $\forall x (\varphi) \equiv \forall x (\psi)
 \pmod{\Gamma}$.
    \\
    \item If $t$ is not free while substitutable for $x$ in $\varphi$,  then $\forall x (\varphi) \equiv \forall t (\varphi[x := t])$.
    \item Let $\varphi$ be a wff, $x, t$ are variables, then there exists another formula $\varphi'$ such that $\varphi \equiv \varphi'$ and $t$ is substitutable for $x$ in $\varphi'$.
\end{enumerate}
\end{theorem}
\begin{example}
$$\exists e \forall x (xe = x), \exists f \forall x (fx = x) \vdash \exists h \forall x (xh = hx = x)$$
\begin{enumerate}
    \item By universal instantiation,
\end{enumerate}
\end{example}

\subsection{Vectorial Notation}
If $\varphi$ is a wff, and $x_1, \hdots, x_n$ are its free variable, then we can shorten $\varphi(x_1, \hdots, x_n)$ into $\varphi(\vec{x})$ using vectorial notation (where $\vec{x} := (x_1, \hdots, x_n)$).
\\
\\
Similarly, if we have a consecutive sequence of universal quantification, or existential quantification, we can abbreviate them too! Given $\vec{x} = (x_1, \hdots, x_n)$, then
\begin{align*}
    \forall \vec{x} (\varphi) & := \forall x_1 \hdots \forall x_n (\varphi)
    \\
    \exists \vec{x} (\varphi) & := \exists x_1 \hdots \exists x_n (\varphi)
    \\
    & \equiv \neg \forall x_1 \hdots \forall x_n (\neg \varphi) \equiv \neg \forall \vec{x} (\neg \varphi)
\end{align*}

\subsection{Some important metatheorems (draft)}
\begin{theorem} \ 
\begin{enumerate}
	\item Universal Generalization: if $\Gamma, \varphi \vdash \psi$, and $x$ is free in $\Gamma$, then $\Gamma, \forall x (\varphi) \vdash \forall x (\psi)$.
	\item Existential Generalization: if $\Gamma, \varphi \vdash \psi$, and $x$ is free in $\Gamma$, then $\Gamma, \exists x (\varphi) \vdash \exists x (\psi)$.
	\item Quantifier Elimination: if $x$ is not free in $\varphi$, then $\forall x (\varphi) \vdash \varphi$ and $\exists x (\varphi)  \vdash \varphi$.
	\item Change of variable: if $w$ is a variable different from $x$ that is not free in $\Gamma$ and $\varphi$, then
	\begin{enumerate}
		\item $\Gamma \vdash \forall w (\varphi[x := w])$ whenever $\Gamma \vdash \forall x (\varphi)$.
		\item $\Gamma \vdash \exists w (\varphi[x := w])$ whenever $\Gamma \vdash \exists x (\varphi)$.
	\end{enumerate}
\end{enumerate}
\end{theorem}

\newpage

\section{First-order logic}
\subsection{Translation of function symbols}
\subsection{The problem of empty domain}
\subsection{Functions}
A predicate $\varphi$ depending on 2 tuples $\mathbf{x}$ (of size $n$) and $\mathbf{y}$ (of size $m$) is said to be
\begin{enumerate}
    \item \textit{\textbf{Exact}} if
    \begin{gather*}
        \forall \mathbf{x} \forall \mathbf{y} \forall \mathbf{z} \left[ \left( \varphi(\mathbf{x}, \mathbf{y}) \wedge \varphi(\mathbf{x}, \mathbf{z}) \right) \rightarrow \mathbf{y} = \mathbf{z} \right]
    \end{gather*}
    with tuples of appropriate size so that the expression makes sense.
    \item \textit{\textbf{Total}} if
    \begin{gather*}
        \forall \mathbf{x} \exists \mathbf{y} (\varphi(\mathbf{x}, \mathbf{y}))
    \end{gather*}
\end{enumerate}
\ \\
We say $\varphi$ is
\begin{enumerate}
    \item A \textit{\textbf{function}} (in $n$-variable returning $m$-values) if it is exact and total.
    \begin{gather*}
        \forall \mathbf{x} \exists! \mathbf{y} (\varphi(\mathbf{x}, \mathbf{y}))
    \end{gather*}
    The tuple $\mathbf{x}$ is called the \textbf{\textit{input}}, while $\mathbf{y}$ is called the \textit{\textbf{output}}
    \item A \textit{\textbf{partial function}} if the totality condition is dropped.
    \item A \textit{\textbf{multivalued function}} if the exactness condition is dropped.
\end{enumerate}
\ \\
Given a function $\varphi$, we say that $\mathbf{x}$ is mapped to $\mathbf{y}$ if $\varphi(\mathbf{x}, \mathbf{y})$ holds. Taking some random letter, say $f$, and write $f(\mathbf{x})$ to denote the unique tuple $\mathbf{y}$ that is mapped to $\mathbf{x}$. In other words,
\begin{gather*}
    \mathbf{y} = f(\mathbf{x}) := \varphi(\mathbf{x}, \mathbf{y})
\end{gather*}
Using substitution, $\varphi(\mathbf{x}, f(\mathbf{x}))$ is always true.
\\
\\
With such notation, we can ``substitute'' functions into other predicate or even functions by the following interpretation
\begin{enumerate}
    \item Let say $\varphi(\mathbf{y})$ is a predicate, $\psi(\mathbf{x}, \mathbf{y})$ is a function with associated letter $g$ (i.e. $\psi(\mathbf{x}, g(\mathbf{x}))$ always hold). Then
    \begin{gather*}
        \varphi(f(\mathbf{x})) := \exists \mathbf{y} \left( \varphi(\mathbf{y}) \wedge \psi(\mathbf{x}, \mathbf{y}) \right)
    \end{gather*}
    \item On the other hand, let $\varphi(\mathbf{x}, \mathbf{y})$ and $\psi(\mathbf{y}, \mathbf{z})$ be functions such that the size of output of $\varphi$ is the same as that of the input of $\psi$ (hence the matching letter). If $f, g$ are the functional symbols associated with $\varphi, \psi$ respectively, then the predicate
    \begin{gather*}
        \mathbf{z} = g(f(\mathbf{x})) := \exists \mathbf{y} \left( \varphi(\mathbf{x}, \mathbf{y}) \wedge \psi(\mathbf{y}, \mathbf{z}) \right)
    \end{gather*}
    is associated with $g \circ f$, i.e. $g \circ f(\mathbf{x})$ is the same as $g(f(\mathbf{x}))$.
\end{enumerate}
\ \\
\underline{Note:} as exactness and totality conditions are propositions, one must add them as axioms in order to guarantee that a predicate is a function.

\subsection{Constants}
A special case of function is when the input is of size $0$. The condition $\forall \mathbf{x} \exists! \mathbf{y} (\varphi(\mathbf{x}, \mathbf{y}))$ just drop to $\exists! \mathbf{y} (\varphi(\mathbf{y}))$. Such predicate is called \textit{\textbf{constant}}.
\\
\\
Taking another random letter, like $\mathbf{c}$ to associate $\varphi$, i.e. $\varphi(\mathbf{c})$ is true. Similarly, we can also ``substitute'' constants into predicates and functions as follows
\begin{enumerate}
    \item Let say $\mathbf{c}$ is a constant associated with a predicate $\psi(\mathbf{x})$, and $\varphi(\mathbf{x})$ is another predicate with the same arity as $\psi$. Then
    \begin{align*}
        \psi(\mathbf{c}) := \exists \mathbf{x} \left( \psi(\mathbf{x}) \wedge \varphi(\mathbf{x}) \right)
    \end{align*}
    \item Again, $\mathbf{c}$ is a constant associated with a predicate $\psi(\mathbf{x})$, and $\varphi(\mathbf{x}, \mathbf{y})$ is a function with associated symbol $f$. Then
    \begin{align*}
        \mathbf{y} = f(\mathbf{c}) := \exists \mathbf{x} \left( \psi(\mathbf{x}) \wedge \varphi(\mathbf{x}, \mathbf{y}) \right)
    \end{align*}
\end{enumerate}
\end{shaded}

\newpage
\newpage

\begin{shaded}
\chapter{Axiomatic Set Theory}
\section{Zermelo-Frankael set theory with Axiom of Choice (ZFC)}
\begin{proposition}
$\left(\prod_{i \in I} A_i \right) \cap \left( \prod_{i \in I} B_i \right) = \prod_{i \in I} (A_i \cap B_i)$
\end{proposition}
\begin{proposition}[Commutativity of Cartesian product]
Let $\{ S_i \}_{i \in I}$ be a family of sets. If $\pi$ is a permutation on the index set $I$, there is a natural bijection  between $\prod_{i \in I} S_i$ and $\prod_{i \in I} S_{\pi(i)}$.
\end{proposition}
\begin{proposition}[Associativity of Cartesian product]
Let $\{ \{ S_i \}_{i \in I_\alpha} \}_{\alpha \in A}$ be a family of families of sets. Show that there is natural bijection between $\prod_{\alpha \in A} \prod_{i \in I_\alpha} S_i$ and $\prod_{(i, \alpha) \in \coprod_{\alpha \in A} I_\alpha} S_{i, \alpha}$
\end{proposition}

\section{Powered Cofinality}
\begin{enumerate}
	\item The \emph{$\lambda$-summatory cofinality} of $\kappa$ is defined as $\operatorname{scf}_\lambda \kappa = \sup \{ \sum_{i \in I} \kappa_i : \kappa_i < \kappa, |I| < \lambda \}$
	\item The \emph{$\lambda$-powered cofinality} of $\kappa$ is defined as $\operatorname{pcf}_\lambda \kappa = \sup \{ \prod_{i \in I} \kappa_i : \kappa_i < \kappa, |I| < \lambda \}$
\end{enumerate}

\section{Lattice operations on collection}
Let $S$ be a set, $C$ be a class (of sets), and $\mathcal{A}, \mathcal{B}$ be families of subsets in $S$.
\begin{enumerate}
    \item $\mathcal{A}_C^{\vee} = \{ \bigcup \mathcal{F} : \mathcal{F} \subseteq \mathcal{A}, \mathcal{F} \in C \}$
    \item $\mathcal{A}_C^{\wedge} = \{ \bigcap \mathcal{F} : \mathcal{F} \subseteq \mathcal{A}, \mathcal{F} \in C \}$
    \item $C_{\mathcal{A}}(\mathcal{B}) = \{ A \setminus B : A \in \mathcal{A}, B \in \mathcal{B} \}$.
\end{enumerate}
If
\begin{enumerate}
    \item $C = V$ is the von Neumann universe, we denote $\mathcal{A}^\vee := \mathcal{A}_V^\vee$ and $\mathcal{A}^\wedge := \mathcal{A}_V^\wedge$.
    \item If $C = V_{< \kappa}$ is the class of sets with cardinality less than $\kappa$, we denote
    $\mathcal{A}_{< \kappa}^\vee := \mathcal{A}_C^\vee$ and $\mathcal{A}_{< \kappa}^\wedge := \mathcal{A}_C^\wedge$.
\end{enumerate}
\begin{proposition} \ 
\begin{enumerate}
    \item If $C$ contains all singletons, then $\mathcal{A}$ is a sub-collection of $\mathcal{A}_C^{\vee}$ and $\mathcal{A}_C^{\wedge}$.
    \item If $C$ contains empty set, then $\varnothing \in \mathcal{A}_C^{\vee}$, and $S \in \mathcal{A}_C^{\wedge}$
\end{enumerate}
\end{proposition}
If
\begin{enumerate}
    \item $\mathcal{A}_C^{\vee} = \mathcal{A}$, we say $\mathcal{A}$ is closed under $C$-union.
    \item $\mathcal{A}_C^{\wedge} = \mathcal{A}$, we say $\mathcal{A}$ is closed under $C$-intersection.
    \item $S \setminus \mathcal{A} = \mathcal{A}$, we say $\mathcal{A}$ is closed under complementary
\end{enumerate}
\begin{example} \ 
\begin{enumerate}
    \item A topology $\mathcal{T}$ on a set $X$ is a collection containing the empty set and $X$, and satisfy $\mathcal{T}^{\vee} = \mathcal{T}$, $\mathcal{T}_{< \aleph_0}^{\wedge} = \mathcal{T}$.
\end{enumerate}
\end{example}

\section{Transfinite Lattice}
Let $X$ be a set, $\mathcal{A}$ be a family of subsets of $X$. We say $\mathcal{A}$ is a $(\kappa, \lambda)$-lattice if
\begin{enumerate}
	\item It is closed under $<\kappa$-union: $\bigcup_{i \in I} S_i \in \mathcal{A}$ whenever $S_i \in \mathcal{A}$ and $|I| < \kappa$.
	\item It is closed under $<\lambda$-intersection: $\bigcup_{i \in I} S_i \in \mathcal{A}$ whenever $S_i \in \mathcal{A}$ and $|I| < \kappa$.
\end{enumerate}
When $\kappa = \infty$, we allow arbitrary union, and say $\mathcal{A}$ is a $\lambda$-meet lattice. When $\lambda = \infty$, we allow arbitrary intersection, and say $\mathcal{A}$ is a $\kappa$-join lattice.
\begin{example} \ 
\begin{enumerate}
	\item A topological space is $\aleph_0$-meet lattice.
	\item A $\sigma$-algebra is an $\aleph_1$-lattice.
\end{enumerate}
\end{example}

\section{Order Theory}
\begin{theorem}
The cofinality of a totally ordered set exists.
\end{theorem}
\begin{theorem}[Monad of Ultrafilters]
For each $\mathfrak{F} \in \beta \beta X$, the collection $\mathcal{F} = \{ A : [A] \in \mathfrak{F} \}$ is an ultrafilter.
\end{theorem}

\section{Class Induction}
\begin{theorem}
Given a unary class function $\alpha$, show that
$$\forall F [F \neq \emptyset \rightarrow \exists B (F \subseteq B \wedge \forall x \in B (\alpha(x) \in B))]$$
Meaning, for each non-empty set $F$, there exists another set $B$ containing it and closed under $\alpha$ operation.
\end{theorem}
\begin{proof}
Define the Godel beta formula
$$\beta(n, C) := \exists M \exists f [(f: (n + 1) \times F \to M \mbox{ is a function}) \wedge \forall x \in F (f(0, x) = x) \wedge \forall m < n, \forall x \in F (f(m + 1, x) = \alpha(f(m, x))) \wedge C = f((n + 1) \times F)]$$
\end{proof}
\begin{corollary}
If $\alpha_1, \alpha_2, \hdots, \alpha_n$ are class functions, then
$$\forall F [F \neq \emptyset \to \exists B [F \subseteq B \wedge \forall \vec{x}_1 \in B(\alpha_1 (\vec{x}_1)) \wedge \cdots \wedge \forall \vec{x}_n \in B(\alpha_1 (\vec{x}_n))]]$$
\end{corollary}
\begin{corollary}
If $\{ \alpha_x \}_{x \in X}$ is a family of class functions (i.e. a formula $\varphi$ such that $\alpha_x(y) = z$ iff $\varphi(x, y, z)$ holds)
$$\forall F [F \neq \emptyset \to \exists B [F \subseteq B \wedge \forall x \in X, \forall y \in B, \forall z (\varphi (x, y, z) \leftrightarrow z \in B)]$$
\end{corollary}

\end{shaded}

\newpage
\newpage

\begin{shaded}
\chapter{Category Theory I}

[Reference: \href{https://math.stackexchange.com/questions/2663526/any-regular-mono-is-extremal}{Any regular mono is extremal}]
\end{shaded}

\newpage
\newpage

\chapter{General Topology I}
Any things we say will be applicable under ZFC, but we will always put a note after each theorem to clarify which axiom we need (in addition to ZF).
\section{Axiom}
A \emph{topology} $\mathcal{T}$ on a set $X$ is a collection of subsets of $X$ (i.e. $\mathcal{T} \subseteq \mathcal{P}(X)$) such that
\begin{enumerate}
    \item It contains the empty set and $X$.
    \item It is closed under arbitrary union: for any subcollection $\mathcal{S}$ of $\mathcal{T}$, we have $\bigcup \mathcal{S} \in \mathcal{T}$.
    \item It is closed under finite intersection: for any $A, B \in \mathcal{T}$, we have $A \cap B \in \mathcal{T}$.
\end{enumerate}
Such pair $(X, \mathcal{T})$ is then called a \emph{topological space} (or space), which can be abbreviated to just $X$.

\subsection{Open set - Closed set}
Any set in $\mathcal{T}$ is called an \emph{open} set, and any set that is the complement of an open set is called a \emph{closed} set.
\begin{remark}
The door (being either open or closed) analogy will not work here, as there are sets that are both open and closed, called \emph{clopen}. These include the empty set and the space $X$ itself.
\end{remark}
\begin{lemma} \label{clopen-complement}
If $U$ is open and $C$ is closed, then $U \setminus C$ is open, while $C \setminus U$ is closed.
\end{lemma}
\begin{proof}
These properties follow from $U \setminus C = U \cap (X \setminus C)$ and $C \setminus U = C \cap (X \setminus U)$
\end{proof}
\begin{theorem}[Topology in terms of closed sets] \label{equiv-topo-closed-set}
From a topology $\mathcal{T}$ on $X$, we can defined $X \setminus \mathcal{T}$ as the collection of closed sets in $X$. It satisfies the following properties:
\begin{enumerate}
    \item It contains the empty set and $X$.
    \item It is closed under arbitrary \textit{intersection}: for any subcollection $\mathcal{S}$ of $\mathcal{T}$, we have $\bigcap \mathcal{S} \in \mathcal{T}$.
    \item It is closed under finite union: for any $A, B \in \mathcal{T}$, we have $A \cup B \in \mathcal{T}$.
\end{enumerate}
Vice versa, Given any collection $\mathcal{L}$ of subsets of $X$ satisfying the 3 above properties, then $\mathcal{T} = \{ X \setminus C : C \in \mathcal{L} \}$ is a topology on $X$, and the closed sets (with respect to $\mathcal{T}$) coincide with those in $\mathcal{L}$, i.e. $\mathcal{L} = X \setminus \mathcal{T}$
\end{theorem}
\begin{example}
There are few distinguished example of topologies on a set $X$
\begin{enumerate}
    \item The \emph{discrete topology} $\mathcal{T} = \mathcal{P}(X)$, where every subset is both open and closed.
    \item The \emph{indiscrete topology} $\mathcal{T} = \{ \varnothing, X \}$, where the only open sets are exactly those in 1st condition. It is straightforward to see that any topology must contain the indiscrete topology.
    \item For an infinite cardinal $\kappa$, the \emph{co-$\kappa$ topology} $\mathcal{T} = \{ U \subseteq X : U = \varnothing \mbox{ or } |X \setminus U| < \kappa \}$ where the closed sets are either $X$ or has cardinality smaller than $\kappa$.
    \begin{enumerate}
        \item If $\kappa = \aleph_0$, we call it the \emph{cofinite topology}. The closed sets in this space are either $X$ or has finite number of elements.
        \item If $\kappa = \aleph_1$, we call it the \emph{cocountable topology}. The closed sets in this space are either $X$ or has countable number of elements.
    \end{enumerate}
\end{enumerate}
\end{example}
\begin{proof}\ \\
\underline{Part 1:} result from the fact that union and intersection of subsets of $X$ are still subsets of $X$.
\\
\underline{Part 2:} any family of sets in $\mathcal{T}$ can only contain either $X$ or $\varnothing$ (or both), so we only need to verify that $X \cup \varnothing = X$ and $X \cap \varnothing = \varnothing$ are open.
\\
\underline{Part 3:} since we can formulate topology in terms of closed sets by \hyperref[equiv-topo-closed-set]{Theorem \ref*{equiv-topo-closed-set}}, we can verify those conditions for closed sets (which is considerably easier). Additionally, we can consider sets that are not $X$ itself, since union of sets with $X$ is $X$ itself, and the intersection of sets with $X$ is just the same intersection (both are closed, assuming we can show them so!).
\\
\\
Let $\{ C_i \}_{i \in I}$ be an arbitrary family of closed set. Then $|C_i| < \kappa$ for each $i \in I$, so $|\bigcap_{i \in I} C_i| \leq |C_i| < \kappa$, i.e. $\bigcap_{i \in I} C_i$ is closed. On the other hand, if $K$ and $L$ are closed, then by cardinal arithmetic, we get $|K \cup L| \leq |K| + |L| < \kappa + \kappa = \kappa$, i.e. $K \cup L$ is closed.
\end{proof}
\begin{proposition}
If $\kappa > |X|$, then the co-$\kappa$ topology on $X$ is the same as the discrete topology. The vice versa also holds. Thus, in particular,
\begin{enumerate}
    \item The cofinite topology on a finite set is discrete, while it is not on infinite set.
    \item The cocountable topology on a countable set is discrete, while it is not on uncountable set, say $\omega_1$ or $\mathbb{R}$.
\end{enumerate}
\end{proposition}
\begin{proof}
Suppose $\kappa > |X|$, then any subset $A$ is closed, as $|A| \leq |X| < \kappa$. Vice versa, suppose every subset of $X$ is closed under co-$\kappa$ topology. If $X$ is finite, then $\kappa \geq \aleph_0 > |X|$. If $X$ is infinite, then there exists a proper subset $S$ of $X$ such that $|X| = |S|$. This means that $|S| < \kappa$, and so $|X| < \kappa$.
\end{proof}
\underline{Proof Note:} we need ``infinite = Dedekind-infinite'' (or equivalently, if $X$ is infinite, then $|X| \geq \aleph_0$).

\subsection{Comparison of topologies}
We denote the collection of topologies on $X$ as $\mathrm{Top}(X)$
\begin{proposition}
$\mathrm{Top}(X)$ forms a complete lattice under inclusion
\begin{enumerate}
    \item The meet of topologies are just their intersection
    \begin{align*}
        \bigwedge \mathfrak{U} = \bigcap \mathfrak{U}
    \end{align*}
    \item The join of topologies are the intersection of all topologies containing their union
    \begin{align*}
        \bigvee \mathfrak{U} = \bigcap_{\bigcup \mathfrak{U} \subseteq \mathcal{T}} \mathcal{T}
    \end{align*}
    \item Additionally, given a collection $\mathcal{A}$ of subsets of $X$, there is a smallest topology containing $\mathcal{A}$, called the topology \emph{generated} by $\mathcal{A}$.
\end{enumerate}
\end{proposition}
\begin{proof}
Let $\mathfrak{U}$ be a collection of topologies on $X$.
\begin{enumerate}
    \item Meet: since $\varnothing, X \in \mathcal{T}$ for any topology, we have $\varnothing, X \in \bigcap \mathfrak{U}$. On the other hand,
    \begin{enumerate}
        \item If $\{ V_i \}_{i \in I}$ is a family of sets in $\bigcap \mathfrak{U}$, then $V_i \in \mathcal{T}$ for all $\mathcal{T} \in \mathfrak{U}$. Thus, $\bigcup_{i \in I} V_i \in \mathcal{T}$ for all $\mathcal{T} \in \mathfrak{U}$, and so $\bigcup_{i \in I} V_i \in \bigcap \mathfrak{U}$.
        \item If $P, Q \in \mathfrak{U}$, then $P, Q \in \mathcal{T}$ for any $\mathcal{T} \in \mathfrak{U}$. Hence, $P \cap Q \in \mathcal{T}$, and so $P \cap Q \in \bigcap \mathfrak{U}$.
    \end{enumerate}
    \item Join: note that $\mathrm{Top}(X)$ is a Dedekind-complete meet-semilattice with a top element - the discrete topology. This automatically makes it into a complete lattice with $\bigvee \mathfrak{U} = \bigwedge \{ \mathcal{T} : \mathcal{T} \supseteq \mathcal{S} \mbox{ for all } \mathcal{S} \in \mathfrak{U} \} = \bigcap_{\bigcup \mathfrak{U} \subseteq \mathcal{T}} \mathcal{T}$.
    \item Given $\mathcal{A} \subseteq \mathcal{P}(X)$, the intersection $\bigcap_{\mathcal{A} \subseteq \mathcal{T}} \mathcal{T}$ is non-empty and forms a topology on $X$. This is, by construction, the smallest topology containing $\mathcal{A}$ (note the intersection).
\end{enumerate}
\end{proof}
Given 2 topologies $\mathcal{T}_1$ and $\mathcal{T}_2$ on $X$, if $\mathcal{T}_1 \subseteq \mathcal{T}_2$, we say that $\mathcal{T}_1$ is \emph{coarser} than $\mathcal{T}_2$, or $\mathcal{T}_2$ is \emph{finer} than $\mathcal{T}_1$.
\begin{lemma} \label{topo-compare-closed-set}
$\mathcal{T}_1$ is coarser than $\mathcal{T}_2$ if and only if $X \setminus \mathcal{T}_1 \subseteq X \setminus \mathcal{T}_2$.
\end{lemma}
\begin{proof}
Suppose $\mathcal{T}_1$ is coarser than $\mathcal{T}_2$. Let $C$ be a closed set with respect to $\mathcal{T}_1$, then $X \setminus C \in \mathcal{T}_1$, and so $X \setminus C \in \mathcal{T}_2$. In other words, $C$ is closed with respect to $\mathcal{T}_2$.
\\
*Vice versa, suppose any closed set under $\mathcal{T}_1$ is also closed under $\mathcal{T}_2$. Let $U$ be an open set under $\mathcal{T}_1$, then $X \setminus U \in X \setminus \mathcal{T}_1 \subseteq X \setminus \mathcal{T}_2$. Therefore, $U$ is open under $\mathcal{T}_2$.
\end{proof}
\begin{proposition} \label{co-kappa-compare}
If $\mathcal{T}_n$ denote the co-$\kappa_n$ topology ($n = 1, 2$), and $\kappa_1 \leq \kappa_2$. Then $\mathcal{T}_1$ is coarser than $\mathcal{T}_2$.
\end{proposition}
\begin{proof}
By the previous \hyperref[topo-compare-closed-set]{Lemma \ref*{topo-compare-closed-set}}, we can instead verify the coarseness on closed sets. If $C \neq X$ is closed under co-$\kappa_1$ topology, then $|C| < \kappa_1 \leq \kappa_2$. We conclude $C$ is also closed under co-$\kappa_2$ topology.
\end{proof}

\newpage

\section{Neighborhood. Basis}
Given a space $X$, a subset $N$ of $X$ is said to be a \emph{neighborhood} around a point $p$ in $X$ (i.e. $p \in X$) if it contains an open set $U$ (not necessarily distinct from $N$) such that $x \in U$.
\begin{remark} \label{neighborhood-simple-facts} \ 
\begin{enumerate}
    \item If $N$ is a neighborhood around any point $p$ of a certain subset $S$, then there exists an open set $U$ such that $S \subseteq U \subseteq N$. The converse holds trivially.
    \\
    \\
    We say that $N$ is a neighborhood around $S$ (so this definition generalizes the one at the beginning).
    \item A set is open if and only if it is a neighborhood of each point in it.
\end{enumerate}
\end{remark}
\begin{proof} \ \\
\underline{Part 1:} let $V$ be the union of all open sets contained in $N$. In particular, $V$ is an open neighborhood of each point $p$ in $S$, and $V \subseteq N$. Since $N$ is an open neighborhood of $S$, for each $p \in S$, there exists some open set $U_p$ such that $p \in U_p \subseteq N$. By definition, $U_p \subseteq V$. Hence, $p \in V$ for all $p \in S$, and so $S \subseteq V$.
\\
\\
\underline{Part 2:} suppose $U$ is open, then it is trivially a neighborhood of each point in it. Vice versa, suppose $U$ is a neighborhood of its own, then there exists some open $V$ (by part 1) such that $U \subseteq V \subseteq U$. We conclude that $U = V$ is open.
\end{proof}
Since neighborhood is more general than \textit{open} neighborhood, there might be cases where we need distinguish between them. However, for all practical purposes, we do not, as evidenced by the following.
\begin{theorem}[Semantic Equivalence]
Let $X$ be a toplogical space, $\varphi(N)$ is a predicate on subsets of $X$ (possibly with parameter) such that
\begin{align*}
    \exists U \subseteq N (\varphi(U)) \to \varphi(N)
\end{align*}
holds, then
\begin{align*}
    \forall N \in \mathcal{N}_p (\varphi(N)) \leftrightarrow \forall U \in \mathcal{N}_p, U \mbox{ open} (\varphi(U))
\end{align*}
Note another way to state the above condition on $\varphi$ is that $\varphi(U) \to \varphi(N)$ whenever $U \subseteq N$. In other words, if we interpret $\varphi$ as a collection of subsets of $X$ where $\varphi$ holds, then such collection is an upper set!
\end{theorem}
\begin{proof}
The forward direction is just specialization. As for the backward direction: let $N$ be a neighborhood of $p$. By definition, there exists an open neighborhood $U$ of $p$ such that $U \subseteq N$. From the hypothesis, we know that $\varphi(U)$ holds. From the condition on $\varphi$, we conclude $\varphi(N)$ must be true.
\end{proof}
\begin{corollary}[Semantic Equivalence - Existential Quantifier]
If $\varphi$ is a predicate on subsets of a topological space $X$ such that
\begin{align*}
    \varphi(N) \to \forall U \subseteq N (\varphi(U))
\end{align*}
holds, then
\begin{align*}
    \exists N \in \mathcal{N}_p (\varphi(N)) \leftrightarrow \exists U \in \mathcal{N}_p, U \mbox{ open} (\varphi(U))
\end{align*}
\end{corollary}
\begin{proof}
Let $\psi(N) := \neg \varphi(N)$, then by contraposition, $\exists U \subseteq N (\psi(U)) \rightarrow \psi(N)$ holds. Thus,
\begin{align*}
    \forall N \in \mathcal{N}_p (\psi(N)) & \leftrightarrow \forall U \in \mathcal{N}_p, U \mbox{ open} (\psi(U)) \mbox{, or}
    \\
    \forall N \in \mathcal{N}_p (\neg\varphi(N)) & \leftrightarrow \forall U \in \mathcal{N}_p, U \mbox{ open} (\neg\varphi(U)) \mbox{, or}
    \\
    \exists N \in \mathcal{N}_p (\varphi(N)) & \leftrightarrow \exists U \in \mathcal{N}_p, U \mbox{ open} (\varphi(U))
\end{align*}
\end{proof}
\begin{example}
The following are examples of predicate satisfying ``$\exists U \subseteq N (\varphi(U)) \to \varphi(N)$''
\begin{enumerate}
    \item $\varphi(N) := p \in N$.
    \item $\varphi(N) := N \not\subseteq A$, where $A$ is a subset of $X$.
    \item $\varphi(N) := N \cap A \neq \varnothing$.
    \item $\varphi(N) := f^{-1}(N) \mbox{ is a neighborhood of } p$, where $f: X \to Y$ is a function between the underlying sets of topological spaces, and $p \in X, N \subseteq Y$.
\end{enumerate}
\end{example}
\ \\
A collection $\mathcal{B}$ of open sets is called a \emph{basis} for $X$ if for each open set $U$ and a point $x$ in $U$, there exists some $B \in \mathcal{B}$ such that $x \in B \subseteq U$
\begin{lemma} \label{basis-union-prop}
Given a basis $\mathcal{B}$ of a topological space $X$, then every open set is a union of sets in $\mathcal{B}$. The empty set is a special case when the union is empty.
\end{lemma}
\begin{proof}
Given $U$ an open set, let $V = \bigcup_{\substack{B \in \mathcal{B} \\ B \subseteq U}} B$, which is also open and a subset of $U$ (even if $V$ is empty). Now since $\mathcal{B}$ is a basis, for each $x \in U$, there exists some $B \in \mathcal{B}$ such that $x \in B \subseteq U$. By construction, $B \subseteq V$, so $x \in V$. In other words, $U \subseteq V \subseteq U$. Hence, $U$ is a union of sets in $\mathcal{B}$.
\end{proof}
\begin{lemma}[Topology comparison based on basis] \label{topo-compare-basis}
Let $\mathcal{B}_n$ be the basis of the topology $\mathcal{T}_n$ on $X$ ($n = 1, 2$). The following are equivalent (TFAE):
\begin{enumerate}
    \item $\mathcal{T}_2$ is finer than $\mathcal{T}_1$.
    \item For each $x \in X$ and $B_1 \in \mathcal{B}_1$ containing $x$, there exists $B_2 \in \mathcal{B}_2$ such that $x \in B_2 \subseteq B_1$.
\end{enumerate}
\end{lemma}
\begin{proof}
Assume $\mathcal{T}_2 \supseteq \mathcal{T}_1$. Let $x \in B_1 \in \mathcal{B}_1$, then $x \in B_1 \in \mathcal{T}_2$, so there must exist some $B_2 \in \mathcal{B}_2$ such that $x \in B_2 \subseteq B_1$.
\\
\\
Vice versa, assume the 2nd condition. From the previous \hyperref[basis-union-prop]{Lemma}, each $U_1 \in \mathcal{T}_1$ is the union $U_1 = \bigcup_{\substack{B \in \mathcal{B}_1 \\ B \subseteq U_1}} B$. Let $U_2 = \bigcup_{\substack{B \in \mathcal{B}_2 \\ B \subseteq U_1}} B$. By definition, $U_2 \in \mathcal{T}_2$ and $U_2$ is a subset of $U_1$. On the other hand, for each $x \in U_1$, there exists some $B_1^x \in \mathcal{B}_1$ and $B_2^x \in \mathcal{B}_2$ such that $x \in B_2^x \subseteq B_1^x \subseteq U_1$. Thus, $x \in U_2$, which should prove that $U_1 = U_2 \in \mathcal{T}_2$. We conclude that $\mathcal{T}_1 \subseteq \mathcal{T}_2$.
\end{proof}
\ \\
A \emph{neighborhood basis} $\mathcal{B}_p$ at $p$ is a collection of neighborhoods of $p$ such that for each neighborhood $N$ at $p$, there exist some neighborhood $B$ in $\mathcal{B}_p$ such that $B \subseteq N$.

\begin{shaded}
\subsection{Topology generated by a collection}
Let $\mathcal{A}$ be a collection of subset of $X$.
\begin{enumerate}
    \item Denote $\mathcal{A}^{M} = \mathcal{A} \cup \{ \varnothing, X \}$.
    \item Add finite intersections of sets in $\mathcal{A}$ to form $\mathcal{A}^{FI} = \{ \bigcap_{i = 1}^n U_i : U_i \in \mathcal{A} \}$.
    \item Add arbitrary union of sets in $\mathcal{A}$ to form $\mathcal{A}^{U} = \{ \bigcup \mathcal{F} : \mathcal{F} \subseteq \mathcal{A} \}$
\end{enumerate}
A common property these operations share is that they always enlarge $\mathcal{A}$.
\begin{remark}
By definition, $\mathcal{T}$ is a topology if and only if $\mathcal{T}^M = \mathcal{T}^{FI} = \mathcal{T}^U = \mathcal{T}$.
\end{remark}
\begin{remark} \ 
\begin{enumerate}
    \item Extensionality: $\mathcal{A} \subseteq \mathcal{A}^M, \mathcal{A}^{FI}, \mathcal{A}^U$.
    \item Monotonicity: if $\mathcal{A} \subseteq \mathcal{B}$, then $\mathcal{A}^M \subseteq \mathcal{B}^M$, $\mathcal{A}^{FI} \subseteq \mathcal{B}^{FI}$, and $\mathcal{A}^U \subseteq \mathcal{B}^U$.
\end{enumerate}
\end{remark}
\begin{proof}
\underline{Part 1:} $\mathcal{A} \subseteq \mathcal{A}^M$ is straightforward, $\mathcal{A} \subseteq \mathcal{A}^{FI}$ because finite intersection includes singleton intersection, and $\mathcal{A} \subseteq \mathcal{A}^U$ because $\bigcup \{ A \} = A$ for $A \in \mathcal{A}$.
\\
\underline{Part 2:} $\mathcal{A}^M \subseteq \mathcal{B}^M$ is straightforward, $\mathcal{A}^{FI} \subseteq \mathcal{B}^{FI}$ since if $U_i \in \mathcal{A}$, then $U_i \in \mathcal{B}$, and so $\bigcap_{i = 1}^n U_i \in \mathcal{B}^{FI}$. Finally, $\mathcal{A}^U \subseteq \mathcal{B}^U$ because whenever $\mathcal{F} \subseteq \mathcal{A} \subseteq \mathcal{B}$, we get $\bigcup \mathcal{F} \in \mathcal{B}^U$.
\end{proof}
\begin{lemma} \label{topo-generated-basis}
A collection $\mathcal{B}$ of subsets of $X$ is a \emph{topological basis} if
\begin{enumerate}
    \item It covers $X$: $\bigcup \mathcal{B} = X$.
    \item For each $B_1, B_2 \in \mathcal{B}$ and $x \in B_1 \cap B_2$, there exists some $B \in \mathcal{B}$ such that $x \in B \subseteq B_1 \cap B_2$.
\end{enumerate}
Then the topology generated by $\mathcal{B}$ is exactly $\mathcal{B}^{U}$.
\end{lemma}
\begin{proof}
It is straightforward from the axioms to see that $\mathcal{B}^{U} \subseteq \mathcal{T}$ for any topology containing $\mathcal{B}$. If $\mathcal{B}^{U}$ is a topology, then we're pretty much done since $\mathcal{B}^{U}$ would be the smallest topology containing $\mathcal{B}$.
\begin{enumerate}
    \item The first condition (of a basis) shows that $X \in \mathcal{B}^U$. We also have $\varnothing \in \mathcal{B}^U$ by considering empty union.
    \item It is closed under arbitrary union: since any element of $\mathcal{B}^{U}$ has the form of $\bigcup \mathcal{F}$, let $\{ \mathcal{F}_i \}_{i \in I}$ be a collection of family of sets in $\mathcal{A}$. Then
    \begin{align*}
        \bigcup_{i \in I} \bigcup \mathcal{F}_i & = \bigcup_{i \in I} \{ x \mid \exists E \in \mathcal{F}_i : x \in E \}
        \\
        & = \{ x \mid \exists i \in I, \exists E \in \mathcal{F}_i : x \in E \}
        \\
        & = \bigcup \{ E \mid \exists i \in I: E \in \mathcal{F}_i \}
        \\
        & = \bigcup \bigcup_{i \in I} \mathcal{F}_i
    \end{align*}
    \item It is closed under finite intersection: first observe that for any $B_1, B_2 \in \mathcal{B}$, we have $B_1 \cap B_2$ a union of sets in $\mathcal{B}$, i.e. $B_1 \cap B_2 \in \mathcal{B}^U$. Indeed, denote $C = \bigcup_{\substack{B \in \mathcal{B} \\ B \subseteq B_1 \cap B_2}}$, which should be in $\mathcal{B}^U$. Under second condition (of a basis), each $x \in B_1 \cap B_2$ there exists some $C_x \in \mathcal{B}$ such that $x \in C_x \subseteq B_1 \cap B_2$. By $C$'s definition, we get $x \in C$, so $B_1 \cap B_2 = C \in \mathcal{B}^U$.
    \\
    \\
    Let $\bigcup_{i \in I} F_i, \bigcup_{j \in J} G_j \in \mathcal{B}^U$, then
    \begin{align*}
        \bigcup_{i \in I} F_i \cap \bigcup_{j \in J} G_j = \bigcup_{\substack{i \in I \\ j \in J}} F_i \cap G_j \in \mathcal{B}^U
    \end{align*}
    Since $F_i \cap G_j \in \mathcal{B}^U$ whenever $F_i, G_j \in \mathcal{B}^U$, and the previous part (i.e. arbitrary union of elements in $\mathcal{B}^U$ is still in $\mathcal{B}^U$). 
\end{enumerate}
\end{proof}
\begin{theorem} \label{topo-gen-steps}
Let $\mathcal{A}$ be a subcollection of $\mathcal{P}(X)$, and $\mathcal{T}$ is the topology generated by $\mathcal{A}$. Then $\mathcal{T} = ((\mathcal{A}^{M})^{FI})^{U} = ((\mathcal{A}^{FI})^{M})^{U} = ((\mathcal{A}^{FI})^{U})^{M}$
\end{theorem}
\begin{proof}
Adding $X$ and $\varnothing$ in any order will not affect the process much since they are the greatest and least element in the (complete) lattice $\mathcal{P}(X)$, meaning we can always omit them when taking union and intersection. This let us to prove just 1 equality, say the first one.
\\
\\
Next, $\mathcal{B} = (\mathcal{A}^M)^{FI}$ is a basis! Indeed,
\begin{enumerate}
    \item It covers $X$ as $X \in \mathcal{A}^M \subset \mathcal{B}$
    \item For each $B_1, B_2 \in \mathcal{B}$, which is represented by $B_1 = \bigcap_{i = 1}^n C_i$ and $B_2 = \bigcap_{j = 1}^m D_j$, then $B_1 \cap B_2$ is a finite intersection of sets ($C_i$ and $D_j$) in $\mathcal{A}^M$, so it's still in $\mathcal{B}$. Hence, for any $x \in B_1 \cap B_2$, just pick $B = B_1 \cap B_2$ and we have $x \in B \subseteq B_1 \cap B_2$.
\end{enumerate}
By the previous \hyperref[topo-generated-basis]{Lemma \ref*{topo-generated-basis}}, the topology generated by $\mathcal{B}$ (which contains $\mathcal{A}$) coincides with $\mathcal{B}^U = ((\mathcal{A}^{M})^{FI})^{U}$. Therefore, $\mathcal{T} \subseteq \mathcal{B}^U$ by minimality. On the other hand,
\begin{enumerate}
    \item Any topology $\mathcal{T}'$ containing $\mathcal{A}$ must contain $\mathcal{A}^M$.
    \item Any topology $\mathcal{T}'$ containing $\mathcal{A}^M$ must contain $\mathcal{B}$ (closed under finite intersection).
    \item Finally, any topology $\mathcal{T}'$ containing $\mathcal{B}$ must contain $\mathcal{B}^U$ (closed under arbitrary union).
\end{enumerate}
This shows the reverse inclusion $\mathcal{T} \supseteq \mathcal{B}^U$.
\end{proof}
\ \\
\begin{lemma}\label{topo-compare-generation}
Let $\mathcal{A} \subseteq \mathcal{B}$ be collections of subsets of $X$, and $\mathcal{T}, \mathcal{S}$ respectively be the topologies generated by $\mathcal{A}, \mathcal{B}$. Then $\mathcal{T} \subseteq \mathcal{S}$.
\end{lemma}
\begin{proof}
Since $\mathcal{S}$ also contains $\mathcal{A}$, we get $\mathcal{T} \subseteq \mathcal{S}$ by minimality.
\end{proof}
\ \\
Given a topological space $X$, the weight $w(X)$ of $X$ is defined as the least cardinality of a basis of $X$.
\begin{remark} \ 
\begin{enumerate}
    \item Since a basis of a space must be a subcollection of its topology, the weight is always less than or equal to the cardinality of the topology, which in turns is less than or equal to the cardinality of the power set of the space. In simple term, $w(X) \leq |\mathcal{T}| \leq 2^{|X|}$.
    \item Since the class of cardinal numbers is well-ordered, there exists a basis with cardinality equal to the weight.
\end{enumerate}
\end{remark}
\begin{lemma}[Cardinality of generation]
If $w(X)$ is infinite, then $w(X)$ is also the least cardinality of any collection of open subsets of $X$ that generates $X$.
\end{lemma}
\begin{proof}
Denote $\kappa$ to be the least cardinality of any collection of open subsets of $X$ that generates $X$. Then $\kappa \leq w(X)$ by definition. On the other hand, for each $\mathcal{S}$ that generates $X$, $\mathcal{B} = (\mathcal{S}^{M})^{FI}$ must be a basis. As $|\mathcal{B}| \geq w(X)$ is infinite, $\mathcal{S}$ cannot be finite (as the first step adds at most 2 sets, and the second step adds finite intersection of these sets). Hence, $|\mathcal{S}| \leq |\mathcal{S}^M| \leq |\mathcal{S}| + 2 = |\mathcal{S}|$. As for $(\mathcal{S}^{M})^{FI}$,
\begin{align*}
    |\mathcal{S}| = |\mathcal{S}^M| & \leq \left| (\mathcal{S}^{M})^{FI} \right| \leq \left| \bigcup_{n = 1}^\infty (\mathcal{S}^{M})^n \right| = \sum_{n = 1}^\infty |\mathcal{S}^{M}|^n
    \\
    & = \sum_{n = 1}^\infty |\mathcal{S}| = \aleph_0 |\mathcal{S}| = \max(\aleph_0, |\mathcal{S}|) = |\mathcal{S}|
\end{align*}
Hence, $|\mathcal{B}| = |\mathcal{S}|$. So for any $\mathcal{S}$ that generates $X$, there exists a basis $\mathcal{B}$ of $X$ with the same cardinality. Therefore, $w(X) \leq \kappa$, and so $\kappa = w(X)$.
\\
\underline{Proof Note:} we need axiom of choice for arbitrary cardinalities to be comparable.
\end{proof}
\end{shaded}

\subsection{Some topologies on the real numbers}
Let $\mathbb{R}$ be the set of real numbers. Denote the following topologies on $\mathbb{R}$ as
\begin{enumerate}
    \item $\mathcal{T}_0$ for the \emph{standard topology}: it is generated by the basis consisting of open intervals $(a, b)$.
    \item $\mathcal{T}_0^+$ for the topology generated by the basis consisting of $(a, \infty)$.
    \item $\mathcal{T}_0^-$ for the topology generated by the basis consisting of $(-\infty, b)$.
    \item $\mathcal{T}_\omega$ for the cofinite topology
    \item $\mathcal{T}_{\omega_1}$ for the cocountable topology
    \item $\mathcal{T}_l$ for the \emph{lower limit topology}: it is generated by half-open intervals of the form $[a, b)$. The resulted line is called \emph{Sorgenfrey line}.
    \item $\mathcal{T}_u$ for the \emph{upper limit topology}: it is generated by half-open intervals of the form $(a, b]$.
    \item $\mathcal{T}_l^+$ for the topology generated by $[a, \infty)$.
    \item $\mathcal{T}_u^-$ for the topology generated by $(-\infty, b]$.
    \item $\mathcal{T}_K$ for the \emph{$K$-topology} generated by $(a, b)$ and $(a, b) \setminus K$ where $K = \{ 1/n : n \in \mathbb{N} \}$
\end{enumerate}
\begin{proposition}
The following holds
\begin{enumerate}
    \item $\mathcal{T}_0$ is (strictly) finer than $\mathcal{T}_0^+, \mathcal{T}_0^-, \mathcal{T}_\omega$.
    \\
    $\mathcal{T}_0$ is coarser than $\mathcal{T}_l, \mathcal{T}_u, \mathcal{T}_K$.
    \\
    $\mathcal{T}_0$ is incomparable to $\mathcal{T}_{\omega_1}, \mathcal{T}_l^+, \mathcal{T}_u^-$.
    \item $\mathcal{T}_0^+$ is incomparable to $\mathcal{T}_0^-, \mathcal{T}_\omega, \mathcal{T}_{\omega_1}, \mathcal{T}_u^-$.
    \\
    $\mathcal{T}_0^+$ is coarser than $\mathcal{T}_l, \mathcal{T}_u, \mathcal{T}_l^+, \mathcal{T}_K$.
    \item $\mathcal{T}_0^-$ is incomparable to $\mathcal{T}_\omega, \mathcal{T}_{\omega_1}, \mathcal{T}_l^+$.
    \\
    $\mathcal{T}_0^-$ is coarser than $\mathcal{T}_l, \mathcal{T}_u, \mathcal{T}_u^-, \mathcal{T}_K$.
    \item $\mathcal{T}_\omega$ is coarser than $\mathcal{T}_{\omega_1}, \mathcal{T}_l, \mathcal{T}_u, \mathcal{T}_K$.
    \\
    $\mathcal{T}_\omega$ is incomparable to $\mathcal{T}_l^+, \mathcal{T}_u^-$.
    \item $\mathcal{T}_{\omega_1}$ is incomparable to $\mathcal{T}_l, \mathcal{T}_u, \mathcal{T}_l^+, \mathcal{T}_u^-, \mathcal{T}_K$.
    \item $\mathcal{T}_l$ is incomparable to $\mathcal{T}_u, \mathcal{T}_u^-, \mathcal{T}_K$.
    \\
    $\mathcal{T}_l$ is finer than $\mathcal{T}_l^+$.
    \item $\mathcal{T}_u$ is incomparable to $\mathcal{T}_l^+$.
    \\
    $\mathcal{T}_u$ is finer than $\mathcal{T}_u^-, \mathcal{T}_K$.
    \item $\mathcal{T}_l^+, \mathcal{T}_u^-, \mathcal{T}_K$ are mutually incomparable.
\end{enumerate}
Here is the Hasse diagram
\begin{align*}
    \xymatrix{
        & & \mathcal{T}_u \ar@{-}[dl] \ar@{-}[dd] &
        \\
        \mathcal{T}_l \ar@{-}[d] \ar@{-}[dr] & \mathcal{T}_K \ar@{-}[d] & &
        \\
        \mathcal{T}_l^+ \ar@{-}[d] & \mathcal{T}_0 \ar@{-}[dl] \ar@{-}[dr] \ar@{-}[drr] & \mathcal{T}_u^- \ar@{-}[d] & \mathcal{T}_{\omega_1} \ar@{-}[d]
        \\
        \mathcal{T}_0^+ & & \mathcal{T}_0^- & \mathcal{T}_\omega
    }
\end{align*}
\end{proposition}
\begin{proof} \ \\
\underline{1. $\mathcal{T}_0$ is finer than $\mathcal{T}_0^+$:} use \hyperref[topo-compare-basis]{Lemma \ref*{topo-compare-basis}}. For each $a \in \mathbb{R}$, $(a, \infty) = \bigcup_{b > a} (a, b)$. If $(-1, 1)$ is in $\mathcal{T}_0^+$, then there exists some $(a, \infty)$ such that $0 \in (a, \infty) \subseteq (-1, 1)$, which impossible since for a big enough $r$ (say $r > \max(1, a)$) then $r \in (a, \infty)$ yet $r \notin (-1, 1)$.
\\
\underline{2. $\mathcal{T}_0$ is finer than $\mathcal{T}_0^+$:} similar as (1)
\\
\underline{3. $\mathcal{T}_0$ is finer than $\mathcal{T}_\omega$:} use \hyperref[topo-compare-closed-set]{Lemma \ref*{topo-compare-closed-set}}. Firstly, each point $x$ is closed in $\mathcal{T}_0$ since $(-\infty, x) \cup (x, \infty) = \bigcup_{y < x} (y, x) \cup \bigcup_{y > x} (x, y)$ is open. Hence, if $C$ is finite, then $C$ is closed, since it is a finite union of closed singletons. On the other hand, $\mathbb{Z} = \mathbb{R} \setminus \bigcup_{n \in \mathbb{Z}} (n, n + 1)$ is closed in $\mathcal{T}_0$ but not in $\mathcal{T}_\omega$.
\\
\underline{4. $\mathcal{T}_0$ is coarser $\mathcal{T}_l$:} $(a, b) = \bigcup_{\varepsilon > 0} [a + \varepsilon, b)$. On the other hand, if $[0, 1)$ is open in $\mathcal{T}_0$, then there exists some $(a, b)$ such that $0 \in (a, b) \subseteq [0, 1)$, meaning both $a < 0$ and $0 \leq a$, a contradiction.
\\
\underline{5. $\mathcal{T}_0$ is coarser $\mathcal{T}_u$:} similar as (4)
\\
\underline{6. $\mathcal{T}_0$ is coarser $\mathcal{T}_K$:} note $(a, b)$ is already in $\mathcal{T}_K$. On the other hand, if $(-1, 1) \setminus K$ is open, then there exists an interval $(a, b) \subseteq (-1, 1) \setminus K$ around $0$. Since $b > 0$, there exists some $n \in \mathbb{N}$ large enough so that $b > 1/n > 0$ (archimedean property). Thus $1/n \in (-1, 1) \setminus K$, a contradiction.
\\
\underline{7. $\mathcal{T}_0$ is incomparable to $\mathcal{T}_{\omega_1}$:} $[0, 1]$ is not closed in $\mathcal{T}_{\omega_1}$ since it is uncountable. On the other hand, $K = \{ 1/n : n \in \mathbb{N} \}$ is not closed in $\mathcal{T}_0$, since otherwise, there must be some $(a, b)$ around $0$ such that $(a, b) \subseteq \mathbb{R} \setminus K$.
\\
\underline{8. $\mathcal{T}_0$ is incomparable to $\mathcal{T}_l^+$:} $(-1, 1)$ is not open in $\mathcal{T}_l^+$ since otherwise, there exists some $[a, \infty)$ such that $0 \in [a, \infty) \subseteq (-1, 1)$ (impossible). On the other hand, $[0, \infty)$ is not open in $\mathcal{T}_0$ because any $(a, b)$ containing $0$ will contain negative numbers.
\\
\underline{9. $\mathcal{T}_0$ is incomparable to $\mathcal{T}_u^-$:} similar to (8).
\\
\underline{10. $\mathcal{T}_0^+$ is incomparable to $\mathcal{T}_0^-$:} similar to (8).
\\
\underline{11. $\mathcal{T}_0^+$ is incomparable to $\mathcal{T}_\omega$:} a singleton like $\{ 0 \}$ cannot be closed in $\mathcal{T}_0^+$ since otherwise, there exists some $(a, \infty)$ such that $-1 \in (a, \infty) \subseteq \mathbb{R} \setminus \{ 0 \}$. This means that $a < -1$, so $0 \in (a, \infty)$, a contradiction. On the other hand, $(-\infty, 0]$ is not closed in $\mathcal{T}_\omega$ since it is uncountable.
\\
\underline{12. $\mathcal{T}_0^+$ is incomparable to $\mathcal{T}_{\omega_1}$:} same as (11).
\\
\underline{13. $\mathcal{T}_0^+$ is incomparable to $\mathcal{T}_u^-$:} similar to (8).
\\
\underline{14. $\mathcal{T}_0^+$ is coarser than $\mathcal{T}_l$:} combination of (1) and (4).
\\
\underline{15. $\mathcal{T}_0^+$ is coarser than $\mathcal{T}_u$:} combination of (1) and (5).
\\
\underline{16. $\mathcal{T}_0^+$ is coarser than $\mathcal{T}_l^+$:} $(a, \infty) = \bigcup_{\varepsilon > 0} [a + \varepsilon, \infty)$. On the other hand, $[0, \infty)$ cannot be open in $\mathcal{T}_0^+$ by an argument similar to (4).
\\
\underline{17. $\mathcal{T}_0^+$ is coarser than $\mathcal{T}_K$:} combination of (1) and (6).
\\
\underline{18. $\mathcal{T}_0^-$ is incomparable to $\mathcal{T}_\omega$:} similar to (11).
\\
\underline{19. $\mathcal{T}_0^-$ is incomparable to $\mathcal{T}_{\omega_1}$:} similar to (12).
\\
\underline{20. $\mathcal{T}_0^-$ is incomparable to $\mathcal{T}_l^+$:} similar to (8).
\\
\underline{21. $\mathcal{T}_0^-$ is coarser than $\mathcal{T}_l$:} combination of (2) and (4).
\\
\underline{22. $\mathcal{T}_0^-$ is coarser than $\mathcal{T}_u$:} combination of (2) and (5).
\\
\underline{23. $\mathcal{T}_0^-$ is coarser than $\mathcal{T}_u$:} similar to (16).
\\
\underline{24. $\mathcal{T}_0^-$ is coarser than $\mathcal{T}_K$:} combination of (2) and (6).
\\
\underline{25. $\mathcal{T}_\omega$ is coarser than $\mathcal{T}_{\omega_1}$}: result of \hyperref[co-kappa-compare]{Proposition \ref*{co-kappa-compare}}. Additionally, $\mathbb{Z}$ is not closed in $\mathcal{T}_\omega$.
\\
\underline{26. $\mathcal{T}_\omega$ is coarser than $\mathcal{T}_l$:} combination of (3) and (4).
\\
\underline{27. $\mathcal{T}_\omega$ is coarser than $\mathcal{T}_u$:} combination of (3) and (5).
\\
\underline{28. $\mathcal{T}_\omega$ is coarser than $\mathcal{T}_K$:} combination of (3) and (6).
\\
\underline{29. $\mathcal{T}_\omega$ is incomparable to $\mathcal{T}_l^+$ and $\mathcal{T}_u^-$:} similar to (11).
\\
\underline{30. $\mathcal{T}_{\omega_1}$ is incomparable to $\mathcal{T}_l, \mathcal{T}_u, \mathcal{T}_l^+, \mathcal{T}_u^-, \mathcal{T}_K$:} similar to (7).
\\
\underline{31. $\mathcal{T}_l$ is incomparable to $\mathcal{T}_u$:} similar to (4).
\\
\underline{32. $\mathcal{T}_l$ is incomparable to $\mathcal{T}_u^-$:} similar to (8).
\\
\underline{33. $\mathcal{T}_l$ is incomparable to $\mathcal{T}_K$:} suppose $[0, 1)$ is open in $\mathcal{T}_K$, then either $0 \in (a, b) \subseteq [0, 1)$ or $0 \in (a, b) \setminus K$ for some $a, b \in \mathbb{R}$. In any case, we get $a < 0$ and $0 \leq a$, a contradiction. On the other hand, first note that $\mathbb{R} \setminus K = (-\infty, 0] \cup \bigcup_{n = 1}^\infty \left( \frac{1}{n + 1}, \frac{1}{n} \right) \cup (1, \infty)$. So if $K$ is closed in $\mathcal{T}_l$, then $0 \in [a, b) \subseteq \mathbb{R} \setminus K$ for some $a, b \in \mathbb{R}$. However, we have $0 < b$, so for large enough $n \in \mathbb{N}$, we get $0 < 1/n < b$, and so $1/n \in \mathbb{R} \setminus K$, a contradiction.
\\
\underline{34. $\mathcal{T}_l$ is finer than $\mathcal{T}_l^+$:} similar to (1).
\\
\underline{35. $\mathcal{T}_u$ is incomparable to $\mathcal{T}_l^+$:} similar to (8).
\\
\underline{36. $\mathcal{T}_u$ is finer to $\mathcal{T}_u^-$:} similar to (2).
\\
\underline{37. $\mathcal{T}_u$ is finer to $\mathcal{T}_K$:} note $(a, b) \in \mathcal{T}_u$ (see (4)), and $\mathbb{R} \setminus K = U_K \cup (-\infty, 0] = U_K \cup \bigcup_{a < 0} (a, 0]$ (where $U_K \in \mathcal{T}_0 \subseteq \mathcal{T}_u$), we also get $(a, b) \setminus K \in \mathcal{T}_u$. In conclusion, $\mathcal{T}_u$ is finer than $\mathcal{T}_K$. Additionally, $(-1, 0]$ is not open in $\mathcal{T}_K$ since otherwise, either $0 \in (a, b) \subseteq (-1, 0]$, or $0 \in (a, b) \setminus K \subseteq (-1, 0]$. Either case gives us $b > 0$ and $b \leq 0$, a contradiction.
\\
\underline{38. $\mathcal{T}_l^+$ is incomparable to $\mathcal{T}_u^-$:} similar to (4) and (8).
\\
\underline{39. $\mathcal{T}_l^+$ is incomparable to $\mathcal{T}_K$:} similar to (33).
\\
\underline{40. $\mathcal{T}_u^-$ is incomparable to $\mathcal{T}_K$:} similar to (8).
\end{proof}

\newpage

\section{Subsets of topological spaces}
Given a set $A$ in a topological space $X$. We denote
\begin{enumerate}
    \item $\operatorname{int}(A)$ as the \emph{interior} of $A$: this is the union of open sets contained in $A$
    \begin{align*}
        \operatorname{int}(A) = \bigcup_{\substack{U \text{ open} \\ U \subseteq A}} U
    \end{align*}
    \item $\operatorname{cl}(A)$ as the \emph{closure} of $A$: this is the intersection of closed sets \textit{containing} $A$
    \begin{align*}
        \operatorname{cl}(A) = \bigcap_{\substack{C \text{ closed} \\ C \supseteq A}} C
    \end{align*}
    \item $\operatorname{ext}(A)$ as the \emph{exterior} of $A$: this is the union of open sets disjoint with $A$
    \begin{align*}
        \operatorname{ext}(A) = \bigcup_{\substack{U \text{ open} \\ A \cap U = \varnothing}} U
    \end{align*}
    \item $\partial A$ as the \emph{boundary} of $A$: this is the complement of the interior relative to the closure of $A$
    \begin{align*}
        \partial A = \operatorname{cl}(A) \setminus \operatorname{int}(A)
    \end{align*}
\end{enumerate}
A point in $\operatorname{int}(A)$ is called an interior point. A point in $\operatorname{cl}(A)$ is called a closure point. A point in $\operatorname{ext}(A)$ is called an exterior point. And a point in $\partial A$ is called a boundary point.
\begin{proposition}[Topological properties] \label{topo-subset-top-prop-1} \ 
\begin{enumerate}
    \item Extremal properties:
    \begin{enumerate}
        \item $\operatorname{int}(A)$ is the largest open set contained in $A$. Hence, if $U$ is open, then $U \subseteq A$ if and only if $U \subseteq \operatorname{int}(A)$.
        \item $\operatorname{cl}(A)$ is the smallest closed set containing $A$. Hence, if $C$ is closed, then $A \subseteq C$ if and only if $\operatorname{cl}(A) \subseteq C$.
        \item $\operatorname{ext}(A)$ is the largest open set disjoint with $A$. Hence, if $U$ is open, then $A \cap U = \varnothing$ if and only if $U \subseteq \operatorname{ext}(A)$
    \end{enumerate}
    \item Partition properties:
    \begin{enumerate}
        \item $\operatorname{int}(A)$ and $\partial A$ forms a partition of $\operatorname{cl}(A)$.
        \item $\operatorname{cl}(A)$ and $\operatorname{ext}(A)$ forms a partition of the space $X$ itself.
    \end{enumerate}
    \item Characterizations of points
    \begin{enumerate}
        \item $p$ is an interior point of $A$ if and only if $A$ is a neighborhood of $p$, or equivalently, there exists some open set $U$ such that $p \in U \subseteq A$.
        \item $p$ is a closure point of $A$ if and only if every neighborhood of $p$ meets $A$ at some point.
        \item $p$ is an exterior point of $A$ if and only if there exists some neighborhood of $p$ that are disjoint from $A$.
        \item $p$ is a boundary point of $A$ if and only if every neighbohood of $p$ meets both $A$ and its complement at some point.
    \end{enumerate}
    \item Open and closed properties:
    \begin{enumerate}
        \item $A$ is open if and only if $A = \operatorname{int}(A)$
        \item $A$ is closed if and only if $A = \operatorname{cl}(A)$, or equivalently, $A = X \setminus \operatorname{ext}(A)$
        \item $\partial A$ is always closed. Additionally, $A$ is clopen if and only if $\partial A = \varnothing$.
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} if $V$ is any open set contained in $A$, then $V \subseteq \bigcup_{\substack{U \text{ open} \\ U \subseteq A}} U = \operatorname{int}(A)$ by definition. Since $\operatorname{int}(A)$ is union of open sets, it is itself open, and so it is the largest open set contained in $A$. The other properties follow similarly.
\\
\underline{Part 2:}
\begin{enumerate}[label=(\alph*)]
    \item Straight from definition, with the fact that $\operatorname{int}(A) \subseteq A \subseteq \operatorname{cl}(A)$ (part (1)).
    \item Note that $X \setminus \operatorname{cl}(A)$ is open and disjoint from $A$ (since $A \subseteq \operatorname{cl}(A)$, so we get $X \setminus \operatorname{cl}(A) \subseteq \operatorname{ext}(A)$ by maximality. Equivalently, $X \subseteq \operatorname{cl}(A) \cup \operatorname{ext}(A)$. But these are subsets of $X$, so the equality must hold.
    \\
    \\
    Let $p \in \operatorname{ext}(A)$, then there exists some open $U$ such that $p \in U \subseteq X \setminus A$ by definition. In other words $p \notin X \setminus U \supset A$. As $X \setminus U$ is closed, we get $X \setminus U \supseteq \operatorname{cl}(A)$. Thus $p \notin \operatorname{cl}(A)$.
\end{enumerate}
\underline{Part 3:}
\begin{enumerate}[label=(\alph*)]
    \item If $p$ is an interior point of $A$, then take $U = \operatorname{int}(A)$ and we get $p \in U \subseteq A$. Vice versa, if $p \in U \subseteq A$ where $U$ is open, then by definition $U \subseteq \operatorname{int}(A)$, and so $p \in \operatorname{int}(A)$.
    \item If $p$ is a closure point of $A$, and $N$ is a neighborhood of $p$, let $U$ be an open set such that $p \in U \subseteq N$. If $U \cap A = \varnothing$, then by definition $p \in \operatorname{ext}(A)$, contradicting the partition property in part (2). Thus, we must have $U \cap A \neq \varnothing$, and so any neighborhood of $p$ must intersect $A$. Vice versa, if any neighborhood $N$ of $p$ intersect $A$, then $p$ cannot be in $\operatorname{ext}(A)$ since it would imply an existence of a neighborhood (of $p$) that is disjoint from $A$. Therefore $p \in X \setminus \operatorname{ext}(A) = \operatorname{cl}(A)$.
    \item If $p$ is an exterior point of $A$, take $U = \operatorname{ext}(A)$ and we get a neighborhood of $A$ that is disjoint from $A$. Vice versa, if there exists some neighborhood $N$ of $p$ that are disjoint from $A$, then there also exists an open set $U$ such that $p \in U \subseteq N$. As $U$ is a subset of $N$, it should be disjoint from $A$. Thus, $U \subseteq \operatorname{ext}(A)$ and so $p \in \operatorname{ext}(A)$.
    \item If $p$ is a boundary point of $A$, then every neighborhood of $p$ meets $A$ (note $\partial A \subseteq \operatorname{cl}(A)$ by definition). To show that each neighborhood of $p$ meets also $X \setminus A$, suppose otherwise, that there exists some open neighborhood $U$ of $p$ (as we can always find such inside any neighborhood) satisfying $U \cap (X \setminus A) = \varnothing$. Equivalently, $U \subseteq A$, so by part (3a), we get $p \in \operatorname{int}(A)$. But $\operatorname{int}(A)$ is disjoint from $\partial A$, a contradiction to the assumption on $p$.
    \\
    \\
    Vice versa, suppose every neighborhood of $p$ meets both $A$ and $X \setminus A$. This means, by part (3c), that $p \in \operatorname{cl}(A)$. Now if $p \in \operatorname{int}(A)$, then there exists some open neighborhood $U$ of $p$ such that $U \subseteq A$. However, this means $U$ is disjoint with the complement of $A$, so there should be no intersection between them, a contradiction. Hence, $p \in \operatorname{cl}(A) \setminus \operatorname{int}(A) = \partial A$.
\end{enumerate}
\underline{Part 4:} if $A = \operatorname{int}(A)$, then $A$ is open (since $\operatorname{int}(A)$ is always open, from part (1)). Vice versa, if $A$ is open, then $A \subseteq \operatorname{int}(A)$ by definition of interior. Yet $\operatorname{int}(A) \subseteq A$ (again from part (1)), so we get $A = \operatorname{int}(A)$. The 2nd property follow similarly. As for $\partial A$, from part (2), we know that $\partial A = X \setminus (\operatorname{int}(A) \cup \operatorname{ext}(A))$, so the boundary is always closed.
\end{proof}
\begin{proposition}[Algebraic Properties] \label{topo-subset-alg-prop-1} \
Let $\mathcal{M}_X = \operatorname{End}(\mathcal{P}(X))$ be the collection of all maps, or operators, on $\mathcal{P}(X)$.
\begin{enumerate}
    \item With composition, and the identity map $I$, this forms a (noncommutative) monoid
    \item Define the partial ordering $\varphi \leq \psi$ if and only if $\varphi(A) \subseteq \psi(A)$ for all $A \subseteq X$.
    \item This ordering is right-compatible with the monoid structure: given $\varphi \leq \psi$, then $\varphi \lambda \leq \psi \lambda$ for any $\lambda \in \mathcal{M}_X$.
    \item It is also a complete lattice: the least element $\bot$ is the map sending everything to $\varnothing$, and the greatest element $\top$ is the map sending everything to $X$.
    \begin{align*}
        \left( \bigvee_{j \in J} \varphi_j \right)(A) & = \bigcup_{j \in J} \varphi_j(A)
        \\
        \left( \bigwedge_{j \in J} \varphi_j \right)(A) & = \bigcap_{j \in J} \varphi_j(A)
    \end{align*}
    \item The join and meet left-distribute with composition:
    \begin{align*}
        \left( \bigvee_{j \in J} \varphi_j \right) \psi & = \bigvee_{j \in J} (\varphi_j \psi)
        \\
        \left( \bigwedge_{j \in J} \varphi_j \right) \psi & = \bigwedge_{j \in J} (\varphi_j \psi)
    \end{align*}
    \item Finally, the complement reverse join and meet
    \begin{align*}
        c \left( \bigvee_{j \in J} \varphi_j \right) & = \bigwedge_{j \in J} (c \varphi_j)
        \\
        c \left( \bigwedge_{j \in J} \varphi_j \right) & = \bigvee_{j \in J} (c \varphi_j)
    \end{align*}
\end{enumerate}
Denote the letters $k, i, e, b, c$ denotes the the closure, interior, exterior, boundary, complement operators correspondingly (and $I, \bot, \top$ as above). Prove
\begin{enumerate}
    \item Monotone properties: given $\varphi \leq \psi$ and $A \subseteq B$
    \begin{enumerate}
        \item $i\varphi \leq i\psi$, or $\operatorname{int}(A) \subseteq \operatorname{int}(B)$.
        \item $k\varphi \leq k\psi$, or $\operatorname{cl}(A) \subseteq \operatorname{cl}(B)$.
        \item $e\varphi \geq e\psi$, or $\operatorname{ext}(A) \supseteq \operatorname{ext}(B)$.
        \item $c\varphi \geq c\psi$, or $X \setminus A \supseteq X \setminus B$.
    \end{enumerate}
    \item Lattice properties (interior):
    \begin{enumerate}
        \item $i \left( \bigwedge_{j \in J} \varphi_j \right) \leq \bigwedge_{j \in J} (i\varphi_j)$, or $\operatorname{int} \left( \bigcap_{j \in J} A_j \right) \subseteq \bigcap_{j \in J} \operatorname{int}(A_j)$.
        \item $i(\varphi \wedge \psi) = i\varphi \wedge i \psi$, or $\operatorname{int}(A \cap B) = \operatorname{int}(A) \cap \operatorname{int}(B)$.
        \item $i \left( \bigvee_{j \in J} \varphi_j \right) \geq \bigvee_{j \in J} (i\varphi_j)$, or $\operatorname{int} \left( \bigcup_{j \in J} A_j \right) \supseteq \bigcup_{j \in J} \operatorname{int}(A_j)$.
    \end{enumerate}
    \item Lattice properties (closure):
    \begin{enumerate}
        \item $k \left( \bigvee_{j \in J} \varphi_j \right) \supseteq \bigvee_{j \in J} (k \varphi_j)$, or $\operatorname{cl} \left( \bigcup_{j \in J} A_j \right) \supseteq \bigcup_{j \in J} \operatorname{cl}(A_j)$.
        \item $k(\varphi \vee \psi) = k\varphi \vee k\psi$, or $\operatorname{cl}(A \cup B) = \operatorname{cl}(A) \cup \operatorname{cl}(B)$.
        \item $k \left( \bigwedge_{j \in J} \varphi_j \right) \subseteq \bigwedge_{j \in J} (k \varphi_j)$, or $\operatorname{cl} \left( \bigcap_{j \in J} A_j \right) \subseteq \bigcap_{j \in J} \operatorname{cl}(A_j)$.
    \end{enumerate}
    \item Lattice properties (exterior):
    \begin{enumerate}
        \item $e \left( \bigvee_{j \in J} \varphi_j  \right) \leq \bigwedge_{j \in J} (e\varphi_j)$, or $\operatorname{ext} \left( \bigcup_{j \in J} A_j \right) \subseteq \bigcap_{j \in J} \operatorname{ext}(A_j)$.
        \item $e(\varphi \vee \psi) = e\varphi \wedge e\psi$, or $\operatorname{ext}(A \cup B) = \operatorname{ext}(A) \cap \operatorname{ext}(B)$.
        \item $e \left( \bigwedge_{j \in J} \varphi_j \right) \geq \bigvee_{j \in J} (e \varphi_j)$, or $\operatorname{ext} \left( \bigcap_{j \in J} A_j \right) \supseteq \bigcup_{j \in J} \operatorname{ext}(A_j)$
    \end{enumerate}
    \item Lattice properties (boundary):
    \begin{enumerate}
        \item $b(\varphi \vee \psi) \leq b\varphi \vee b\psi$, or $\partial (A \cup B) \subseteq \partial A \cup \partial B$
        \item $b = k \wedge kc$, or $\partial A = \operatorname{cl}(A) \cap \operatorname{cl}(X \setminus A)$
    \end{enumerate}
    \item Other Identities and Inequalities:
    \begin{enumerate}
        \item $\top \varphi = \top$, $\bot \varphi = \bot$ for all $\varphi \in \operatorname{End}(\mathcal{P}(X))$.
        \item $I \varphi = \varphi I = \varphi$ for all $\varphi \in \operatorname{End}(\mathcal{P}(X))$.
        \item $\varphi \top = \top$ for $\varphi \in \{ c, k, i, e \}$ and $b \top = \bot$.
        \item $\varphi \bot = \bot$ for $\varphi \in \{ c, k, i, e, b \}$.
        \item $c \bot = \top$ and $c \top = \bot$.
        \\
        \item $c^2 = I$.
        \item $ck = e = ic$, or $X \setminus \operatorname{cl}(A) = \operatorname{ext}(A) = \operatorname{int}(X \setminus A)$.
        \item $cb = i \vee e = eb$, or $X \setminus \partial A = \operatorname{int}(A) \cup \operatorname{ext}(A) = \operatorname{ext}(\partial A)$
        \\
        \item $k^2 = k$, or $\operatorname{cl}(\operatorname{cl}(A)) = \operatorname{cl} (A)$.
        \item $kb = b$, or $\operatorname{cl}(\partial A) = \partial A$.
        \item $kc = ci$.
        \\
        \item $ik = e^2$, or $\operatorname{int}(\operatorname{cl}(A)) = \operatorname{ext}(\operatorname{ext}(A))$.
        \item $i^2 = i$, or $\operatorname{int}(\operatorname{int}(A)) = \operatorname{int}(A)$.
        \item $ie = e$, or $\operatorname{int}(\operatorname{ext}(A)) = \operatorname{ext}(A)$.
        \item $ibi = ibe = ibk = \bot$, or more generally, the interior of the boundary of either an open set or a closed set is always empty.
        \\
        \item $ek = e$, or $\operatorname{ext}(\operatorname{cl}(A)) = \operatorname{ext}(A)$.
        \\
        \item $bc = b$, or $\partial (X \setminus A) = \partial A$.
        \item $bi, bk, b^2 \leq b$, or $\partial(\operatorname{int}(A)), \partial(\operatorname{cl}(A)), \partial\partial A \subseteq \partial A$.
        \\
        Additionally, $\partial \partial A = \partial A$ iff $\operatorname{int}(\partial A) = \varnothing$
        \item $b^3 = b^2$, or $\partial \partial \partial A = \partial \partial A$
        \\
        \item $kck = kckckck$
        \item $e^4 = e^2$
        \item $ik = (ik)^2$
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:}
\begin{enumerate}[label=(\alph*)]
    \item Since $\operatorname{int}(A)$ is open, and $\operatorname{int}(A) \subseteq A \subseteq B$, we have $\operatorname{int}(A) \subseteq \operatorname{int}(B)$ by minimality.
    \item Similar argument as the previous one
    \item Using part (1b), we get $\operatorname{ext}(A) = X \setminus \operatorname{cl}(A) \supseteq X \setminus \operatorname{cl}(B) = \operatorname{ext}(B)$.
    \item This is just set-theoretic result.
\end{enumerate}
\underline{Part 2:}
\begin{enumerate}[label=(\alph*)]
    \item Let $p \in \operatorname{int}(\bigcap_{j \in J} A_j)$, then there exists some open neighborhood $U$ of $p$ such that $U \subseteq \bigcap_{j \in J} A_j$. In other words, $U \subseteq A_j$ for each $j \in J$. From there, we have $p \in \operatorname{int}(A_j)$ for all $j \in J$.
    \item Vice versa, if $p \in \operatorname{int}(A) \cap \operatorname{int}(B)$, then there exists some open neighborhoods $U \subseteq A$ and $V \subseteq B$ of $p$. Together, we get $U \cap V \subseteq A \cap B$ is an open neighborhood of $p$. Hence, $p \in \operatorname{int}(A \cap B)$.
    \item Since $A_k \in \subseteq \bigcup_{j \in J} A_j$, by monotone property, we have $\operatorname{int}(A_k) \subseteq \operatorname{int} \left( \bigcup_{j \in J} A_j \right)$. Hence, $\bigcup_{j \in J} \operatorname{int}(A_j) \subseteq \operatorname{int} \left( \bigcup_{j \in J} A_j \right)$.
\end{enumerate}
\underline{Part 3:}
\begin{enumerate}[label=(\alph*)]
    \item Let $p \in \bigcup_{j \in J} \operatorname{cl}(A_j)$, then there exists some $k \in J$ such that $p \in \operatorname{cl}(A_k)$. Let $U$ be a neighborhood of $p$. From part (3), we know that $U \cap A_k \neq \varnothing$, and so is $U \cap \bigcup_{j \in J} A_j \neq \varnothing$. But $U$ is arbitrary, so we should have $p \in \operatorname{cl} \left( \bigcup_{j \in J} A_j \right)$.
    \item
    \begin{align*}
        \operatorname{cl}(A \cup B) & = X \setminus \operatorname{int}(X \setminus (A \cup B))
        \\
        & = X \setminus \operatorname{int}((X \setminus A) \cap (X \setminus B))
        \\
        & = X \setminus (\operatorname{int}(X \setminus A) \cap \operatorname{int}(X \setminus B))
        \\
        & = (X \setminus \operatorname{int}(X \setminus A)) \cup (X \setminus \operatorname{int}(X \setminus B))
        \\
        & = \operatorname{cl}(A) \cup \operatorname{cl}(B)
    \end{align*}
    \item Since $\bigcap_{j \in J} A_j \subseteq A_j$, we have $\operatorname{cl} \left( \bigcap_{j \in J} A_j \right) \subseteq \operatorname{cl}(A_j)$ by monotonicity. Thus, $\operatorname{cl} \left( \bigcap_{j \in J} A_j \right) \subseteq \bigcap_{j \in J} \operatorname{cl}(A_j)$.
\end{enumerate}
\underline{Part 4:}
\begin{enumerate}[label=(\alph*)]
    \item Since $\operatorname{ext}(A)$ and $\operatorname{cl}(A)$ forms a partition on $X$, from the inclusion $\bigcup_{j \in J} \operatorname{cl}(A_j) \subseteq \operatorname{cl} \left( \bigcup_{j \in J} A_j \right)$ (part (3)), we get
    \begin{align*}
        \bigcap_{j \in J} \operatorname{ext}(A_j) = \bigcup_{j \in J} X \setminus \operatorname{cl}(A_j) = X \setminus \bigcup_{j \in J} \operatorname{cl}(A_j) \supseteq X \setminus \operatorname{cl} \left( \bigcup_{j \in J} A_j \right) = \operatorname{ext} \left( \bigcup_{j \in J} A_j \right)
    \end{align*}
    \item Similarly, $\operatorname{ext}(A \cup B) = X \setminus \operatorname{cl}(A \cup B) = X \setminus (\operatorname{cl}(A) \cup \operatorname{cl}(B)) = (X \setminus \operatorname{cl}(A)) \cap (X \setminus \operatorname{cl}(B)) = \operatorname{ext}(A) \cap \operatorname{ext}(B)$.
    \item Since $\bigcap_{j \in J} A_j \subseteq A_j$, we have $\operatorname{ext} \left( \bigcap_{j \in J} A_j \right) \supseteq \operatorname{ext} (A_j)$ by antitonicity. Hence, $\operatorname{ext} \left( \bigcap_{j \in J} A_j \right) \supseteq \bigcup_{j \in J} \operatorname{ext} (A_j)$.
\end{enumerate}
\underline{Part 5:}
\begin{enumerate}
    \item Taking the complement of both side of the inclusion, we can instead prove the following one
    \begin{align*}
        \operatorname{ext} \left( A \cup B \right) \cup \operatorname{int} \left( A \cup B \right) & \supseteq (\operatorname{ext}(A) \cup \operatorname{int}(A)) \cap (\operatorname{ext}(B) \cup \operatorname{int}(B))
    \end{align*}
    Let $p$ be a point in the RHS, then $p \in (\operatorname{ext}(A) \cup \operatorname{int}(A))$ and $p \in (\operatorname{ext}(B) \cup \operatorname{int}(B))$. Consider the following 2 cases
    \begin{enumerate}
        \item If either $p \in \operatorname{int}(A)$ or $p \in \operatorname{int}(B)$, WLOG, say $p \in \operatorname{int}(A)$. Let $U$ be an open neighborhood of $p$ contained in $A$. Then $U$ is also contained in $A \cup B$. From part (1), we get $p \in \operatorname{int} \left( A \cup B \right)$.
        \item If $p \in \operatorname{ext}(A)$ \textit{and} $p \in \operatorname{ext}(B)$, then $p \in \operatorname{ext}(A) \cap \operatorname{ext}(B) = \operatorname{ext}(A \cup B)$.
    \end{enumerate}
    \item Apply part (3), we get $\partial A \subseteq \operatorname{cl}(A)$ and $\partial A \subseteq \operatorname{cl}(X \setminus A)$, so $\partial A \subseteq \operatorname{cl}(A) \cap \operatorname{cl}(X \setminus A)$. Vice versa, if $p \in \operatorname{cl}(A) \cap \operatorname{cl}(X \setminus A)$, then any neighborhood of $p$ must intersect both $A$ and $X \setminus A$, hence $p \in \partial A$.
\end{enumerate}
\underline{Part 6:} the first 6 are trivial.
\begin{enumerate}[label=(\alph*)] \setcounter{enumi}{6}
    \item $ck = e$ is clear from partition property. As for $e = ic$, note that $p \in \operatorname{ext}(A)$ iff $p \in U \cap A = \varnothing$ for some open set $U$, and iff $p \in U \subseteq X \setminus A$, which is just $p \in \operatorname{int}(X \setminus A)$.
    \item $cb = i \vee e$ is also from partition property. For $cb = eb$, note that $X \setminus \partial A$ is open, so $\operatorname{ext}(\partial A) \supseteq X \setminus \partial A$. On the other hand, $\operatorname{ext}(\partial A) \cap \partial A = \varnothing$ by construction, so we get $X \setminus \partial A = \operatorname{ext}(\partial A)$.
    \item $k^2 = k$ follows from $A = \operatorname{cl}(A)$ iff $A$ is closed.
    \item Same for $kb = b$ as the boundary of a set is always closed.
    \item Left-multiply and right-multiply $c$ on both side of $ck = ic$, we get $kc = Ikc = c(ck)c = c(ic)c = ciI = ci$.
    \item $ik = iIk = (ic)(ck) = e^2$.
    \item $i^2 = i$ follows from $A = \operatorname{int}(A)$ iff $A$ is open.
    \item Same as above.
    \item Firstly, suppose $U$ is open, we need to show that $\operatorname{int}(\partial U) = \varnothing$. Since $U$ is open, $\operatorname{int}(U) = U$, and $\partial U = \operatorname{cl}(U) \setminus U = \operatorname{cl}(U) \cap (X \setminus U)$. Hence,
    \begin{align*}
        \operatorname{int}(\partial U) = \operatorname{int}(\operatorname{cl}(U)) \cap \operatorname{int}(X \setminus U) = \operatorname{int}(\operatorname{cl}(U)) \cap (X \setminus \operatorname{cl}(U))
    \end{align*}
    Now, note that $A = \operatorname{int}(\operatorname{cl}(U))$ is a subset of $\operatorname{cl}(U)$, while $B = X \setminus \operatorname{cl}(U)$ is disjoint from $\operatorname{cl}(U)$. Thus, $\operatorname{int}(\partial U) = A \cap B = \varnothing$.
    \\
    \\
    Secondly, suppose $C$ is closed, then $\partial C = C \setminus \operatorname{int}(C) = C \cap (X \setminus \operatorname{int}(C))$ and so
    \begin{align*}
        \operatorname{int}(\partial C) = \operatorname{int}(C) \cap \operatorname{int}(X \setminus \operatorname{int}(C)) = \operatorname{int}(C) \cap (X \setminus \operatorname{cl}(\operatorname{int}(C)))
    \end{align*}
    As $\operatorname{cl}(\operatorname{int}(C))$ contains $\operatorname{int}(C)$, $X \setminus \operatorname{cl}(\operatorname{int}(C))$ must be disjoint from $\operatorname{int}(C)$ due to it being a subset of $X \setminus \operatorname{int}(C)$. Therefore, $\operatorname{int}(\partial C) = \varnothing$.
    \item $ek = (ck)k = ck^2 = ck = e$.
    \item Since $e = ic$ (part 6g), $bc = c(i \vee ic)c = cic \wedge cic^2 = ci \wedge cic = c(i \vee ic) = c(cb) = Ib = b$ (part 6h).
    \item Note $b = k \wedge kc = k \wedge ci$ (part 5b and 6k), so
    \begin{enumerate}
        \item $bk = (k \wedge kc)k = k^2 \wedge kck = k \wedge k(ck)$. As $k \geq I$, we get $ck \leq cI = c$ and so $bk = k \wedge k(ck) \leq k \wedge kc = b$.
        \item $bi = (k \wedge ci)i = ki \wedge ci^2 = ki \wedge ci = ki \wedge kc$. As $i \leq I$, we get $ki \leq kI = k$, and so $bi = ki \wedge kc \leq k \wedge kc = b$.
        \item $b^2 = (k \wedge kc) b = kb \wedge kcb = b \wedge kcb \leq b$
    \end{enumerate}
    Suppose $ib = \bot$, then $b^2 = (k \wedge ci)b = kb \wedge cib = b \wedge c\bot = b \wedge \top = b$. Translated back to the language of sets, we have
    \begin{align*}
        \partial (\partial A) = \operatorname{cl}(\partial A) \cap (X \setminus \operatorname{int}(\partial A)) = \partial A \cap (X \setminus \varnothing) = \partial A \cap X = \partial A
    \end{align*}
    Vice versa, suppose $b^2 = b$, then $b = b^2 = b \wedge c(ib)$, which only happens if $c(ib) \geq b$, or $ib \leq cb = eb$. However $i \wedge e = \bot$ (as the interior and exterior of a set are always disjoint), which shows that $ib = ib \wedge eb = (i \wedge e)b = \bot b = \bot$.
    \item Since $ibk = \bot$ (part 6o), we can use previous part 6r to show that $b^2 (kb) = b (kb)$, which results in $b^3 = b^2$. Translated to the language of sets, since $\operatorname{int}(\partial (\operatorname{cl}(A))) = \varnothing$, substituting $\partial A$ to $A$, we get
    \begin{align*}
        \partial \partial (\operatorname{cl}(\partial A)) & = \partial (\operatorname{cl}(\partial A)) \mbox{ or}
        \\
        \partial \partial \partial A & = \partial \partial A
    \end{align*}
    \item With $k(ckc)kck = k(ic^2)kck = kikck$ and $i(kck) \leq kck$, we get $kckckck \leq k(kck) = kck$. On the other hand,
    \begin{align*}
        ik & \leq k
        \\
        k(ik) & \leq k^2 = k
        \\
        ck(ik) & \geq ck
        \\
        kck(ckc)k = kck(ik) & \geq kck
    \end{align*}
    since $k$ is monotonic and $c$ is antitonic. Thus, $kckckck = kck$.
    \item Multiply $c$ to the previous equation in part (t) on the left, we get $(ck)^2 = (ck)^4$, or $e^2 = e^4$ (from part g)
    \item A result of part (l) and (u).
\end{enumerate}
\end{proof}

\subsection{Denseness}
A set $A$ is
\begin{enumerate}
    \item \emph{Dense} (in $X$) if $X = \operatorname{cl}(A)$.
    \item \emph{Nowhere dense} (in $X$) if $\operatorname{int}(\operatorname{cl}(A)) = \varnothing$
\end{enumerate}
\begin{proposition} \ 
\begin{enumerate}
    \item Properties of dense sets:
    \begin{enumerate}
        \item A set is dense if and only if it meets with every non-empty open set.
        \item Supersets of dense set is still dense.
        \item The collection of \textit{open} dense sets forms a filter on $X$ (may contain only $X$).
        \item The only dense set in a discrete space is the space itself.
        \item Any nonempty subset of an indiscrete space is dense.
    \end{enumerate}
    \item Properties of nowhere dense sets:
    \begin{enumerate}
        \item TFAE:
        \begin{enumerate}
            \item $A$ is nowhere dense.
            \item The complement of $A$ contains an open dense subset.
            \item The closure of $A$ is the boundary of some open set (in particular, the closure of $A$ is exactly the boundary of $X \setminus \operatorname{cl}(A)$).
            \item $A$ is a subset of the boundary of some open set.
            \item For each non-empty open set $U$, there exists a non-empty open subset $V$ of $U$ that is disjoint from $A$.
        \end{enumerate}
        \item The collection of nowhere dense sets forms an ideal on $X$.
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:}
\begin{enumerate}[label=(\alph*)]
    \item Suppose $A$ is dense, and let $U$ be a non-empty open set. Take any $p \in U$, then since $\operatorname{cl}(A) = X$, $U$ must meets $A$ at some point (possibly $p$). Vice versa, suppose $A$ meets with every non-empty open set, we let $p \in X$ and $U$ be any open neighborhood of $p$. By assumption, $U \cap A = \varnothing$, so $p$ must lie in the closure of $A$. In other words, $X \subseteq \operatorname{cl}(A)$ (since $p$ is arbitrary), and so $X = \operatorname{cl}(A)$.
    \item Suppose $\operatorname{cl}(A) = X$, and $A \subseteq B$. Then by monotonicity, $\operatorname{cl}(A) \subseteq \operatorname{cl}(B) \subseteq X$, so $\operatorname{cl}(B)$ must be the whole space $X$, i.e. $B$ is dense.
    \item By part (1b), we only need to show intersection of 2 open dense sets is still dense (the openness is implied by the axioms of topology). Suppose $A, B$ are open dense sets, and $U$ an arbitrary \textit{non-empty} open set. Then $A \cap U$ is also non-empty and open (by part 1a), and $(A \cap B) \cap U = B \cap (A \cap U)$ is also non-empty and open. Hence, by equivalent definition, $A \cap B$ must be dense.
    \item If $A$ is dense in a discrete space, then $A = \operatorname{cl}(A) = X$.
    \item Since the only non-empty closed set in an indiscrete space $X$ is $X$ itself, $\operatorname{cl}(A) = X$ for any non-empty $A$.
\end{enumerate}
\underline{Part 2:}
\begin{enumerate}[label=(\alph*)]
    \item We prove $(i) \Rightarrow (ii) \Rightarrow (iii) \Rightarrow (iv) \Rightarrow (v) \Rightarrow (i)$. Note that $(iii) \Rightarrow (iv)$ is straight forward.
    \\
    \\
    Suppose $A$ is nowhere dense, then
    \begin{align*}
        \operatorname{int}(\operatorname{cl}(A)) = \varnothing \leftrightarrow X = X \setminus \operatorname{int}(\operatorname{cl}(A)) = \operatorname{cl}(X \operatorname{cl}(A)) = \operatorname{cl}(\operatorname{int}(X \setminus A))
    \end{align*}
    Hence, $\operatorname{int}(X \setminus A)$ is dense and open. Since $\operatorname{int}(X \setminus A) \subseteq X \setminus A$, the complement of $A$ contains an open dense subset.
    \\
    \\
    Suppose $V \subseteq X \setminus A$ is an open dense set, then $\operatorname{int}(X \setminus A) = X \setminus \operatorname{cl}(A)$, which must contains $V$ by maximality, is also open dense. Yet
    \begin{align*}
        X = \operatorname{cl}(X \setminus \operatorname{cl}(A)) = X \setminus \operatorname{int}(\operatorname{cl}(A))
    \end{align*}
    Hence, $\operatorname{int}(\operatorname{cl}(A)) = \varnothing$, which results in
    \begin{align*}
        \partial (X \setminus \operatorname{cl}(A)) = \partial (\operatorname{cl}(A)) = \operatorname{cl}(\operatorname{cl}(A)) \setminus \operatorname{int}(\operatorname{cl}(A)) = \operatorname{cl}(A)
    \end{align*}
    \\
    Suppose $A \subseteq \partial U$ for some open set $U$, then $\operatorname{int}(\operatorname{cl}(A)) \subseteq \operatorname{int}(\operatorname{cl}(\partial U)) = \operatorname{int}(\partial U)$ by monotonicity. However, $\operatorname{int}(\partial U) = \varnothing$ by \hyperref[topo-subset-alg-prop-1]{Proposition \ref*{topo-subset-alg-prop-1}} (part 6o), so $\operatorname{int}(\operatorname{cl}(A)) = \varnothing$. From there, we get $\operatorname{cl}(\operatorname{int}(X \setminus A)) = X \setminus \operatorname{int}(\operatorname{cl}(A)) = X$. Denote $W = \operatorname{int}(X \setminus A)$, which is a dense open set. For each non-empty open set $U$, let $V = U \cap W$ be an open subset of $U$. Since $W$ is dense, $V$ is not empty (part 1a), so we have found a non-empty open subset of any non-empty open set that is disjoint from $A$ (as $V \subseteq W \subseteq X \setminus A$).
    \\
    \\
    Suppose for each non-empty open set $U$, there exists a non-empty open subset $V$ of $U$ that is disjoint from $A$. Take $W = \operatorname{int}(X \setminus A) = X \setminus \operatorname{cl}(A)$, let $U$ be any non-empty open subset of $X$. By the hypothesis, let $V$ be a non-empty open subset of $U$ that is disjoint from $A$ (so $V \subseteq X \setminus A$). By maximality, $V \subseteq W$, so $W \cap U$ is not empty. By part 1a, $W$ is dense, i.e. $\operatorname{cl}(\operatorname{int}(X \setminus A)) = X \setminus \operatorname{int}(\operatorname{cl}(A)) = X$, so $\operatorname{int}(\operatorname{cl}(A)) = \varnothing$, i.e. $A$ is nowhere dense.
    \item We first show if $A \subseteq B$, and $B$ is nowhere dense, then $A$ is nowhere dense. Indeed, $\operatorname{int}(\operatorname{cl}(A)) \subseteq \operatorname{int}(\operatorname{cl}(B)) = \varnothing$ by monotonicity.
    \\
    \\
    Next, we show that union of 2 nowhere dense sets $A$ and $B$ is again nowhere dense. Let $U$ be any non-empty open set, then from part (2a), there exists a non-empty open subset $V$ of $U$ disjoint from $A$, and a non-empty open subset $W$ of $V$ disjoint $B$. Thus, $W$ is disjoint from $A \cup B$ (as $W \subseteq V$, and $V \cap A = \varnothing$). By equivalent definition, $A \cup B$ must be nowhere dense set.
\end{enumerate}
\end{proof}
\ \\
The \emph{density} $d(X)$ of $X$ is the least cardinality of a dense set in $X$.
\begin{remark} \ 
\begin{enumerate}
    \item Since $X$ is a dense set itself, the density of the space is $\leq |X|$.
    \item Since the class of cardinal numbers is well-ordered, there must exist a dense subset of $X$ with cardinality equal to the density.
\end{enumerate}
\end{remark}
\begin{proposition}
If $\mathcal{B}$ is a basis on $X$, then there exists a dense subset $S$ of $X$ such that $|S| \leq |\mathcal{B}|$. As a result, $d(X) \leq w(X)$.
\end{proposition}
\begin{proof}
Assuming axiom of choice, pick $x_B \in B$ for each $B \in \mathcal{B}$, and collect them into a set $S$. The map from $\mathcal{B}$ to $S$ by sending $B$ to $x_B$ is then a surjection, so we must have $|\mathcal{B}| \leq |S|$. We now show that $S$ is dense. For any $p \in X$ and $N$ a neighborhood of $p$, there exists some $B \in \mathcal{B}$ such that $p \in B \subseteq N$. Since $x_B \in B$, $S \cap N$ is non-empty. By definition, $p \in \operatorname{cl}(S)$, and so $\operatorname{cl}(S) = X$.
\end{proof}

\subsection{Regularity}
An set $U$ is \emph{regularly open} if $U = \operatorname{int}(\operatorname{cl}(U))$. Likewise, a set $C$ is \emph{regularly closed} if $C = \operatorname{cl}(\operatorname{int}(C))$. As defined, a regularly open set is open, while a regularly closed set is closed.
\begin{proposition} \ 
\begin{enumerate}
    \item Both $X$ and $\varnothing$ are regular open and regular closed sets.
    \item A set is regularly open iff its complement is regularly closed.
    \item An open set $U$ is regular iff $\partial \operatorname{cl}(U) = \partial U$.
    \item A closed set $C$ is regular iff $\partial \operatorname{int}(C) = \partial C$.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:}
\begin{align*}
    \operatorname{cl}(\operatorname{int}(X)) = \operatorname{cl}(X) & = X
    \\
    \operatorname{cl}(\operatorname{int}(\varnothing)) = \operatorname{cl}(\varnothing) & = \varnothing
    \\
    \operatorname{int}(\operatorname{cl}(X)) = \operatorname{cl}(X) & = X
    \\
    \operatorname{int}(\operatorname{cl}(\varnothing)) = \operatorname{cl}(\varnothing) & = \varnothing
\end{align*}
\underline{Part 2:} if $U$ is regularly open, then $\operatorname{cl}(\operatorname{int}(X \setminus U)) = \operatorname{cl}(X \setminus \operatorname{cl}(U)) = X \setminus \operatorname{int}(\operatorname{cl}(U)) = X \setminus U$. Hence $X \setminus U$ is regularly closed. The reverse direction is similar.
\\
\underline{Part 3:} if $U$ is regularly open, then $\partial \operatorname{cl}(U) = \operatorname{cl}(\operatorname{cl}(U)) \setminus \operatorname{int}(\operatorname{cl}(U)) = \operatorname{cl}(U) \setminus U = \partial U$. Vice versa, if $\partial U = \partial \operatorname{cl}(U)$, then
\begin{align*}
    \operatorname{int}(U) = \operatorname{cl}(U) \setminus \partial U = \operatorname{cl}(\operatorname{cl}(U)) \setminus \partial \operatorname{cl}(U) = \operatorname{int}(\operatorname{cl}(U))
\end{align*}
Since $U$ is open we get $U = \operatorname{int}(U) = \operatorname{int}(\operatorname{cl}(U))$. Hence $U$ is regular
\\
\underline{Part 4:} a combination of part (2) and (3). Indeed, suppose $C$ is regularly closed. Then $X \setminus C$ is regularly open, and thus, $\partial C = \partial (X \setminus C) = \partial \operatorname{cl}(X \setminus C) = \partial (X \setminus \operatorname{int}(C)) = \partial \operatorname{int}(C)$. Vice versa, if $\partial C = \partial \operatorname{int}(C)$, then
\begin{align*}
    C = \operatorname{cl}(C) = \partial C \cup \operatorname{int}(C) = \partial \operatorname{int}(C) \cup \operatorname{int}(\operatorname{int}(C)) = \operatorname{cl}(\operatorname{int}(C))
\end{align*}
which shows that $C$ is regular.
\end{proof}
A space $X$ is called a \emph{partition space} if there exists a basis on $X$ such that it is also a partition on $X$.
\begin{theorem}
The followings are equivalent
\begin{enumerate}
    \item $X$ is a partition space.
    \item Every closed set is regular.
    \item Every open set is regular.
    \item Every closed set is open.
    \item Every open set is closed.
\end{enumerate}
\end{theorem}
\begin{proof}
We show that $(1) \Rightarrow (2) \Rightarrow (3) \Rightarrow (4) \Rightarrow (5) \Rightarrow (1)$.
\\
*Suppose $X$ is a partition space: let $\mathcal{B}$ be a basis in $X$ such that it is also a partition on $X$. Given $C$ a closed set, then $U = X \setminus C$ is open and so $U = \bigcup_{\substack{B \subseteq U \\ B \in \mathcal{B}}} B$. Yet $\mathcal{B}$ is a partition, so $C = X \setminus U = \bigcup_{\substack{B \not\subseteq U \\ B \in \mathcal{B}}} B = \bigcup_{\substack{B \subseteq C \\ B \in \mathcal{B}}} B$. By definition, $C$ is open, and so $\operatorname{cl}(\operatorname{int}(C)) = \operatorname{cl}(C) = C$.
\\
\\
*Suppose every closed set is regular: since an open set is regular if and only if its complement, which is closed, is also regular, we conclude that every open set is regular.
\\
\\
*Suppose every open set is regular: let $A$ be a \textit{non-empty} subset of $X$. Denote $R = \operatorname{int}(X \setminus A)$, which is closed. Since $\operatorname{cl}(R \cup A) = \operatorname{cl}(R) \cup \operatorname{cl}(A) \supseteq R \cup \operatorname{cl}(A) = (X \setminus \operatorname{cl}(A)) \cup \operatorname{cl}(A) = X$, we know that $R \cup A$ is dense in $X$.
\\
\\
If $A \subseteq R$, then by minimality, $\operatorname{cl}(A) \subseteq R$. Hence, $X = \operatorname{cl}(R \cup A) = \operatorname{cl}(R)$. By regularity hypothesis, $X = \operatorname{int}(\operatorname{cl}(R)) = R \subseteq X \setminus A$, which forces $A$ to be empty, a contradiction. Hence, $A \not\subseteq \operatorname{cl}(R)$, or equivalently, $A \cap (X \setminus \operatorname{cl}(R)) \neq \varnothing$. In particular, by setting $A = \{ p \}$ to be a singleton, we get $p \in X \setminus \operatorname{cl}(\operatorname{int}(X \setminus \{ p \}))$
\\
\\
Furthermore, $\operatorname{cl} (X \setminus \operatorname{cl}(R)) = X \setminus \operatorname{int}(\operatorname{cl}(R)) = X \setminus R = \operatorname{cl}(A)$. Let $A = \{ p \}$, we get $\operatorname{cl}(\operatorname{int}(X \setminus \{ p \}))) = \operatorname{cl}(\{ p \})$
\\
\\
So given $K$ a closed set, and any $p \in K$, we know that $\operatorname{cl}(\{ p \}) \subseteq K$ and thus,
\begin{align*}
    p \in X \setminus \operatorname{cl}(\operatorname{int}(X \setminus \{ p \})) \subseteq \operatorname{cl} [X \setminus \operatorname{cl}(\operatorname{int}(X \setminus \{ p \}))] = \operatorname{cl}(\{ p \}) \subseteq K
\end{align*}
In short, we have found an open neighborhood $U = X \setminus \operatorname{cl}(\operatorname{int}(X \setminus \{ p \}))$ of $p$ such that $U \subseteq K$. As $p$ varies in $K$, we know that $K$ is open.
\\
\\
*Suppose every closed set is open: by complementary, we know that every open set is closed.
\\
\\
*Suppose every open set is closed: let $E_p$ be the intersection of all open set containing $p \in X$. By the hypothesis, $E_p$ is closed, so $\operatorname{cl}(\{ p \}) \subseteq E_p$ by minimality. Vice versa, if $C$ is a closed containing $p$, then $C$ is also open, as $X \setminus C$ will be both open and closed set. Hence, $E_p \subseteq C$ for all closed sets containing $p$. By definition, $E_p \subseteq \bigcap_{\substack{p \in C \\ C \text{ closed}}} C = \operatorname{cl}(\{ p \})$.
\\
\\
Next, if $x \in E_p = \operatorname{cl}(\{ p \})$, then $E_x = \operatorname{cl}(\{ x \}) \subseteq E_p$ by minimality. On the other hand, for any open neighborhood $V$ of $x$, we must have $V \cap \{ p \} \neq \varnothing$, or $p \in V$ simply. Thus, $p$ is in the $E_x$, the intersection of open neighborhoods of $x$. We then argue similarly that $E_p \subseteq E_x$, and so $E_p = E_x$ whenever $x \in E_p$.
\\
\\
It is then true that $\{ E_p : p \in X \}$ forms a basis and a partition on $X$. Indeed
\begin{enumerate}
    \item $\bigcup_{p \in X} E_p = \bigcup_{p \in X} \operatorname{cl}(\{ p \}) \supseteq \bigcup_{p \in X} \{ p \} = X$.
    \item If $E_p \cap E_q$ is nonempty, let $x \in E_p \cap E_q$. By the previous observation, we get $E_p = E_x =  E_q$.
    \item Since $E_p$ is closed, $X \setminus E_p$ is open. By the hypothesis, $X \setminus E_p$ is closed, and so $E_p$ is open.
    \item Finally, if $U$ is open, and $p \in U$, then $U$ is closed (by the hypothesis), and so $E_p = \operatorname{cl}(\{ p \}) \subseteq \operatorname{cl}(U) = U$
\end{enumerate}
\end{proof}

\subsection{Locally finite collection}
A collection $\mathcal{A}$ of subsets of $X$ is \emph{locally finite} if there exists a neighborhood around each point that intersects finitely many sets of $\mathcal{A}$. This includes any finite family of subsets of $X$
\begin{proposition}
Suppose $\{ A_j \}_{j \in J}$ is a locally finite collection, show that
\begin{enumerate}
    \item $\operatorname{cl} \left( \bigcup_{j \in J} A_j \right) = \bigcup_{j \in J} \operatorname{cl}(A_j)$
    \item $\operatorname{int} \left( \bigcap_{j \in J} A_j \right) = \bigcap_{j \in J} \operatorname{int}(A_j)$
    \item $\operatorname{ext} \left( \bigcup_{j \in J} A_j \right) = \bigcap_{j \in J} \operatorname{ext}(A_j)$
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} by \hyperref[topo-subset-top-prop-1]{Proposition \ref*{topo-subset-top-prop-1}}, we just need to show that $\operatorname{cl} \left( \bigcup_{j \in J} A_j \right) \subseteq \bigcup_{j \in J} \operatorname{cl}(A_j)$. Let $p \notin \bigcup_{j \in J} \operatorname{cl}(A_j)$, then $p \notin \operatorname{cl}(A_j)$ for all $j \in J$. By local finiteness, there exists an open neighborhood $V$ of $p$ such that $Z = \{ j \in J : A_j \cap U \neq \varnothing \}$ is finite. For each $j \in Z$, let $U_j$ be some open neighborhood of $p$ that is disjoint from $A_j$. Denote $W = V \cap \bigcup_{j \in Z} U_j$, which is open since it is an intersection of $|Z|+1$ open sets.
\\
\\
We verify that $W$ is disjoint with $A_j$ for \textit{all} $j \in J$. Indeed, consider 2 cases
\begin{enumerate}
    \item $j \in Z$: since $W \subseteq U_j$, $W$ is disjoint from $A_j$ by construction of $U_j$.
    \item $j \notin Z$: by definition, $V \cap A_j = \varnothing$. With $W \subseteq V$, we conclude that $W$ is disjoint from $A_j$.
\end{enumerate}
Thus, we have found, for each $p \notin \bigcup_{j \in J} \operatorname{cl}(A_j)$, an open neighborhood around it that is disjoint with $\bigcup_{j \in J} \operatorname{cl}(A_j)$. This means $\bigcup_{j \in J} \operatorname{cl}(A_j)$ is closed, and so, by minimality of closure, we get $\operatorname{cl} \left( \bigcup_{j \in J} A_j \right) \subseteq \bigcup_{j \in J} \operatorname{cl}(A_j)$ (note both side contains $\bigcup_{j \in J} A_j$).
\\
\underline{Part 2:} follows from part 1 directly
\begin{align*}
    \operatorname{int} \left( \bigcap_{j \in J} A_j \right) & = X \setminus \operatorname{cl} \left( X \setminus \bigcap_{j \in J} A_j \right) = X \setminus \operatorname{cl} \left( \bigcup_{j \in J} X \setminus A_j \right)
    \\
    & = X \setminus \bigcup_{j \in J} \operatorname{cl} (X \setminus A_j) = \bigcap_{j \in J} X \setminus \operatorname{cl} (X \setminus A_j)
    \\
    & = \bigcap_{j \in J} \operatorname{int}(A_j)
\end{align*}
\\
\underline{Part 3:} similar to part 2
\begin{align*}
    \operatorname{ext} \left( \bigcup_{j \in J} A_j \right) & = X \setminus \operatorname{cl}\left( \bigcup_{j \in J} A_j \right) = X \setminus \bigcup_{j \in J} \operatorname{cl}(A_j)
    \\
    & = \bigcap_{j \in J} X \setminus \operatorname{cl}(A_j) = \bigcap_{j \in J} \operatorname{ext}(A_j)
\end{align*}
\end{proof}
\underline{Proof Note:} in part 1, we only pick a finite number of $U_j$ so there's no need for axiom of choice.

\subsection{Limit points. Isolated points}
Let $A$ be a subset of a topological space $X$. A point $p$ in $X$ is said to be
\begin{enumerate}
    \item A \emph{limit} point of $A$ if each neighborhood $U$ of $p$ contains at least some point of $A$ other than $p$ itself. In other words, $A \cap (U \setminus \{ p \}) \neq \varnothing$.
    \item An \emph{isolated} point of $A$ if $p \in A$, and there exists a neighborhood $U$ of $p$ such that $p$ is the only common point between $U$ and $A$. In other words, $A \cap (U \setminus \{ p \}) = \varnothing$.
\end{enumerate}
The set of limit points is denoted with $\operatorname{lp}(A)$ (or $A'$), called the \emph{derived set} of $A$. The set if isolated points is denoted with $\operatorname{ip}(A)$ (which is a subset of $A$).
\begin{proposition} \label{lim-iso-topo-prop} \ 
\begin{enumerate}
    \item $\operatorname{lp}(A)$ and $\operatorname{ip}(A)$ forms a partition on $\operatorname{cl}(A)$.
    \item $\operatorname{lp}(A)$ and $A$ covers $\operatorname{cl}(A)$.
    \item $A$ is closed iff $\operatorname{lp}(A) \subseteq A$.
    \item If $A$ is closed, then $\operatorname{lp}(A)$ is closed.
    \item TFAE:
    \begin{enumerate}
        \item $p$ is a limit point of $A$.
        \item $p$ lies in the closure of $A \setminus \{ p \}$.
        \item $p$ is a limit point of $A \setminus \{ p \}$.
    \end{enumerate}
    \item If $\{ p \}$ is open, then $p$ is an isolated point of any set containing it. We also have a partial converse, if $p$ is an isolated point of the space, then $\{ p \}$ is open.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} if $p$ is both a limit point and an isolated point, then $p \in A$ and there exists some neighborhood $U$ of $p$ such that
\begin{enumerate}
    \item $U$ contains some point in $A$ other than $p$.
    \item The only point in common with $U$ and $A$ is $p$.
\end{enumerate}
A contradiction! So $\operatorname{lp}(A)$ and $\operatorname{ip}(A)$ are disjoint. Now for each $p \in \operatorname{cl}(A)$ since any neighborhood $U$ of $p$ must meet $A$ at some point (i.e. $|U \cap A| \geq 1$), there are 2 cases
\begin{enumerate}
    \item Any neighborhood $U$ contains at least some point in $A$ other than $p$. By definition, $p$ is a limit point.
    \item Some neighborhood $U$ contains no point in $A$ other than $p$. Since $U \cap A \neq \varnothing$, $p$ has to be in the intersection, and so $U \cap A = \{ p \}$. By definition, $p$ is an isolated point.
\end{enumerate}
\underline{Part 2:} let $p \in \operatorname{cl}(A)$, if $p \notin A$ then since each neighborhood $U$ must meet $A$ at some point, such point cannot be $p$. By definition, $p$ has to be a limit point of $A$.
\\
\underline{Part 3:} by previous part (2), we have $\operatorname{cl}(A) = A \cup \operatorname{lp}(A) \subseteq A$. Yet $A \subseteq \operatorname{cl}(A)$ always hold, so we obtain $A = \operatorname{cl}(A)$, i.e. $A$ is closed. Vice versa, if $A$ is closed, then $A = \operatorname{cl}(A) = A \cup \operatorname{lp}(A)$, which holds only if $\operatorname{lp}(A) \subseteq A$.
\\
\underline{Part 4:} since $A$ is closed, we have $\operatorname{lp}(A) \subseteq A$. We will show that $\operatorname{lp}(\operatorname{lp}(A)) \subseteq \operatorname{lp}(A)$ (which in turns imply that $\operatorname{lp}(A)$ is closed by part 2). Let $p \in \operatorname{lp}(\operatorname{lp}(A))$, and $U$ be a neighborhood of $p$. Then $U$ meets $\operatorname{lp}(A)$ at some point other than $p$. Yet $\operatorname{lp}(A) \subseteq A$, so we have $U$ meets $A$ at some point other than $p$. Hence, $p \in \operatorname{lp}(A)$.
\\
\underline{Part 5:} we will prove in the direction $(a) \Rightarrow (b) \Rightarrow (c) \Rightarrow (a)$
\begin{enumerate}
    \item Suppose $p$ is a limit point of $A$, then $A \cap (U \setminus \{ p \}) \neq \varnothing$ whenever $U$ is a neighborhood of $p$. Note that $A \cap (U \setminus \{ p \}) = A \cap [U \cap (X \setminus \{ p \})] = [A \cap (X \setminus \{ p \})] \cap U = (A \setminus \{ p \}) \cap U$, we conclude that $p$ must lie in $\operatorname{cl}(A \setminus \{ p \})$.
    \item Suppose $p$ lies in the closure of $A \setminus \{ p \}$, let $U$ be an open neighborhood of $p$. Then $U \cap (A \setminus \{ p \}) \neq \varnothing$, note that any point in such intersection must be different from $p$ due to $A \setminus \{ p \}$. Hence, $p$ must be a limit point of $A \setminus \{ p \}$.
    \item Suppose $p$ is a limit point $A \setminus \{ p \}$, then each neighborhood of $p$ must contain some point, other than $p$, in $A \setminus \{ p \} \subseteq A$. This means $p$ is also a limit point of $A$.
\end{enumerate}
\underline{Part 6:} just take $U = \{ p \}$ to be the open neighborhood of $p$. Vice versa, if $p$ is an isolated point of $X$, then there exists an open neighborhood $U$ of $p$ such that $U \cap X = \{ p \}$. But $U \subseteq X$, so $U = \{ p \}$, i.e. $\{ p \}$ is open.
\end{proof}
\begin{proposition} \label{lim-iso-lat-prop} \ 
\begin{enumerate}
    \item Properties of derived set:
    \begin{enumerate}
        \item $A \subseteq B$ implies $\operatorname{lp}(A) \subseteq \operatorname{lp}(B)$
        \item $\operatorname{lp}(\operatorname{lp}(A)) \subseteq \operatorname{lp}(A) \cup A = \operatorname{cl}(A)$
        \item $\bigcup_{i \in I} \operatorname{lp} (A_i) \subseteq \operatorname{lp} \left( \bigcup_{i \in I} A_i \right)$
        \item $\operatorname{lp}(\operatorname{cl}(A)) = \operatorname{cl}(\operatorname{lp}(A))$
    \end{enumerate}
    \item Properties of set of isolated points:
    \begin{enumerate}
        \item $\operatorname{ip}(A) \subseteq A$
        \item $\operatorname{ip}(\operatorname{ip}(A)) = \operatorname{ip}(A)$
        \item $\operatorname{ip} \left( \bigcup_{i \in I} A_i \right) \subseteq \bigcup_{i \in I} \operatorname{ip}(A_i)$ 
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:}
\begin{enumerate}[label=(\alph*)]
    \item Let $p \in \operatorname{lp}(A)$, and $U$ be an open neighborhood of $p$. There exists some $q \in U \cap A$ that is distinct from $p$. But $A \subseteq B$, so $q \in U \cap B$. Thus, $p \in \operatorname{lp}(B)$.
    \item Let $p \in \operatorname{lp}(\operatorname{lp}(A))$ yet $p \notin A$, and $U$ be an open neighborhood of $p$. Then there exists some $q \in U \cap \operatorname{lp}(A)$ such that $q \neq p$. As $U$ is also a neighborhood of $q \in \operatorname{lp}(A)$, there exists another $r \in U \cap A$ such that $r \neq q$. Since $r \in A$ yet $p \notin A$, we must have $r \neq p$. Thus, there is always some point in $U \cap A$ other than (possibly) $p$. But $U$ is arbitrary, so we get $p \in \operatorname{lp}(A)$. On the other hand, the equality $\operatorname{lp}(A) \cup A = \operatorname{cl}(A)$ comes from previous proposition.
    \item From part (1a), we already have $\operatorname{lp}(A_i) \subseteq \operatorname{lp} \left( \bigcup_{i \in I} A_i \right)$, or $\bigcup_{i \in I} \operatorname{lp}(A) \subseteq \operatorname{lp} \left( \bigcup_{i \in I} A_i \right)$.
    \item For the reverse inclusion, suppose $p \notin \operatorname{lp}(A \cup B)$, we will show that $p \notin \operatorname{lp}(A) \cup \operatorname{lp}(B)$. By the hypothesis, there is some neighborhood $U, V$ of $p$ such that $U \cap A$ and $V \cap B$ is either empty or contains only $p$. Taking $W = U \cap V$ to be neighborhood of $p$, then we get $W \cap (A \cup B)$ is either empty or contains only $p$ (since $W \subseteq U, V$). In other words, $p \notin \operatorname{lp}(A \cup B)$.
    \item Applying part (1c), we get $\operatorname{lp}(\operatorname{cl}(A)) = \operatorname{lp}(\operatorname{lp}(A) \cup A) = \operatorname{lp}(\operatorname{lp}(A)) \cup \operatorname{lp}(A) = \operatorname{cl}(\operatorname{lp}(A))$.
\end{enumerate}
\underline{Part 2:}
\begin{enumerate}[label=(\alph*)]
\setcounter{enumi}{1}
    \item Note that $\operatorname{ip}(A) \subseteq A$ (by definition) for any set $A$, so $\operatorname{ip}(\operatorname{ip}(A)) \subseteq \operatorname{ip}(A)$. Vice versa, let $p \in \operatorname{ip}(A)$, then there exists some neighborhood $N$ of $p$ such that $N \cap A = \varnothing$. Since $A$ contains $\operatorname{ip}(A)$, it also holds that $N \cap \operatorname{ip}(A) = \varnothing$. By definition, $p \in \operatorname{ip}(\operatorname{ip}(A))$.
    \item If $p \in \operatorname{ip} \left( \bigcup_{i \in I} A_i \right)$, then there exists a neighborhood $N$ such that $N \cap \bigcup_{i \in I} A_i = \bigcup_{i \in I} N \cap A_i = \{ p \}$. In particular, there must be some $k \in I$ such that $N \cap A_k = \{ p \}$ (otherwise, the union will be empty). By definition, $p \in \operatorname{ip}(A_k)$, hence $p \in \bigcup_{i \in I} \operatorname{ip}(A_i)$.
\end{enumerate}
\end{proof}
\ \\
A set is \emph{discrete} if every point in it is an isolated point (i.e. $\operatorname{ip}(A) = A$). On the opposite side, a set is \emph{dense-in-itself} if no point in the set is an isolated point (i.e. $\operatorname{ip}(A) = \varnothing$). A \emph{perfect} set is then a dense-in-itself, closed set.
\begin{remark}
A discrete set is not necessarily closed. Take $K = \{ 1/n : n \in \mathbb{N} \}$ in $\mathbb{R}$ as an example.
\end{remark}
\begin{proposition} \ 
\begin{enumerate}
    \item Subsets of a discrete set are discrete themselves.
    \item Union of dense-in-itself sets is dense-in-itself.
    \item Open subsets of a dense-in-itself space are dense-in-itself themselves.
    \item A set is perfect iff every point in it is a limit point. In other words, $A$ is perfect if and only if $\operatorname{lp}(A) = A$.
    \item A set is dense-in-itself iff its closure is perfect. In particular, the closure of a dense-in-itself set is still dense-in-itself.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} let $A$ be a discrete set in $X$, and $B \subseteq A$. Then for each $p \in B$, there must exists some neighborhood $N$ of $p$ such that $N \cap A = \{ p \}$. Since $p \in B \subseteq A$, we also get $N \cap B = \{ p \}$. Therefore, $p$ is an isolated point of $B$.
\\
\underline{Part 2:} let $\{ A_i \}_{i \in I}$ be a family of dense-in-itself sets. Let $p \in \bigcup_{i \in I} A_i$, then $p \in A_k$ for some $k \in I$. In other words, for all neighborhood $N$ of $p$, $N$ meets $A_k$ at another point other than $p$ ($N \cap A_k$ cannot be empty since $p \in A_k$). Since $A_k \subseteq \bigcup_{i \in I} A_i$, $N$ must also meet at $\bigcup_{i \in I} A_i$ another point other than $p$. Hence, $p$ cannot be an isolated point of the union of $A_i$.
\\
\underline{Part 3:} suppose $X$ is dense-in-itself, and $U$ is open. If $p \in U$ is an isolated point, then there exists open neighborhood $W$ of $p$ such that $U \cap W = \{ p \}$. Since finite intersection of open sets is open, $\{ p \}$ is open in $X$. Therefore, $V = \{ p \}$ is an open neighborhod of $p$ such that $V \cap X = \{ p \}$, i.e. $p$ is an isolated point of $X$, contradicting the assumption.
\\
\underline{Part 4:} suppose $A$ is perfect, then $A = \operatorname{cl}(A) = \operatorname{lp}(A) \cup \operatorname{ip}(A)$. But it is dense-in-itself, so it must be the case that $\operatorname{ip}(A) = \varnothing$, or $A = \operatorname{lp}(A)$. Vice versa, if $A = \operatorname{lp}(A)$, then $A$ must be closed in particular, and so $\operatorname{lp}(A) = A = \operatorname{cl}(A) = \operatorname{lp}(A) \cup \operatorname{ip}(A)$. Yet $\operatorname{ip}(A) \cap \operatorname{lp}(A) = \varnothing$, so we get $\operatorname{ip}(A) = \varnothing$, or equivalently, $A$ is dense-in-itself. Combined with the fact $A$ is closed, we conclude $A$ is perfect.
\\
\underline{Part 5:} if $A$ is dense-in-itself, then $\operatorname{cl}(A) = \operatorname{lp}(A) \cup \operatorname{ip}(A) = \operatorname{lp}(A)$. On the other hand, $\operatorname{lp}(\operatorname{cl}(A)) = \operatorname{cl}(\operatorname{lp}(A))$ (for any subset $A$ of $X$), so $\operatorname{lp}(\operatorname{cl}(A)) = \operatorname{cl}(\operatorname{cl}(A)) = \operatorname{cl}(A)$. By part (4), $\operatorname{cl}(A)$ must be perfect. Vice versa, if $\operatorname{cl}(A) = \operatorname{lp}(A) = \operatorname{lp}(A) \cup \operatorname{ip}(A)$, then $\operatorname{ip}(A)$ must be empty (since $\operatorname{lp}(A)$ and $\operatorname{ip}(A)$ are disjoint). By definition, $A$ is dense-in-itself.
\end{proof}

\newpage

\section{Convergence}
Let $\mathcal{B}$ be a (non-empty) filter base on a topological space $X$. We say that $\mathcal{B}$ \emph{converges} to a point $x$ if for each neighborhood $N$ of $x$, there exists some $B \in \mathcal{B}$ such that $B \subseteq N$. We denote $\mathcal{B} \to x$, or $x \in \lim \mathcal{B}$.
\\
\underline{Note:} if $\lim \mathcal{B}$ is a singleton $\{ x \}$, then we can write $\lim \mathcal{B} = x$ instead of the convoluted set notation $x \in \lim \mathcal{B}$.
\begin{remark}
By definition of refinement, $\mathcal{B}$ converges to $x$ if and only if it refines the neighborhood filter $\mathcal{N}_x$ of $x$. Since the refinement relation is reflexive, this also means that $\mathcal{N}_x \to x$ for each $x \in X$.
\end{remark}
\begin{remark}
If $\mathcal{B}$ is a trivial filter base, i.e. $\varnothing \in \mathcal{B}$ (which can happen, for example, if $\mathcal{B}$ contains 2 sets that are disjoint), then it converges to any point in $X$. Thus, from now on, any filter base we mention is non-trivial (and thus also exclude, for example, the empty topological space).
\end{remark}
\begin{proposition} \label{conv-lat-prop} \ 
\begin{enumerate}
    \item Refinement: if $\mathcal{B} \to x$, and $\mathcal{C}$ refines $\mathcal{B}$, then $\mathcal{C} \to x$ also. In particular, $\lim \mathcal{C} \supseteq \lim \mathcal{B}$.
    \item Generated Filter: If $\mathcal{B}$ is a filter base, and $\mathcal{F}$ is the filter (which is itself a filter base) generated by $\mathcal{B}$, then $\mathcal{B} \to x$ if and only if $\mathcal{F} \to x$.
    \item Meet: if $\{ \mathcal{B}_i \}_{i \in I}$ is a family of filter bases converging to some $x$, then there exists some other filter base $\mathcal{C}$, also converging to $x$, such that $\mathcal{B}_i$ refines $\mathcal{C}$.
    \item Subsequentiality: let $x \in X$. If $\mathcal{B}$ is a filter base such that, whenever $\mathcal{C}$ refines $\mathcal{B}$, there exists another $\mathcal{D}$ refining $\mathcal{C}$ that converges to $x$, then $\mathcal{B}$ converges to $x$.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} by assumption, for each neighborhood $N$ of $x$, there exists $B \in \mathcal{B}$ and $C \in \mathcal{C}$ such that $B \subseteq N$ and $C \subseteq B$. Hence, there always exists $C \in \mathcal{C}$ such that $C \subseteq N$. As $N$ varies, $\mathcal{C} \to x$.
\\
\underline{Part 2:} note that $\mathcal{B} \subseteq \mathcal{F}$ (and so $\mathcal{F}$ refines $\mathcal{B}$), $\mathcal{B} \to x$ implies $\mathcal{F} \to x$ by part (1). Vice versa, given $\mathcal{B}$ refines $\mathcal{F}$ as, by definition, there exists some $B \in \mathcal{B}$ such that $B \subseteq F$ whenever $F \in \mathcal{F}$, then $\mathcal{F} \to x$ implies $\mathcal{B} \to x$.
\\
\underline{Part 3:} let $\mathcal{B}_i \to x$ for each $i \in I$. We define $\mathcal{C} = \{ C \subseteq X \mid \forall i \in I, \exists B \in \mathcal{B}_i : B_i \subseteq C \}$. This a filter base (and in fact, a filter) since
\begin{enumerate}
    \item Because $\mathcal{B}_i$ does not contain empty set, each set $C$ in $\mathcal{C}$ is non-empty since they need to contain some set in $\mathcal{B}_i$.
    \item If $C_1, C_2 \in \mathcal{C}$, there exists, for each $i \in I$, $B_1^i, B_2^i \in \mathcal{B}$ such that $B_n^i \subseteq C_n$ ($n = 1, 2$). Since $\mathcal{B}_i$ is a filter base, there exists another $B_i \in \mathcal{B}_i$ such that $B_i \subseteq B_1^i \cap B_2^i$. Thus, $B_i \subseteq B_1^i \cap B_2^i \subseteq C_1 \cap C_2$ for every $i \in I$, meaning $C_1 \cap C_2 \in \mathcal{C}$.
\end{enumerate}
$\mathcal{C}$ is also coarser than $\mathcal{B}_i$ because every $C$ is defined to contain some set in $\mathcal{B}_i$ for each $i \in I$. Finally, we also have $\mathcal{C} \to x$. Indeed, for each neighborhood $N$ of $x$, there exists some $B_i \in \mathcal{B}_i$ such that $B_i \subseteq N$. By definition, $N \in \mathcal{C}$ and so $\mathcal{C}$ contains the neighborhood filter at $x$.
\\
\underline{Part 4:} suppose $\mathcal{B}$ does not converge to $x$. Equivalently, there exists some neighborhood $N_0$ of $x$ such that $B \not\subseteq N_0$ for all $B \in \mathcal{B}$. In particular, $\mathcal{B}_0 = \{ B \setminus N_0 : B \in \mathcal{B} \}$ does not contain empty set. Furthermore, $\mathcal{B}_0$ is a filter base that refines $\mathcal{B}$
\begin{enumerate}
    \item If $B_1 \setminus N_0, B_2 \setminus N_0 \in \mathcal{B}_0$, there exists some $B \in \mathcal{B}$ such that $B \subseteq B_1 \cap B_2$. Therefore, $B \setminus N_0 \subseteq (B_1 \cap B_2) \setminus N_0 = (B_1 \setminus N_0) \cap (B_2 \setminus N_0)$.
    \item For each $B \in \mathcal{B}$, we have $B \setminus N_0 \in \mathcal{B}_0$ and $B \setminus N_0 \subseteq B$.
\end{enumerate}
Thus, by the hypothesis, there exists some $\mathcal{D}$ refining $\mathcal{B}_0$ that converges to $x$. In particular, pick any $B \in \mathcal{B}$, and there exists some $D_0, D_b \in \mathcal{D}$ such that $D_0 \subseteq N_0$ and $D_b \setminus B \setminus N_0$. There also some $D \in \mathcal{D}$ such that $D \subseteq D_0 \cap D_b \subseteq N_0 \cap (B \setminus N_0) = \varnothing$, contradicting the non-triviality of a filter base.
\end{proof}
\ 
\\
\begin{theorem}[Convergence as categorical limit]
Let $X$ be a topological space (with neighborhood filter $\mathcal{N}_x$) and $\mathfrak{F}X$ be the set of filters on $X$. Denote $\mathfrak{F}_{\mathcal{F}, x} = \{ \mathcal{G} \in \mathfrak{F}X : \mathcal{G} \supseteq \mathcal{F} \cup \mathcal{N}_x \}$. Note that both $\mathfrak{F}X$, $\mathfrak{F}_{\mathcal{F}, x}$, and any filter on $X$ can be considered as categories (as they are partially ordered under inclusion).
\\
\\
Next, define $E_x: \mathfrak{F}_{\mathcal{F}, x} \to \mathfrak{F}X$ to be the inclusion functor. Then $\mathcal{F} \to x$ if and only if $\mathcal{F}$ is the limit of $E_x$
\end{theorem}
\begin{proof}
Suppose $\mathcal{F}$ is a limit of $E_x$, then for any cone $\mathcal{N}$ to $E_x$, i.e. $\mathcal{N}$ is a filter such that $\mathcal{N} \subseteq \mathcal{G}$ for any $\mathcal{G} \in \mathfrak{F}_{\mathcal{F}, x}$, one must have $\mathcal{N} \subseteq \mathcal{F}$. In other words, $\mathcal{N} \subseteq \bigcap_{\mathcal{F} \cup \mathcal{N}_x \subseteq \mathcal{G}} \mathcal{G} = \mathcal{W}$ implies $\mathcal{N} \subseteq \mathcal{F}$. By construction, $\mathcal{W}$ is the filter generated by $\mathcal{F}$ and neighborhoods of $x$. Taking $\mathcal{N} = \mathcal{W}$, we get $\mathcal{W} \subseteq \mathcal{F}$. Hence $\mathcal{N}_x \subseteq \mathcal{F}$ in particular. By monotonicity, $\mathcal{F} \to x$.
\\
\\
Vice versa, suppose $\mathcal{F} \to x$, then $\mathcal{F} \supseteq \mathcal{N}_x$ (\hyperref[conv-lat-prop]{Proposition \ref*{conv-lat-prop}}), and so $\mathfrak{F}_{\mathcal{F}, x} = \{ \mathcal{G} \in \mathfrak{F}X : \mathcal{G} \supseteq \mathcal{F} \}$. Let $\mathcal{N}$ be a cone to $E_x$, i.e. $\mathcal{N}$ is a filter such that $\mathcal{N} \subseteq \mathcal{G}$ for all $\mathcal{G} \in \mathfrak{F}_{\mathcal{F}, x}$ (or $\mathcal{G} \supseteq \mathcal{F}$). This means that $\mathcal{N} \subseteq \bigcap_{\mathcal{G} \supseteq \mathcal{F}} \mathcal{F} = \mathcal{F}$. By definition, $\mathcal{F}$ is the limit of $E_x: \mathfrak{F}_{\mathcal{F}, x} \to \mathfrak{F}X$
\end{proof}

\subsection{Eventuality. Stationary}
Given a filter base $\mathcal{B}$ and a subset $S$ of $X$, we say that
\begin{enumerate}
    \item $S$ is $\mathcal{B}$-eventual, if there exists some $B \in \mathcal{B}$ such that $x \in S$ for all $x \in B$.
    \item $S$ is $\mathcal{B}$-frequent, or $\mathcal{B}$-stationary, if for each $B \in \mathcal{B}$, there exists some $x \in B$ such that $x \in S$. 
\end{enumerate}
\begin{lemma} \label{event-freq-equiv} \ 
\begin{enumerate}
    \item ``$\mathcal{B}$-eventual'' implies ``$\mathcal{B}$-frequent''.
    \item $S$ is $\mathcal{B}$-eventual iff its complement is $\mathcal{B}$-frequent.
    \item Monotonicity (filter): let $\mathcal{C}$ refines $\mathcal{B}$ (both are filter bases), then
    \begin{enumerate}
        \item $S$ is $\mathcal{B}$-eventual implies it is $\mathcal{C}$-eventual.
        \item $S$ is $\mathcal{C}$-frequent implies it is $\mathcal{B}$-frequent.
    \end{enumerate}
    \item Monotonicity (subset): let $S \subseteq T$  be subsets of $X$
    \begin{enumerate}
        \item $S$ is $\mathcal{B}$-eventual implies $T$ is $\mathcal{B}$-eventual.
        \item $S$ is $\mathcal{B}$-frequent implies $T$ is $\mathcal{B}$-frequent.
    \end{enumerate}
    \item Lattice properties (subset):
    \begin{enumerate}
        \item $S$ and $T$ are $\mathcal{B}$-eventual iff $S \cap T$ is $\mathcal{B}$-eventual.
        \item $S$ or $T$ is $\mathcal{B}$-frequent iff $S \cup T$ is $\mathcal{B}$-frequent.
    \end{enumerate}
    \item Lattice properties (filter): let $\{ \mathcal{F}_\lambda \}_{\lambda \in L}$ be a family of filters on $X$.
    \begin{enumerate}
        \item $S$ is $\mathcal{F}_\lambda$-eventual for every $\lambda \in L$ iff $S$ is $\bigcap_{\lambda \in L} \mathcal{F}_\lambda$-eventual.
        \item $S$ is $\mathcal{F}_\lambda$-frequent for some $\lambda \in L$ iff $S$ is $\bigcap_{\lambda \in L} \mathcal{F}_\lambda$-frequent.
    \end{enumerate}
    \item Subsequentiality:
    \begin{enumerate}
        \item If $B \subseteq S$ for all $B \in \mathcal{B}$, then $S$ is both $\mathcal{B}$-frequent and $\mathcal{B}$-eventual.
        \item If $S$ is $\mathcal{B}$-frequent, then there exists another filter base $\mathcal{C}$ refining $\mathcal{B}$ such that $C \subseteq S$ for all $C \in \mathcal{C}$.
    \end{enumerate}
\end{enumerate}
\end{lemma}
\begin{proof}
\underline{Part 1:} suppose $S$ is $\mathcal{B}$-eventual, then there exists some $B_0 \in \mathcal{B}$ such that $B_0 \subseteq S$. Now for each $B \in \mathcal{B}$, there exists another $B' \in \mathcal{B}$ such that $B' \subseteq B \cap B_0$. Yet $B_0 \subseteq S$, so we know that $B' \subseteq B \cap S$, i.e. $B \cap S$ is not empty for all $B \in \mathcal{B}$ (again, as $\mathcal{B}$ is non-trivial).
\\
\underline{Part 2:} we have the following logical equivalence
\begin{align*}
    & S \mbox{ is } \mathcal{B} \mbox{-eventual}
    \\
    & \qquad \Leftrightarrow \exists B \in \mathcal{B}, \forall x \in B: x \in S
    \\
    & \qquad \Leftrightarrow \exists B \in \mathcal{B}, \forall x \in B [\neg (x \notin S)]
    \\
    & \qquad \Leftrightarrow \neg [\forall B \in \mathcal{B}, \exists x \in B: x \in X \setminus S]
    \\
    & \qquad \Leftrightarrow \neg [X \setminus S \mbox{ is } \mathcal{B} \mbox{-frequent}]
\end{align*}
\underline{Part 3:}
\begin{enumerate}[label=(\alph*)]
    \item Suppose $S$ is $\mathcal{B}$-eventual: there exists $B_0 \in \mathcal{B}$ such that $B_0 \subseteq S$. Since $\mathcal{C}$ refines $\mathcal{B}$, there exists some $C_0 \in \mathcal{C}$ such that $C_0 \subseteq B_0$. Hence, $C_0 \subseteq S$ for some $C_0 \in \mathcal{C}$.
    \item Applying previous part (3a) and (2), we have:
    \begin{align*}
        S \mbox{ is } \mathcal{C} \mbox{-frequent} & \Leftrightarrow \neg [X \setminus S \mbox{ is } \mathcal{C} \mbox{-eventual}]
        \\
        & \Rightarrow \neg [X \setminus S \mbox{ is } \mathcal{B} \mbox{-eventual}]
        \\
        & \Leftrightarrow S \mbox{ is } \mathcal{B} \mbox{-frequent}
    \end{align*}
\end{enumerate}
\underline{Part 4:}
\begin{enumerate}[label=(\alph*)]
    \item Suppose $S$ is $\mathcal{B}$-eventual: there exists $B_0 \in \mathcal{B}$ such that $B_0 \subseteq S$. Since $S \subseteq T$, we also have $B_0 \subseteq T$.
    \item Apply previous part (4a) and (2), we have (note $X \setminus T \subseteq X \setminus S$):
    \begin{align*}
        S \mbox{ is } \mathcal{B} \mbox{-frequent} & \Leftrightarrow \neg [X \setminus S \mbox{ is } \mathcal{B} \mbox{-eventual}]
        \\
        & \Rightarrow \neg [X \setminus T \mbox{ is } \mathcal{B} \mbox{-eventual}]
        \\
        & \Leftrightarrow T \mbox{ is } \mathcal{B} \mbox{-frequent}
    \end{align*}
\end{enumerate}
\underline{Part 5:}
\begin{enumerate}[label=(\alph*)]
    \item Suppose $S$ and $T$ are $\mathcal{B}$-eventual. This means there exists $B_s, B_t \in \mathcal{B}$ such that $B_s \subseteq S$ and $B_t \subseteq T$. Since $\mathcal{B}$ is a filter base, there exists $B_0 \in \mathcal{B}$ such that $B_0 \subseteq B_s \cap B_t \subseteq S \cap T$.
    \item Apply the previous part (5a) and (2), we get
    \begin{align*}
        & (S \mbox{ is } \mathcal{B} \mbox{-frequent}) \vee (T \mbox{ is } \mathcal{B} \mbox{-frequent})
        \\
        & \qquad \Leftrightarrow \neg (X \setminus S \mbox{ is } \mathcal{B} \mbox{-eventual}) \vee \neg (X \setminus T \mbox{ is } \mathcal{B} \mbox{-eventual})
        \\
        & \qquad \Leftrightarrow \neg [(X \setminus S \mbox{ is } \mathcal{B} \mbox{-eventual}) \wedge (X \setminus T \mbox{ is } \mathcal{B} \mbox{-eventual})]
        \\
        & \qquad \Leftrightarrow \neg [(X \setminus S) \cap (X \setminus T) \mbox{ is } \mathcal{B} \mbox{-eventual}]
        \\
        & \qquad \Leftrightarrow \neg [X \setminus (S \cup T) \mbox{ is } \mathcal{B} \mbox{-eventual}]
        \\
        & \qquad \Leftrightarrow S \cup T \mbox{ is } \mathcal{B} \mbox{-frequent}
    \end{align*}
\end{enumerate}
\underline{Part 6:}
\begin{enumerate}[label=(\alph*)]
    \item Suppose $S$ is $\mathcal{F}_\lambda$-eventual for all $\lambda \in L$. This means, for each $\lambda \in L$, there exists some $F \in \mathcal{F}_\lambda$ such that $F \subseteq S$. However, $\mathcal{F}_\lambda$ is a filter so $S \in \mathcal{F}_\lambda$, and so $S \in \bigcap_{\lambda \in L} \mathcal{F}_\lambda$. In particular, $S$ is $\bigcap_{\lambda \in L} \mathcal{F}_\lambda$-eventual.
    \item Apply part (6a) and (2), we get
    \begin{align*}
        & \exists \lambda \in L: S \mbox{ is } \mathcal{F}_\lambda \mbox{-frequent}
        \\
        & \qquad \Leftrightarrow \exists \lambda \in L: \neg(X \setminus S \mbox{ is } \mathcal{F}_\lambda \mbox{-eventual})
        \\
        & \qquad \Leftrightarrow \neg [\forall \lambda \in L: X \setminus S \mbox{ is } \mathcal{F}_\lambda \mbox{-eventual}]
        \\
        & \qquad \Leftrightarrow \neg \left[ X \setminus S \mbox{ is } \bigcap_{\lambda \in L} \mathcal{F}_\lambda \mbox{-eventual} \right]
        \\
        & \qquad \leftrightarrow S \mbox{ is } \bigcap_{\lambda \in L} \mathcal{F}_\lambda \mbox{-frequent}
    \end{align*}
\end{enumerate}
\underline{Part 7:}
\begin{enumerate}[label=(\alph*)]
    \item This follows from part (1) and (3) by first setting $\mathcal{I}_0 = \{ S \}$ (assuming $S$ is not empty) to be a filter base. Then $S$ is $\mathcal{I}_0$-eventual, since the only option is $S$. From there, we conlcude $S$ is also $\mathcal{I}_0$-frequent.
    \item Suppose $S$ is $\mathcal{B}$-frequent. Define $\mathcal{B}_s = \{ B \cap S : B \in \mathcal{B} \}$, then $\mathcal{B}_s$ is a filter base.
    \begin{enumerate}
        \item By assumption, $B \cap S$ is nonempty for all $B \in \mathcal{B}$.
        \item Given $B_n \cap S \in \mathcal{B}_s$ ($n = 1, 2$), then there exists some $B \in \mathcal{B}$ such that $B \subseteq B_1 \cap B_2$. We then have $B \cap S \subseteq (B_1 \cap B_2) \cap S = (B_1 \cap S) \cap (B_2 \cap S)$.
    \end{enumerate}
    We also have $B \cap S \subseteq S$ for every $B \cap S \in \mathcal{B}_s$, and $B \cap S \subseteq B$ for every $B \in \mathcal{B}$, so $\mathcal{B}_s$ refines $\mathcal{B}$ in particular.
\end{enumerate}
\end{proof}
\begin{theorem}[Topology in terms of convergence] \label{topo-filt-seq-conv} \ 
\begin{enumerate}
    \item $x \in \operatorname{cl}(S)$ if and only if there exists a filter base $\mathcal{B}$ converging to $x$ such that $S$ is $\mathcal{B}$-frequent.
    \item $x \in \operatorname{int}(S)$ if and only if $S$ is $\mathcal{B}$-eventual whenever $\mathcal{B}$ converges to $x$.
\end{enumerate}
\end{theorem}
\begin{proof} \ \\
\underline{Part 1:} suppose $x \in \operatorname{cl}(S)$, then the neighborhood filter $\mathcal{N}_x$ converges to $x$. Since $N \cap S$ is non-empty for all $N \in \mathcal{N}_x$ by equivalent definition of closure, $S$ must be $\mathcal{B}$-frequent. Vice versa, suppose there exists a filter base $\mathcal{B}$ converging to $x$ such that $S$ is $\mathcal{B}$-frequent. Then for each neighborhood $N$ of $x$, there exists some $B \in \mathcal{B}$ such that $B \subseteq N$. But $B \cap S$ is not empty, so $N \cap S$ is also not empty. By definition, $x \in \operatorname{cl}(S)$.
\\
\underline{Part 2:} we make use of the previous part (1) and the previous \hyperref[event-freq-equiv]{Lemma \ref*{event-freq-equiv}}.
\begin{align*}
    & x \in \operatorname{int}(S) \Leftrightarrow x \notin X \setminus \operatorname{int}(S) = \operatorname{cl}(X \setminus S)
    \\
    & \qquad \Leftrightarrow \neg [\exists \mathcal{B} : \mathcal{B} \to x \wedge (X \setminus S \mbox{ is } \mathcal{B} \mbox{-frequent})]
    \\
    & \qquad \Leftrightarrow \neg [\exists \mathcal{B} \mbox{ filter base}: (\mathcal{B} \to x) \wedge (X \setminus S \mbox{ is } \mathcal{B} \mbox{-frequent})]
    \\
    & \qquad \Leftrightarrow \forall \mathcal{B} \mbox{ filter base}: \neg(\mathcal{B} \to x) \vee \neg(X \setminus S \mbox{ is } \mathcal{B} \mbox{-frequent})
    \\
    & \qquad \Leftrightarrow \forall \mathcal{B} \mbox{ filter base}: (\mathcal{B} \to x) \rightarrow (S \mbox{ is } \mathcal{B} \mbox{-eventual})
\end{align*}
\end{proof}

\subsection{Cluster points}
A point $x$ in $X$ is a \emph{cluster} point of a filter base $\mathcal{B}$ if every neighborhood of $x$ is $\mathcal{B}$-frequent. Equivalently, $x$ is a cluster point of $\mathcal{B}$ iff $B \cap N$ is not empty for all $B \in \mathcal{B}$ and neighborhood $N$ of $x$.
\begin{remark}
If $\{ x \} \in \mathcal{B}$, then $x$ is a cluster point.
\end{remark}
\begin{proof}
Note that for any $B \in \mathcal{B}$, $B \cap \{ x \}$ has to be not empty, so $\{ x \}$ must be a subset of $B$. In other words, $x \in B$ for all $B \in \mathcal{B}$. Therefore, since any neighborhood of a point must contain that point, $B \cap N$ is not empty for all $B \in \mathcal{B}$ and neighborhood $N$ of $x$.
\end{proof}
\begin{proposition} \label{topo-cluster-equiv}
TFAE
\begin{enumerate}
    \item $x$ is a cluster point of $\mathcal{B}$.
    \item $x$ is in the closure of $B$ for each $B \in \mathcal{B}$.
    \item $x$ is a limit of some filter base $\mathcal{C}$ that refines $\mathcal{B}$.
\end{enumerate}
\end{proposition}
\begin{proof}
We will show $(1) \Rightarrow (2) \Rightarrow (3) \Rightarrow (1)$.
\\
\\
*Suppose $x$ is a cluster points of $(x_i)_{i \in I}$: let $B \in \mathcal{B}$. Then $B \cap N$ is not empty for all neighborhood $N$ of $x$. By definition, $x$ is in the closure of $B$.
\\
\\
*Suppose $x$ is in the closure of $B$ for all $B \in \mathcal{B}$: this means that $B \cap N$ is not empty for all neighborhood $N$ of $x$. Define $\mathcal{C} = \{ B \cap N : B \in \mathcal{B} \wedge N \mbox{ is a neighborhood of } x \}$
\begin{enumerate}
    \item $\varnothing \notin \mathcal{C}$ by the hypothesis.
    \item If $B_1 \cap N_1, B_2 \cap N_2 \in \mathcal{C}$, then there exists some $B \in \mathcal{B}$ such that $B \subseteq B_1 \cap B_2$. Since $N = N_1 \cap N_2$ is another neighborhood of $x$, we have $B \cap N \in \mathcal{C}$ such that $B \cap N \subseteq (B_1 \cap B_2) \cap (N_1 \cap N_2) = (B_1 \cap N_1) \cap (B_2 \cap N_2)$.
    \item $B \cap N \subseteq B, N$ for all $B \in \mathcal{B}$ and neighborhood $N$ of $x$.
\end{enumerate}
We conclude that $\mathcal{C}$ is a filter base that refines $\mathcal{B}$ and converges to $x$.
\\
\\
*Finally, suppose $x$ is a limit of some filter base $\mathcal{C}$ that refines $\mathcal{B}$: for each $B \in \mathcal{B}$, there exists some $C_b \in \mathcal{C}$ such that $C_b \subseteq B$. Additionally, for each neighborhood $N$ of $x$, there also exists some $C_n \in \mathcal{C}$ such that $C_n \subseteq N$. Yet $\mathcal{C}$ is a filter base, so there exists some \textit{non-empty} $C \in \mathcal{C}$ such that $C \subseteq C_b \cap C_n \subseteq B \cap N$. But $B$ and $N$ are arbitrary (in their respective domains), so $x$ must be a cluster point of $\mathcal{B}$ by definition.
\end{proof}

\subsection{Filtered Sequence}
[Reference: \href{https://math.stackexchange.com/questions/1568548/where-has-this-common-generalization-of-nets-and-filters-been-written-down}{Where has this common generalization of nets and filters been written down? (Stack Exchange)}]
\\
A \emph{$\mathcal{B}$-filtered sequence} $(x_i)_{i \in I}$ in $X$ (indexed by $I$) is just a function $x: I \to X$ along with a filter base $\mathcal{B}$ on $I$.
\begin{remark}
For each $\mathcal{B}$-filtered sequence $(x_i)_{i \in I}$ in $X$, we can then form the \emph{induced} filter base on $X$ to be the image of $\mathcal{B}$ under $x$.
\\
\\
Vice versa, given a filter base $\mathcal{B}$ on $X$, we can form the \emph{canonical} filtered sequence to be the pair $(\operatorname{id}_X, \mathcal{B})$ where $\operatorname{id}_X$ is the identity map on $X$.
\end{remark}
With these transformations, we can declare a filtered sequence satisfies a (topological) property $P$ (e.g. convergence, cluster, eventuality, stationary) if its canonical filter base also satifies $P$.
\begin{remark}
Let $(x_i)_{i \in I}$ be a $\mathcal{B}$-filtered sequence on $X$
\begin{enumerate}
    \item $x$ converges to $p$ along $\mathcal{B}$ if and only if $x(\mathcal{B})$ refines the neighborhood filter at $p$.
    \item $p$ is a cluster point of $(x_i)_{i \in I}$ with respect to $\mathcal{B}$ if and only if for all $B \in \mathcal{B}$ and neighborhood $N$ of $p$, there exists some $i \in B$ such that $x_i \in N$.
    \item $(x_i)_{i \in I}$ is $\mathcal{B}$-eventually in $S \subseteq X$ if and only if there exists some $B_0 \in \mathcal{B}$ such that $x_i \in S$ for all $i \in B$.
    \item Vice versa, $(x_i)_{i \in I}$ is $\mathcal{B}$-frequently in $S$ if and only if for each $B \in \mathcal{B}$, there exists some $i \in B$ such that $x_i \in S$.
\end{enumerate}
\end{remark}
\ 
\\
Given a $\mathcal{B}$-filtered sequence $(x_i)_{i \in I}$, there are 2 types of $\mathcal{C}$-filtered subsequences $(y_j)_{j \in J}$ to discuss
\begin{enumerate}
    \item $(y_j)_{j \in J}$ is a \emph{KW-subsequence} (stands for Kelley and Willard) if there exists a map $\varphi: J \to I$, called the re-indexing map, such that
    \begin{enumerate}
        \item $y_j = x_{\varphi(j)}$ for all $j \in J$.
        \item $\varphi(\mathcal{C})$ is finer than $\mathcal{B}$.
    \end{enumerate}
    \item $(y_j)_{j \in J}$ is an \emph{AA-subsequence} (stands for Aarnes and AndenÃ¦s) if $y(\mathcal{C})$ refines $x(\mathcal{B})$ (as both are filter bases on $X$).
\end{enumerate}
\begin{remark} \ 
\begin{enumerate}
    \item The notion of AA-subsequences is derived directly from their corresponding (canonical) filter base on $X$.
    \item Every KW-subsequence is AA-subsequence
    \item Both notions of subsequences are (pre-)orderings, in that they satisfies reflexivity and transitivity.
\end{enumerate}
\end{remark}
\begin{proof}
\ \\
\underline{Part 2:} if $\varphi: J \to I$ is the re-indexing map from $\mathcal{C}$-filtered sequence $(y_j)_{j \in J}$ to $\mathcal{B}$-filtered sequence $(x_i)_{i \in I}$, then $y = x \circ \varphi$, and $\varphi(\mathcal{C})$ refines $\mathcal{B}$. Since image under a function preserves refinement relation, we also have $y(\mathcal{C}) = x(\varphi(\mathcal{C}))$ refines $x(\mathcal{B})$, i.e. $(y_j)_{j \in J}$ is AA-subsequence of $(x_i)_{i \in I}$
\\
\underline{Part 3:} each filtered sequence is a KW-subsequence of itself by letting the identity map on the index set to serve as the reindexing map. It is also a AA-subsequence of itself since the refinement relation is reflexive.
\\
\\
The transitivity of AA-subsequence follows from the transitivity of refinement. As for KW-subsequence, let $(y_j)_{j \in J}$ be a $\mathcal{C}$-filtered subsequence of $(x_i)_{i \in I}$ (with $\varphi: J \to I$ as the re-indexing map), and $(z_k)_{k \in K}$ be a $\mathcal{D}$-filtered subsequence of $(y_j)_{j \in J}$ (with $\psi: K \to J$ as the re-indexing map). Consider $\lambda = \varphi \circ \psi$, which is a function from $K \to I$
\begin{enumerate}
    \item $z = y \circ \psi = (x \circ \varphi) \circ \psi = x \circ (\varphi \circ \psi) = x \circ \lambda$.
    \item Since $\psi(\mathcal{D})$ refines $\mathcal{C}$, $\varphi(\psi(\mathcal{D}))$ refines $\varphi(\mathcal{C})$. However $\varphi(\mathcal{C})$ refines $\mathcal{B}$, so $\lambda(\mathcal{D})$ must refine $\mathcal{B}$. 
\end{enumerate}
Hence, $(z_k)_{k \in K}$ is a KW-subsequence of $(x_i)_{i \in I}$, with $\lambda: K \to I$ serves as the re-indexing map.
\end{proof}
\begin{proposition}[Equivalence of AA-subsequence]
Let $(x_i)_{i \in I}$ be a $\mathcal{B}$-filtered sequence and $(y_j)_{j \in J}$ be a $\mathcal{C}$-filtered sequence. TFAE
\begin{enumerate}
    \item $(y, \mathcal{C})$ is an AA-subsequence of $(x, \mathcal{B})$.
    \item For any $S \subseteq X$, $(y_j)_{j \in J}$ is $\mathcal{C}$-frequently in $S$ implies $(x_i)_{i \in I}$ is $\mathcal{B}$-frequently in $S$.
    \item For any $S \subseteq X$, $(x_i)_{i \in I}$ is $\mathcal{B}$-eventually in $S$ implies $(y_j)_{j \in J}$ is $\mathcal{C}$-eventually in $S$.
    \item If $L \subseteq I$ is $\mathcal{B}$-eventual (i.e. $L$ contains some $B \in \mathcal{B}$), then $y^{-1}(x(L))$ is $\mathcal{C}$-eventual.
\end{enumerate}
\end{proposition}
\begin{proof}
We show $(1) \Rightarrow (2) \Rightarrow (3) \Rightarrow (4) \Rightarrow (1)$.
\\
\\
*Suppose $(y, \mathcal{C})$ is an AA-subsequence of $(x, \mathcal{B})$: then $y(\mathcal{C})$ refines $x(\mathcal{B})$. Note that $(x_i)_{i \in I}$ is $\mathcal{B}$-frequently in $S$ iff $S$ is $x(\mathcal{B})$-eventual. Hence, by \hyperref[event-freq-equiv]{Lemma \ref*{event-freq-equiv}}, we have $(y_j)_{j \in J}$ is $\mathcal{C}$-frequently in $S$ (or $S$ is $y(\mathcal{C})$-frequent), then $(x_i)_{i \in I}$ is $\mathcal{B}$-frequently in $S$ (or $S$ is $x(\mathcal{B})$-frequent).
\\
\\
*Suppose $(x_i)_{i \in I}$ is $\mathcal{B}$-frequently in $S$ whenever $(y_j)_{j \in J}$ is $\mathcal{C}$-frequently in $S$: again, from \hyperref[event-freq-equiv]{Lemma \ref*{event-freq-equiv}}, we know that $(x_i)_{i \in I}$ is $\mathcal{B}$-eventually in $S$ iff $(x_i)_{i \in I}$ is not $\mathcal{B}$-frequently in $X \setminus S$, which in turn  implies $(y_j)_{j \in J}$ is not $\mathcal{C}$-frequently in $X \setminus S$, and so $(y_j)_{j \in J}$ is $\mathcal{C}$-eventually in $S$.
\\
\\
*Suppose $(y_j)_{j \in J}$ is $\mathcal{C}$-eventually in $S$ whenever $(x_i)_{i \in I}$ is $\mathcal{B}$-eventually in $S$: Let $L \subseteq I$ be such that $B \subseteq L$ for some $B \in \mathcal{B}$. then $(x_i)_{i \in I}$ is $\mathcal{B}$-eventually in $x(L)$. Therefore, $(y_j)_{j \in J}$ is $\mathcal{C}$-eventually in $x(L)$ also. Equivalently, there exists some $C \in \mathcal{C}$ such that $y(C) \subseteq x(L)$, or $C \subseteq y^{-1}(x(L))$, or $y^{-1}(x(L))$ is $\mathcal{C}$-eventual.
\\
\\
*Suppose $y^{-1}(x(L))$ is $\mathcal{C}$-eventual whenever $L$ is $\mathcal{B}$-eventual: note that $B \in \mathcal{B}$ is $\mathcal{B}$-eventual, so $y^{-1}(x(B))$ is $\mathcal{C}$-eventual, i.e. $C \subseteq y^{-1}(x(B))$ or $y(C) \subseteq x(B)$ for some $C \in \mathcal{C}$. By definition, $y(\mathcal{C})$ refines $x(\mathcal{B})$.
\end{proof}
\ \\
While a KW-subsequence is more natural in functional and intuitive sense, the AA-subsequence is more natural in categorical sense. However, with respect to the filter bases they map to, they are ``equivalent''. With respect to the pre-ordering above, we say the 2 filtered sequences is \emph{KW-equivalence} (resp. \emph{AA-equivalence}) if each is a KW-subsequence (resp. AA-subsequence) of the other one.
\begin{lemma}
Given $\mathcal{B}$-filtered sequence $(x_i)_{i \in I}$ and $\mathcal{C}$-filtered sequence $(y_j)_{j \in J}$, TFAE
\begin{enumerate}
    \item For all $B \in \mathcal{B}$ and $C \in \mathcal{C}$, there exists some $p \in X$ such that $x_i = y_j = p$ for some $i \in B, j \in C$.
    \item $\mathcal{M} = \{ S \subseteq X : S \supseteq x(B) \cap y(C) \mbox{ for some } B \in \mathcal{B}, C \in \mathcal{C} \}$ is a proper filter.
    \item $x(\mathcal{B})$ and $y(\mathcal{C})$ have a common filter base refining both.
    \item $x$ and $y$ have a common KW-subsequence. In fact, such subsequence can be chosen to be a maximal AA-subsequence.
\end{enumerate}
\end{lemma}
\begin{proof}
We prove the following direction $(1) \Rightarrow (2) \Rightarrow (3) \Rightarrow (4) \Rightarrow (1)$.
\\
\\
*Suppose there exists $i \in B, j \in C$ such that $x_i = y_j$ whenever $B \in \mathcal{B}, C \in \mathcal{C}$: equivalently, $x(B) \cap y(C) \neq \varnothing$. Hence, every set in $\mathcal{M}$ is non-empty. $\mathcal{M}$ is then a proper filter since
\begin{enumerate}
    \item If $S \in \mathcal{M}$, then $x(B) \cap y(C) \subseteq S$ for some $B \in \mathcal{B}, C \in \mathcal{C}$. If $S \subseteq T$, then we also have $x(B) \cap y(C) \subseteq T$, and so $T \in \mathcal{M}$.
    \item On the other hand, if $S_n \in \mathcal{M}$ ($n = 1, 2$), then $x(B_n) \cap y(C_n) \subseteq S_n$ for some $B_n \in \mathcal{B}, C_n \in \mathcal{C}$. Since $\mathcal{B}, \mathcal{C}$ a filter base, there also exists some $B \in \mathcal{B}, C \in \mathcal{C}$ such that $B \subseteq B_1 \cap B_2, C \subseteq C_1 \cap C_2$. Let $S = x(B) \cap y(C) \in \mathcal{M}$, which then satisfies $S \subseteq x(B_1 \cap B_2) \cap y(C_1 \cap C_2) \subseteq x(B_1) \cap x(B_2) \cap y(C_1) \cap y(C_2) \subseteq S_1 \cap S_2$.
\end{enumerate}
\ 
\\
*Suppose $\mathcal{M}$ is a proper filter: in particular $x(B) \cap y(C)$ is not empty since it is in $\mathcal{M}$. Additionally $x(B) \cap y(C) \subseteq x(B)$ and $x(B) \cap y(C) \subseteq y(C)$, so $\mathcal{M}$ refines both $x(\mathcal{B})$ and $y(\mathcal{C})$.
\\
\\
*Suppose $\mathcal{F}$ is a filter base on $X$ that refines $x(\mathcal{B})$ and $y(\mathcal{C})$: let $K = \{ (i, j) \in I \times J : x_i = y_j \}$ and $\mathcal{D} = \{ (B \times C) \cap K : B \in \mathcal{B}, C \in \mathcal{C} \}$.
\begin{enumerate}
    \item By the hypothesis, for all $B \in \mathcal{B}$, $C \in \mathcal{C}$, there exists $F_b, F_c, F \in \mathcal{F}$ such that $F_b \subseteq x(B)$, $F_c \subseteq y(C)$, and $F \subseteq F_b \cap F_c \subseteq x(B) \cap y(C)$. In particular, $K$ is not empty, since we can take some $(i, j) \in I \times J$ such that $p = x_i = y_j \in F$. This also shows that $\mathcal{D}$ is not empty, and contains no empty set.
    \item $\mathcal{D}$ is a filter base on $K$: given $D_n = (B_n \times C_n) \cap K$ in $\mathcal{D}$ ($n = 1, 2$), let $B \in \mathcal{B}$ and $C \in \mathcal{C}$ such that $B \subseteq B_1 \cap B_2$ and $C \subseteq C_1 \cap C_2$. We then have $D \in \mathcal{D}$ such that $D = (B \times C) \cap K \subseteq [(B_1 \cap B_2) \times (C_1 \cap C_2)] \cap K = [(B_1 \times C_1) \cap (B_2 \times C_2)] \cap K = D_1 \cap D_2$.
\end{enumerate}
Let $z: K \to X$ where $(i, j)$ is sent to $x_i = y_j \in X$, and consider the projection $\pi_I : K \to I$ and $\pi_J : K \to J$
\begin{enumerate}
    \item $z_{ij} = x_i = x_{\pi_I(i, j)}$ and $z_{ij} = y_j = y_{\pi_J(i, j)}$.
    \item We also have $\pi_I ((B \times C) \cap K) \subseteq \pi_I(B \times C) = B$ and similarly, $\pi_J((B \times C) \cap K) \subseteq C$ for all $B \in \mathcal{B}, C \in \mathcal{C}$. Thus, $\pi_I$ and $\pi_J$ are the reindexing map from $z$ to $x$ and $y$ respectively.
\end{enumerate}
We conclude that $z$ is a common KW-subsequence of $x$ and $y$. Furthermore, $z$ is a maximal AA-subsequence among common subsequence of $x$ and $y$. Indeed, if $(w_l)_{l \in L}$ is a $\mathcal{E}$-filtered AA-subsequence of both $x$ and $y$, then $w(\mathcal{E})$ refines both $x(\mathcal{B})$ and $y(\mathcal{C})$. In particular, for each $B \in \mathcal{B}$ and $C \in \mathcal{C}$, there exists some $E_b, E_c, E \in \mathcal{E}$ such that $w(E_b) \subseteq x(B)$, $w(E_c) \subseteq y(C)$, and $E \subseteq E_b \cap E_c$. Together, we get $w(E) \subseteq w(E_b) \cap w(E_c) \subseteq x(B) \cap y(C)$ for some $E \in \mathcal{E}$. Yet $z((B \times C) \cap K) = \{ p \in X : x_i = y_j = p \mbox{ for some } i \in B, j \in C \} = x(B) \cap y(C)$, so as $B, C$ varies, $w(\mathcal{E})$ refines $z(\mathcal{D})$ by definition.
\\
\\
*Finally, suppose $(z_k)_{k \in K}$ is a common $\mathcal{D}$-filtered KW-subsequence of $x$ and $y$: then $z$ is also AA-subsequence of $x$ and $y$, and so $z(\mathcal{D})$ refines both $x(\mathcal{B})$ and $y(\mathcal{C})$. Again, by similar argument as above, we can show that $x(B) \cap y(C)$ is not empty (by containing some $z(D)$) for all $B \in \mathcal{B}, C \in \mathcal{C}$.
\end{proof}
\begin{theorem}
Any AA-subsequence of $(x_i)_{i \in I}$ is AA-equivalent to a KW-subsequence of $(x_i)_{i \in I}$.
\end{theorem}
\begin{proof}
If $(y_j)_{j \in J}$ is an AA-subsequence of $(x_i)_{i \in I}$, then $y(\mathcal{C})$ refines $x(\mathcal{B})$. In particular, given $B \in \mathcal{B}$ and $C \in \mathcal{C}$, there exists $C_b, C' \mathcal{C}$ such that $y(C_b) \subseteq x(B)$ and $C' \subseteq C_b \cap C$. Thus, $y(C') \subseteq y(C_b) \cap y(C) \subseteq y(C) \cap x(B)$, and so $y(C) \cap x(B)$ is not empty. By the previous lemma, there exists a common KW-subsequence $z$ of both $x$ and $y$ that is also a maximal AA-subsequence. In other words, $y$ must be an AA-subsequence of $z$. Since a KW-subsequence is also an AA-subsequence, we conclude $z$ is AA-equivalent to $y$.
\end{proof}
\ 
\\
\begin{theorem}[Transformational Adjunction I]
Let $(x_i)_{i \in I}$ be a $\mathcal{B}$-filtered sequence in $X$, and $\mathcal{F}$ be a filter base on $X$. Then
\begin{center}
    $\mathcal{F}$ refines the induced filter base of $(x, \mathcal{B})$ if and only if the canonical sequence of $\mathcal{F}$ is an AA-subsequence to $(x, \mathcal{B})$.
\end{center}
Additionally, the induced filter base of the canonical sequence of $\mathcal{F}$ is just $\mathcal{F}$!
\end{theorem}
\begin{proof}
Suppose the canonical sequence of $\mathcal{F}$ is a KW-subsequence (or more generally AA-subsequence) of $(x, \mathcal{B})$, then $\mathcal{F} = \operatorname{id}_X (\mathcal{F})$ refines $x(\mathcal{B})$. Vice versa, if $\mathcal{F}$ refines $x(\mathcal{B})$, then $\operatorname{id}_X (\mathcal{F})$ refines $x(\mathcal{B})$, and so $(\operatorname{id}_X, \mathcal{F})$ is an AA-subsequence of $(x, \mathcal{B})$.
\\
\\
Since the canonical filtered sequence of $\mathcal{F}$ is $(\operatorname{id}_X, \mathcal{F})$, its induced filter base is $\operatorname{id}_X (\mathcal{F}) = \mathcal{F}$.
\end{proof}

\subsection{Net on topological space}
A \emph{net} on $X$ is a map $x: A \to X$ from a directed set $A$ (i.e. $A$ is a pre-ordered set where there is an upper bound to every 2 elements in $A$).
\begin{remark}
If $A = \mathbb{N}$, then a net turns into a sequence (of points in $X$)!
\end{remark}
\begin{remark}
Given a net $(x_\alpha)_{\alpha \in A}$, the \emph{eventuality filter base} on $X$ (with respect to $x$) is defined as the image of $\mathcal{E}_A$ (under $x$) where
\begin{center}
    $S \in \mathcal{E}_A$ if and only if $S = \uparrow \eta = \{ \alpha \in A : \alpha \geq \eta \}$ for some $\eta \in A$.
\end{center}
Vice versa, given a filter base $\mathcal{B}$ on $X$, let
\begin{enumerate}
    \item $\langle X, \mathcal{B} \rangle$ be the subcollection of $X \times \mathcal{B}$ containing exactly $(p, B)$ such that $p \in B$.
    \item Ordering on $\langle X, \mathcal{B} \rangle$: $(p_1, B_1) \leq (p_2, B_2)$ iff $B_1 \supseteq B_2$.
\end{enumerate}
Then the projection $\pi_\mathcal{B}: \langle X, \mathcal{B} \rangle \to X, (p, B) \mapsto p$ forms the canonical net of $\mathcal{B}$.
\end{remark}
With these transformation, we again declare that a net has property $P$ if its eventuality filter base on $X$ has property $P$
\begin{remark}
\ 
\begin{enumerate}
    \item A net $(x_\alpha)_{\alpha \in A}$ converges to $p$ if for each neighborhood $N$ of $p$, there is some $\eta \in A$ such that $x_\alpha \in N$ for all $\alpha \geq \eta$.
    \item $p$ is a cluster point of $(x_\alpha)_{\alpha \in A}$ if for each neighborhood $N$ of $p$ and $\eta \in A$, there exists some $\alpha \geq \eta$ such that $x_\alpha \in N$.
    \item $(x_\alpha)_{\alpha \in A}$ is eventually in $S$ if there exists some $\gamma \in A$ such that $x_\alpha \in S$ for all $\alpha \geq \gamma$.
    \item $(x_\alpha)_{\alpha \in A}$ is frequently in $S$ if for each $\alpha \in A$, there exists some $\lambda \geq \alpha$ such that $x_\lambda \in S$.
\end{enumerate}
\end{remark}
\begin{remark}
Given a net $(x_\alpha)_{\alpha \in A}$ in $X$, if $\gamma \in A$ is a maximal element, then $x_\gamma$ is a limit of the net.
\end{remark}
\begin{proof}
Indeed, note that $\{ \alpha \in A : \alpha \geq \gamma \} = \{ \gamma \}$ by definition, so for any neighborhood $N$ of $x_\gamma$, we have $x_\alpha \in N$ for all $\alpha \in \gamma$.
\end{proof}
\underline{Note:} if $A$ contains a maximal element, then such element is also the greatest element of $A$.
\\
\\
{[Reference: \url{http://thales.doa.fmph.uniba.sk/sleziak/texty/rozne/topo/subnets2.pdf}]} Given a net $x: A \to X$, there are 3 types of subnet in general
\begin{enumerate}
    \item A \emph{Willard subnet} is a map $y: B \to X$ such that there exists a cofinal monotone map $\varphi: B \to A$, and $y = x \circ \varphi$. Note that as $\varphi$ is monotone, the cofinality condition is equivalent to
    \begin{align*}
        \forall \alpha \in A, \exists \beta \in B: \varphi(\beta) \geq \alpha
    \end{align*}
    \item A \emph{Kelley subnet} is like Willard subnet, but remove monotone condition on $\varphi$.
    \item Finally, an \emph{AA-subnet} (initials of the 2 authors Aarnes and  AndenÃ¦s) is a map $y: B \to X$ such that the eventuality filer base $\mathcal{E}[y]$ refines $\mathcal{E}[x]$. 
\end{enumerate}
\begin{remark}
Straight from definition, we have the following inclusion: Willard subnets $\subseteq$ Kelley subnets $\subseteq$ AA-subnets.
\end{remark}
\begin{proof}
The first inclusion is obvious, so we verify the second one. Let $y: B \to X$ be a Kelley subnet of $x: A \to X$, with $\varphi: B \to A$ be a cofinal map so that $y = x \circ \varphi$. Given $\eta \in A$, then there exists some $\gamma \in B$ such that $\varphi(\beta) \geq \eta$ for all $\beta \geq \gamma$. In other words,
\begin{align*}
    \{ y_\beta : \beta \geq \gamma \} = \{ x_{\varphi(\beta)} : \beta \geq \gamma \} \subseteq \{ x_\alpha : \alpha \geq \eta \}
\end{align*}
This shows that $y(\mathcal{E}_B)$ refines $x(\mathcal{E}_A)$.
\end{proof}
\begin{proposition}[Ordering of subnets]
The AA-subnet relation between nets is a pre-order on them. Same holds for other types of subnet.
\end{proposition}
\begin{proof}
\underline{For AA-subnet:} by definition, $\mathcal{E}[x]$ refines $\mathcal{E}[y]$, which in turns refines $\mathcal{E}[z]$. Because refinement relation is transitive, we know that $\mathcal{E}[x]$ refines $\mathcal{E}[z]$. Additionally also refines itself, so every net is an AA-subnet of itself.
\\
\\
\underline{For Kelley subnet:} let $\varphi: A \to B$ and $\psi: B \to C$ be monotone and cofinal maps such that $x = y \circ \varphi$ and $y = z \circ \psi$. Thus, $x = z \circ (\psi \circ \varphi)$. We will verify that $\psi \circ \varphi$ is cofinal. For each $\gamma_0 \in C$, there exists $\beta_0 \in B$ such that $\psi(\beta) \geq \gamma_0$ for all $\beta \geq \beta_0$. With such $\beta_0 \in B$, there then exists some $\alpha_0 \in A$ such that $\varphi(\alpha) \geq \beta_0$ whenever $\alpha \geq \alpha_0$. Therefore, $\psi(\varphi(\alpha)) \geq \gamma$ for all $\alpha \geq \alpha_0$.
\\
On the other hand, given $x: A \to X$ a net, then $\operatorname{id}_A : A \to A$ is cofinal (just pick $\beta_0 = \alpha_0$ for any $\alpha_0 \in A$ to get $\operatorname{id}_A (\beta) = \beta \geq \beta_0 = \alpha_0$ for all $\beta \geq \beta_0$), and $x = x \circ \operatorname{id}_A$.
\\
\\
\underline{For Willard subnet:} just copy the cofinal proof. The monotone one come from the fact that pre-ordered sets with monotone maps form a category. Explicitly,
\begin{enumerate}
    \item Whenever $\alpha_1 \leq \alpha_2$, we get $\varphi(\alpha_1) \leq \varphi(\alpha_2)$ and $\psi(\varphi(\alpha_1)) \leq \psi(\varphi(\alpha_2))$.
    \item The identity map on any pre-ordered set is always monotone: $\operatorname{id}_A (\alpha_1) = \alpha_1 \leq \alpha_2 = \operatorname{id}_A (\alpha_2)$ whenever $\alpha_1 \leq \alpha_2$
\end{enumerate}
\end{proof}
\begin{proposition}[Equivalent definition of AA-subnet]
Let $x: A \to X$, $y: B \to X$ be nets. TFAE:
\begin{enumerate}
    \item $y$ is an AA-subnet of $x$.
    \item A frequent subset with respect to $y$ is also frequent with respect to $x$.
    \item An eventual subset of with respect to $x$ is also eventual with respect to $y$
    \item If $D \subseteq A$ is eventual, i.e. $D \supseteq \{ \alpha \in A : \alpha \geq \eta \}$ for some $\eta \in A$, then $y^{-1}(x(D))$ is eventual in $B$.
\end{enumerate}
\end{proposition}
\begin{proof}
We show $(1) \Rightarrow (2) \Rightarrow (3) \Rightarrow (4) \Rightarrow (1)$
\\
\\
*Suppose $y$ is an AA-subnet of $x$: let $T$ be a frequent subset of $X$ with respect to $y$ and $\eta$ be an element of $A$. Since $\mathcal{E}[y]$ refines $\mathcal{E}[x]$, there exists some $\gamma \in B$ such that $\{ y_\beta : \beta \geq \gamma \} = \{ x_{\varphi(\beta)} : \beta \geq \gamma \} \subseteq \{ x_\alpha : \alpha \geq \eta \}$. By assumption, there is some $\beta_T \geq \gamma$ such that $y_{\beta_T} = x_{\varphi(\beta_T)} \in T$. In other words, there is some $\alpha_T = \varphi(\beta_T) \geq \eta$ such that $x_{\alpha_T} \in T$. By definition, $T$ is frequent with respect to $x$.
\\
\\
*Suppose any frequent subset with respect to $y$ is also frequent with respect to $x$: let $K$ be a $x$-eventual subset of $X$. Apply \hyperref[event-freq-equiv]{Lemma \ref*{event-freq-equiv}}, $X \setminus K$ must not be $x$-frequent. By the hypothesis, $X \setminus K$ is also not $y$-frequent. Equivalently, $K$ is $y$-eventual.
\\
\\
*Suppose any eventual subset of with respect to $x$ is also eventual with respect to $y$: let $D \subseteq A$ be eventual. Then $x(D)$ is $x$-eventual subset of $X$. Indeed, since $D$ contains $\{ \alpha \in A : \alpha \geq \eta \}$ for some $\eta \in A$, $x(D)$ contains $\{ x_\alpha : \alpha \geq \eta \}$. By the hypothesis, $x(D)$ is also $y$-eventual, so there must exists some $\gamma \in B$ such that $y_\beta \in x(D)$ for all $\beta \geq \gamma$, or simply, $x(D)$ contains $\{ y_\beta : \beta \geq \gamma \}$. Taking the inverse image (under $y$) on both side we get $y^{-1}(x(D))$ contains $y^{-1}\{ y_\beta : \beta \geq \gamma \} \supseteq \{ \beta \in B : \beta \geq \gamma \}$, i.e. $y^{-1}(x(D))$ is eventual in $B$.
\\
\\
*Finally, suppose $y^{-1}(x(D))$ is eventual in $B$ whenever $D$ is eventual in $A$: since $D = \{ \alpha \in A : \alpha \geq \eta \}$ is automatically eventual in $A$, $y^{-1}(x(D)) = \{ \beta \in B : y_\beta = x_\alpha \mbox{ for some } \alpha \geq \eta \}$ must contains $\{ \beta \in B : \beta \geq \gamma \}$ for some $\gamma \in B$. In other words, $\{ y_\beta : \beta \geq \gamma \} \subseteq x(D) = \{ x_\alpha : \alpha \geq \eta \}$. As $\eta$ varies in $A$, this shows that $\mathcal{E}[y]$ refines $\mathcal{E}[x]$, i.e. $y$ is an AA-subnet of $x$.
\end{proof}
2 nets are called \emph{AA-equivalent} if each of them is an AA-subnet of another one.
\begin{lemma}
Let $x: A \to X$, $y: B \to X$ be nets, and $\mathcal{E}[x], \mathcal{E}[y]$ be correspondingly the eventuality filter bases. Then TFAE
\begin{enumerate}
    \item $F_x \cap F_y \neq \varnothing$ for every $F_x \in \mathcal{E}[x]$, $F_y \in \mathcal{E}[y]$.
    \item $\mathcal{M} = \{ S \subseteq X : S \supseteq F_x \cap F_y \mbox{ for some } F_x \in \mathcal{E}[x], F_y \in \mathcal{E}[y] \}$ is a proper filter.
    \item $\mathcal{E}[x], \mathcal{E}[y]$ have a common filter base refining both.
    \item $x$ and $y$ have a common AA-subnet.
    \item $x$ and $y$ have a common Willard subnet. Furthermore, such subnet can be chosen to be a maximal AA-subnet (i.e. under AA-subnet relation).
\end{enumerate}
\end{lemma}
\begin{proof}
We will show $(1) \Rightarrow (2) \Rightarrow (3) \Rightarrow (4) \Rightarrow (5) \Rightarrow (1)$.
\\
\\
*Suppose $F_x \cap F_y \neq \varnothing$ for every $F_x \in \mathcal{E}[x]$ and $F_y \in \mathcal{E}[y]$:
\begin{enumerate}
    \item If $S \subseteq T$ with $S \in \mathcal{M}$, then $T \supseteq S \supseteq F_x \cap F_y$ for some $F_x \in \mathcal{E}[x]$ and $F_y \in \mathcal{E}[y]$. By construction $T \in \mathcal{M}$.
    \item If $S^k \supseteq F^k_x \cap F^k_y$ for $k = 1, 2$, where $F^k_x \in \mathcal{E}[x]$ and $F^k_y \in \mathcal{E}[y]$, then $S^1 \cap S^2 \supseteq (F^1_x \cap F^1_y) \cap (F^2_x \cap F^2_y) = (F^1_x \cap F^2_x) \cap (F^1_y \cap F^2_y)$. Since $\mathcal{E}[x], \mathcal{E}[y]$ are filter base, we know that $F_x \subseteq F^1_x \cap F^2_x$ and $F_y \subseteq F^1_y \cap F^2_y$ for some $F_x \in \mathcal{E}[x]$ and $F_y \in \mathcal{E}[y]$. In summary, $S^1 \cap S^2 \supseteq (F^1_x \cap F^2_x) \cap (F^1_y \cap F^2_y) \supseteq F_x \cap F_y$, and so $S^1 \cap S^2 \in \mathcal{M}$.
    \item If $\mathcal{M}$ is not proper, then $\varnothing \in \mathcal{M}$, which means $\varnothing \supseteq F_x \cap F_y$ for some $F_x \in \mathcal{E}[x]$ and $F_y \in \mathcal{E}[y]$. In particular, $F_x \cap F_y = \varnothing$, contradicting the hypothesis.
\end{enumerate}
\ \\
*Suppose $\mathcal{M}$ is a proper: this means that $F_x \cap F_y$ can never be empty for all $F_x \in \mathcal{E}[x]$ and $F_y \in \mathcal{E}[y]$. Therefore, $\mathcal{M}$ is a filter base that refines $\mathcal{E}[x]$ since $F_x \supseteq F_x \cap G$ for a fixed $G \in \mathcal{E}[y]$. Similarly, $\mathcal{M}$ refines $\mathcal{E}[y]$.
\\
\\
*Suppose $\mathcal{B}$ is a common filter base refining both $\mathcal{E}[x]$ and $\mathcal{E}[y]$: let $z: \mathcal{B} \to X$ be a derived net (which exists assuming choice). This leads to a filter base $\mathcal{E}[z]$ which should refines $\mathcal{B}$. Indeed, since $x_C \in C \subseteq B$ for any $C \subseteq B$ ($C, B \in \mathcal{B}$), we get $\{ x_C : C \subseteq B \} \subseteq B$ for each $B \in \mathcal{B}$. Because refinement relation is transitive, $\mathcal{E}[z]$ refines both $\mathcal{E}[x]$ and $\mathcal{E}[y]$. By definition, $z$ is an AA-subnet to both $x$ and $y$.
\\
\\
*Suppose $x$ and $y$ has a common AA-subnet: $C = \{ (\alpha, \beta) \in A \times B : x_\alpha = y_\beta \}$ ordered by $(\alpha_1, \beta_1) \leq (\alpha_2, \beta_2)$ iff $\alpha_1 \leq \alpha_2$ and $\beta_1 \leq \beta_2$. Construct $z: C \to X$ where $z(\alpha, \beta) = x_\alpha = y_\beta$. We verify the followings
\begin{enumerate}
    \item $C$ is a frequent subset of $A \times B$, and so it is directed: let $w: D \to X$ be a common AA-subnet of $x$ and $y$. Given $\alpha_0 \in A$ and $\beta_0 \in B$, then there exists $\omega_0^A, \omega_0^B, \omega_0 \in D$ such that
    \begin{align*}
        \{ w_\delta : \delta \geq \omega_0^A \} & \subseteq \{ x_\alpha : \alpha \geq \alpha_0 \}
        \\
        \{ w_\delta : \delta \geq \omega_0^B \} & \subseteq \{ y_\beta : \beta \geq \beta_0 \}
        \\
        \omega_0 & \geq \omega_0^A, \omega_0^B
    \end{align*}
    Therefore, $\{ w_\delta : \delta \geq \omega_0 \} \subseteq \{ x_\alpha : \alpha \geq \alpha_0 \} \cap \{ y_\beta : \beta \geq \beta_0 \}$. In particular, as $\alpha_0$ and $\beta_0$ varies, $C$ becomes a frequent subset of $A \times B$.
    \\
    \\
    Hence, for all $(\alpha_k, \beta_k) \in C$ ($k = 1, 2$), let $\alpha_0$ and $\beta_0$ be respective upper bound of $\alpha_1, \alpha_2$ and $\beta_1, \beta_2$. Since $C$ is frequent, there exists $(\alpha_f, \beta_f) \geq (\alpha_0, \beta_0) \geq (\alpha_k, \beta_k)$ ($k = 1, 2$). We conclude that $C$ is directed.
    \item Let $\pi_A : C \to A$ and $\pi_B : C \to B$ be projection of coordinates in $C$. Then
    \begin{enumerate}
        \item Whenever $(\alpha_1, \beta_1) \leq (\alpha_2, \beta_2)$, we get $\pi_A (\alpha_1, \beta_1) = \alpha_1 \leq \alpha_2 = \pi_A (\alpha_2, \beta_2)$, i.e. $\pi_A$ is monotone. Similarly, $\pi_B$ is monotone.
        \item Whenever $\alpha_0 \in A$, fix some $\beta_0 \in B$, and let $(\alpha_f, \beta_f) \in C$ such that $(\alpha_f, \beta_f) \geq (\alpha_0, \beta_0)$. Then $\pi_A (\alpha, \beta) = \alpha \geq \alpha_f \geq \alpha_0$ for all $(\alpha, \beta) \geq (\alpha_f, \beta_f)$. In other words, $\pi_A$ (and $\pi_B$ similarly) is cofinal.
    \end{enumerate}
    \item Furthermore, $z(\alpha, \beta) = x_\alpha = y_\beta = x \circ \pi_A (\alpha, \beta) = y \circ \pi_B (\alpha, \beta)$ for all $(\alpha, \beta) \in C$. This concludes $z$ to be a Willard subnet of both $x$ and $y$.
    \item Additionally, $z$ is the maximal AA-subnet: let $w: D \to X$ to be any AA-subnet of $x$ and $y$. Using the same argument in part (1), there exists $\omega_0 \in D$ for each $(\alpha_0, \beta_0) \in A \times B$ such that
    \begin{align*}
        \{ w_\delta : \delta \geq \omega_0 \} \subseteq \{ x_\alpha : \alpha \geq \alpha_0 \} \cap \{ y_\beta : \beta \geq \beta_0 \}
    \end{align*}
    If $\gamma_0 = (\alpha_0, \beta_0) \in C$, then $\{ w_\delta : \delta \geq \omega_0 \} \subseteq \{ x_\alpha : \alpha \geq \alpha_0 \} \cap \{ y_\beta : \beta \geq \beta_0 \} = \{ z = x_\alpha = y_\beta : (\alpha, \beta) \geq (\alpha_0, \beta_0) \} = \{ z_\gamma : \gamma \geq \gamma_0 \}$. As $\gamma_0 \in C$ can be made arbitrary, $w$ is an AA-subnet of $z$.
\end{enumerate}
\ \\
*Suppose $z: C \to X$ is a common Willard subnet to both $x$ and $y$: as $z$ is also AA-subnet of $x$ and $y$, the eventuality filter base $\mathcal{E}[z]$ refines both $\mathcal{E}[x]$ and $\mathcal{E}[y]$. For each $F_x \in \mathcal{E}[x]$ and $F_y \in \mathcal{E}[y]$, let $G_x, G_y, H \in \mathcal{E}[z]$ be sets such that $G_x \subseteq F_x, G_y \subseteq F_y$, and $H \subseteq G_x \cap G_y$. By definition, $H$ is a non-empty subset of $G_x \cap G_y \subseteq F_x \cap F_y$, so $F_x \cap F_y$ must be non-empty.
\end{proof}
\begin{corollary}
Every AA-subnet is AA-equivalent to a Willard subnet.
\end{corollary}
\begin{proof}
If $x: A \to X$ is net, and $y: B \to X$ is some AA-subnet of $x$, then by previous lemma, we can construct a Willard subnet to both $x$ and $y$. In particular $z$ is an AA-subnet of $y$. Additionally, $z$ can be made into the maximal AA-subnet, indicating that $y$ must be AA-subnet of $z$ (note $y$ is AA-subnet of itself). By definition, $y$ is AA-equivalent to a Willard subnet $z$ of $x$.
\end{proof}
\ 
\\
\begin{proposition}[Transformational Adjunction II] \label{conv-trans-adjunct-ii}
Let $(x_\alpha)_{\alpha \in A}$ be a net and $\mathcal{B}$ be a filter base on $X$. Show that
\begin{center}
    $\mathcal{B}$ refines the eventuality filter base of $(x_\alpha)_{\alpha \in A}$ if and only if the canonical net of $\mathcal{B}$ is an AA-subnet of $(x_\alpha)_{\alpha \in A}$.
\end{center}
Additionally, the eventuality filter base of the canonical net of $\mathcal{B}$ is just $\mathcal{B}$!
\end{proposition}
\begin{proof} \ \\
*Suppose $\mathcal{B}$ refines $x(\mathcal{E}_A)$: the canonical net of $\mathcal{B}$ is $\pi_\mathcal{B}: \langle X, \mathcal{B} \rangle \to X$. The eventuality filter base $\mathcal{F} = \pi_\mathcal{B} (\mathcal{E}_{\langle X, \mathcal{B} \rangle})$ of this net is: $S \in \mathcal{F}$ if and only if $S = \pi_\mathcal{B} \{ (q, C) \in \langle X, \mathcal{B} \rangle: (q, C) \geq (p, B) \} = \{ (q, C) \in \langle X, \mathcal{B} \rangle: C \subseteq B \} = B$ for some $p \in B \in \mathcal{B}$. In other words, $\mathcal{F} = \mathcal{B}$, so $\pi_\mathcal{B}$ is an AA-subnet of $(x_\alpha)_{\alpha \in A}$ (as $\mathcal{B}$ refines $x(\mathcal{E}_A)$ by assumption).
\\
\\
*Suppose $\pi_\mathcal{B}: \langle X, \mathcal{B} \rangle \to X$ is an AA-subnet of $(x_\alpha)_{\alpha \in A}$. Again, we know that $\mathcal{B}$ is just the eventuality filter base on $X$ of $\pi_\mathcal{B}$. Therefore, $\mathcal{B}$ is finer than the eventuality filter base $x(\mathcal{E}_A)$ of $x$.
\end{proof}
\begin{remark}
Given a net $(p_\alpha)_{\alpha \in A}$, the canonical filtered sequence is the same $p$, but with $\mathcal{E}_A$ as the eventuality filter base on $A$.
\\
\\
Vice versa, given a $\mathcal{B}$-filtered sequence $(x_i)_{i \in I}$, then the canonical net of the sequence is the composition $\lambda: \langle I, \mathcal{B} \rangle \to X$ of the projection $\pi_\mathcal{B}: \langle I, \mathcal{B} \rangle \to I$ and $x: I \to X$ itself (recall that $\langle I, \mathcal{B} \rangle = \{ (i, B) : i \in B \in \mathcal{B} \}$)
\end{remark}
\begin{proposition}[Transformational Bi-adjunction III]
Let $(x_i)_{i \in I}$ be a $\mathcal{B}$-filtered sequence and $(p_\alpha)_{\alpha \in A}$ be a net in $X$. Then
\begin{enumerate}
    \item $(p_\alpha)_{\alpha \in A}$ is an AA-subnet of the canonical net of $(x_i)_{i \in I}$ if and only if the canonical sequence of $(p_\alpha)_{\alpha \in A}$ is an AA-subsequence of $(x_i)_{i \in I}$.
    \item $(x_i)_{i \in I}$ is an AA-subsequence of the canonical sequence of $(p_\alpha)_{\alpha \in A}$ if and only if the canonical net of $(x_i)_{i \in I}$ is an AA-subnet of $(p_\alpha)_{\alpha \in A}$.
\end{enumerate}
In the categorical sense, filtered sequence and net provides the same expressive power. They are still less expressive (but more general), though, than filter base as many filtered sequences and nets have the same induced filter base.
\end{proposition}
\begin{proof} \ \\
*Suppose $(p_\alpha)_{\alpha \in A}$ is an AA-subnet of the the canonical net of $(x_i)_{i \in I}$: let $\lambda : \langle I, \mathcal{B} \rangle \to X$ be the composition of $\pi_\mathcal{B}: \langle I, \mathcal{B} \rangle \to I$ and $x: I \to X$. By assumption, $p(\mathcal{E}_A)$ refines $\lambda(\mathcal{E}_{\langle I, \mathcal{B} \rangle}) = x(\pi_\mathcal{B}(\mathcal{E}_{\langle I, \mathcal{B} \rangle}))$. Since we have proved  $\pi_\mathcal{B}(\mathcal{E}_{\langle X, \mathcal{B} \rangle}) = \mathcal{B}$ (even when $X$ is just a set) in \hyperref[conv-trans-adjunct-ii]{Proposition \ref*{conv-trans-adjunct-ii}}), this shows that $p(\mathcal{E}_A)$ refines $x(\mathcal{B})$. Finally, note that the canonical sequence of $(p_\alpha)_{\alpha \in A}$ only adds $\mathcal{E}_A$ as a filter base on the index set $A$, we conclude the canonical sequence of $(p_\alpha)_{\alpha \in A}$ is an AA-subsequence of $(x_i)_{i \in I}$.
\\
\\
Vice versa, suppose the canonical sequence of $(p_\alpha)_{\alpha \in A}$ is an AA-subsequence of $(x_i)_{i \in I}$: in other words, $p(\mathcal{E}_A)$ refines $x(\mathcal{B})$. By previous part, we know that the eventuality filter base of the canonical net $\lambda: \langle I, \mathcal{B} \rangle \to X$ is just $x(\mathcal{B})$ and so, by definition, $(p_\alpha)_{\alpha \in A}$ is an AA-subnet of the canonical net of $(x_i)_{i \in I}$.
\\
\\
*The reverse adjunction is proven similarly.
\end{proof}
\begin{proposition}[Compositional relation between transformations]
Let $\mathcal{F}$ be a filter base, $(x_i)_{i \in I}$ be a $\mathcal{B}$-filtered sequence, and $(p_\alpha)_{\alpha \in A}$ be a net on $X$.
\begin{enumerate}
    \item If the canonical sequence of $\mathcal{F}$ is $(x_i)_{i \in I}$, and the canonical net of $(x_i)_{i \in I}$ is $(p_\alpha)_{\alpha \in A}$, then the canonical net of $\mathcal{F}$ coincides with $(p_\alpha)_{\alpha \in A}$.
    \item If the canonical net of $\mathcal{F}$ is $(p_\alpha)_{\alpha \in A}$, and the canonical sequence of $(p_\alpha)_{\alpha \in A}$ is $(x_i)_{i \in I}$, then canonical sequence of $\mathcal{F}$ admits $(x_i)_{i \in I}$ as a KW-subsequence.
    \item If the induced filter base of $(x_i)_{i \in I}$ is $\mathcal{F}$, and the canonical net of $\mathcal{F}$ is $(p_\alpha)_{\alpha \in A}$, then the canonical net of $(x_i)_{i \in I}$ is a Willard subnet of $(p_\alpha)_{\alpha \in A}$.
    \item If the canonical net of $(x_i)_{i \in I}$ is $(p_\alpha)_{\alpha \in A}$, and the eventuality filter base of $(p_\alpha)_{\alpha \in A}$ is $\mathcal{F}$, then the induced filter base of $(x_i)_{i \in I}$ coincides with $\mathcal{F}$.
    \item If the eventuality filter base of $(p_\alpha)_{\alpha \in A}$ is $\mathcal{F}$, and the canonical sequence of $\mathcal{F}$ is $(x_i)_{i \in I}$, then the canonical sequence of $(p_\alpha)_{\alpha \in A}$ is a KW-subsequence of $(x_i)_{i \in I}$.
    \item If the canonical sequence of $(p_\alpha)_{\alpha \in A}$ is $(x_i)_{i \in I}$, and the induced filter base of $(x_i)_{i \in I}$ is $\mathcal{F}$, then the eventuality filter base of $(p_\alpha)_{\alpha \in A}$ coincides with $\mathcal{F}$.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} by the hypothesis, $x = \operatorname{id}_X, \mathcal{B} = \mathcal{F}$, and $A = \langle I, \mathcal{B} \rangle = \langle X, \mathcal{F} \rangle, p = \operatorname{id}_X \circ \pi_\mathcal{F} = \pi_\mathcal{F}$. On the other hand, the canonical net of $\mathcal{F}$ is $\pi_\mathcal{F}: \langle X, \mathcal{F} \rangle \to X$, which is the same as $p$.
\\
\underline{Part 2:} by the hypothesis, $p: A \to X$ is the same as $\pi_\mathcal{F} : \langle X, \mathcal{F} \rangle \to X$, and $(x, \mathcal{B})$ is the same as $(p, \mathcal{E}_A) = (\pi_\mathcal{F}, \mathcal{E}_{\langle X, \mathcal{F} \rangle})$. On the other hand, the canonical sequence of $\mathcal{F}$ is $(\operatorname{id}_X, \mathcal{F})$, so consider $\varphi = \pi_\mathcal{F}$, which should serves as the re-indexing map from $\pi_\mathcal{F}$ to $\operatorname{id}_X$
\begin{enumerate}
    \item $\pi_\mathcal{F} = \operatorname{id}_X \circ \varphi$.
    \item Note that $\pi_\mathcal{F}(\mathcal{E}_{\langle X, \mathcal{F} \rangle}) = \mathcal{F}$, so $\varphi(\mathcal{E}_{\langle X, \mathcal{F} \rangle})$ refines $\mathcal{F}$ by reflexivity.
\end{enumerate}
\underline{Part 3:} by the hypothesis, $\mathcal{F} = x(\mathcal{B})$, and $A = \langle X, x(\mathcal{B}) \rangle, p = \pi_{x(\mathcal{B})}$. On the other hand, the canonical net of $(x_i)_{i \in I}$ is $x \circ \pi_\mathcal{B}: \langle I, \mathcal{B} \rangle \to X$, so consider the map $\mu_x : \langle I, \mathcal{B} \rangle \to \langle X, x(\mathcal{B}) \rangle$ where $(i, B)$ is sent to $(x_i, x(B))$.
\begin{enumerate}
    \item $p(\mu_x(i, B)) = \pi_{x(\mathcal{B})} (x_i, x(B)) = x_i = x(\pi_\mathcal{B}(i, B))$
    \item $\mu_x$ is monotone: if $(i_1, B_1) \leq (i_2, B_2)$, then $B_1 \supseteq B_2$, $x(B_1) \supseteq x(B_2)$, and $(x_{i_1}, x(B_1) \leq (x_{i_2}, x(B_2))$, or equivalently, $\mu_x(i_1, B_1) \leq \mu_x (i_2, B_2)$.
    \item $\mu_x$ is cofinal: given $(p, x(B))$ ($p \in x(B), B \in \mathcal{B}$), then pick some $i \in B$, we get $\mu_x(i, B) = (x_i, x(B))$. So for all $(j, C) \geq (i, B)$, we get $C \subseteq B$, $x(C) \subseteq x(B)$, and $\mu_x(j, C) = (x_j, x(C)) \geq (p, x(B))$
\end{enumerate}
We conclude that the canonical net (which is $x \circ \pi_\mathcal{B}$) of $(x_i)_{i \in I}$ is a Willard subnet of $(p_\alpha)_{\alpha \in A}$ (or $\pi_{x(\mathcal{B})}$.
\\
\underline{Part 4:} by the hypothesis, $A = \langle I, \mathcal{B} \rangle, p = x \circ \pi_{\mathcal{B}}$, and $\mathcal{F} = p(\mathcal{E}_A) = x(\pi_\mathcal{B}(\mathcal{E}_{\langle I, \mathcal{B} \rangle})) = x(\mathcal{B})$. The induced filter base of $(x_i)_{i \in I}$ is just $x(\mathcal{B})$, so they coincide.
\\
\underline{Part 5:} by the hypothesis, $\mathcal{F} = p(\mathcal{E}_A)$ and $(x, \mathcal{B}) = (\operatorname{id}_X, \mathcal{F}) = (\operatorname{id}_X, p(\mathcal{E}_A))$. On the other hand, the canonical sequence of $(p_\alpha)_{\alpha \in A}$ is $(p, \mathcal{E}_A)$, so consider $p: A \to X$
\begin{enumerate}
    \item $p = \operatorname{id}_X \circ p = x \circ p$
    \item $p(\mathcal{E}_A) = \mathcal{F} = \mathcal{B}$, so $p(\mathcal{E}_A)$ refines $\mathcal{B}$ in particular.
\end{enumerate}
Therefore, $p$ serves as the re-indexing map from $(p, \mathcal{E}_A)$ to $(x, \mathcal{B})$.
\\
\underline{Part 6:} by the hypothesis, $(p, \mathcal{E}_A) = (x, \mathcal{B})$ and $\mathcal{F} = x(\mathcal{B}) = p(\mathcal{E}_A)$. On the other hand, the eventuality filter base of $(p_\alpha)_{\alpha \in A}$ is $p(\mathcal{E}_A)$ so they coincide.
\end{proof}
\ 
\\
A \emph{derived net} on a filter base $\mathcal{B}$ on $X$ is a net $x: \mathcal{B} \to X$ (with $\mathcal{B}$ ordered under reverse inclusion) such that $x(B) \in B$ for all $B \in \mathcal{B}$.
\begin{proposition}
A filter base $\mathcal{B}$ converges to $x$ if and only if every derived net on $\mathcal{B}$ converges to $x$.
\end{proposition}
\begin{proof}
Suppose $\mathcal{B} \to x$. Let $p: \mathcal{B} \to X$ to be any derived net on $\mathcal{B}$. Given a neighborhood $U$ of $x$, there exists some $B \in \mathcal{B}$ such that $B \subseteq U$. Hence $p_F \in F \subseteq U$ for all $F \subseteq B, F \in \mathcal{B}$. By definition, the net $(p_B)_{B \in \mathcal{B}}$ converges to $x$.
\\
\\
Vice versa, suppose $\mathcal{B}$ does not converge to $x$. We will construct a derived net that also does not converge to $x$. By the hypothesis, there exists a neighborhood $N$ of $x$ such that $B \not\subseteq N$ for all $B \in \mathcal{B}$. Equivalently, $B \setminus N \neq \varnothing$  for all $B \in \mathcal{B}$. Hence, let $q: \mathcal{B} \to X$ be a derived net such that $q_B \notin N$ for all $B \in \mathcal{B}$. If $q_B \xrightarrow[]{B} x$, then given the neighborhood $N$ of $p$, there exists some $C \in \mathcal{B}$ such that $q_B \in N$ for all $B \subseteq C$, a contradiction to the fact that $q_B \notin N$ for all $B \in \mathcal{B}$. Hence, $q_B$ does not converge to $x$.
\end{proof}
\underline{Proof Note:} the reverse direction essentially requires axiom of choice for the existence of a derived net.

\newpage

\section{Continuity}
A \emph{continuous} map $f: (X, \mathcal{T}_X) \to (Y, \mathcal{T}_Y)$ between topological spaces consists of a function $f: X \to Y$ between sets such that $f^{-1}(V)$ is open in $X$ whenever $V$ is open in $Y$.
\begin{proposition} \label{img-event-freq}
Let $f: X \to Y$ be a function between sets, $\mathcal{B}$ be a filter base on $X$, and $S$ be a subset of $X$
\begin{enumerate}
    \item If $S$ is $\mathcal{B}$-eventual, then $f(S)$ is $f(\mathcal{B})$-eventual.
    \item If $S$ is $\mathcal{B}$-frequent, then $f(S)$ is $f(\mathcal{B})$-frequent.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} by assumption, there exists $B \in \mathcal{B}$ such that $B \subseteq S$. Apply $f$ on both side we get, $f(B) \subseteq f(S)$ (and $f(B) \in f(\mathcal{B})$).
\\
\underline{Part 2:} by assumption, for each $B \in \mathcal{B}$, $B \cap S \neq \varnothing$. Again, applying $f$ on both side, we get $f(B \cap S) \neq \varnothing$. But $f(B \cap S) \subseteq f(B) \cap f(S)$, so we also have $f(B) \cap f(S) \neq \varnothing$.
\end{proof}
\begin{theorem}[Equivalence of definitions] \label{cont-equiv-def}
Given a function $f: X \to Y$ between spaces, TFAE:
\begin{enumerate}
    \item $f$ is continuous.
    \item {[Closedness]} The inverse image of a closed set (under $f$) is closed.
    \item {[Neighborhood]} $f$ is continuous at $x$ for every $x \in X$. Here, $f$ is \emph{continuous at} $x$ if for every neighborhood $N$ of $f(x)$, $f^{-1}(N)$ is a neighborhood of $x$.
    \item {[Convergence]} $f(\mathcal{B}) \to f(x)$ whenever $\mathcal{B} \to x$.
    \item {[Closure]} $f(\operatorname{cl}(A)) \subseteq \operatorname{cl}(f(A))$ for all $A \subseteq X$.
    \item {[Interior]} $f^{-1}(\operatorname{int}(B)) \subseteq \operatorname{int}(f^{-1}(B))$ for all $B \subseteq Y$.
\end{enumerate}
\end{theorem}
\begin{proof}
We prove $(1) \Rightarrow (2) \Rightarrow (3) \Rightarrow (4) \Rightarrow (5) \Rightarrow (6) \Rightarrow (1)$.
\\
\\
*Suppose $f$ is continuous: given $C$ a closed set in $Y$, then $f^{-1}(Y \setminus C) = X \setminus f^{-1}(C)$ is open in $X$, which shows that $f^{-1}(C)$ is closed in $X$.
\\
\\
*Suppose the inverse image of any closed set is closed: for every neighborhood $N$ of $f(x)$, there exists some open neighborhood $V \subseteq N$ of $f(x)$ (and so $x \in f^{-1}(V) \subseteq f^{-1}(N)$). By assumption, $f^{-1}(Y \setminus V) = X \setminus f^{-1}(V)$ is a closed set. Thus, $f^{-1}(V)$ is open, and so $f^{-1}(N)$ is a neighborhood of $x$.
\\
\\
*Suppose $f$ is continuous at $x$ for all $x \in X$: given $\mathcal{B} \to x$, let $N$ be a neighborhood of $f(x)$. Then $f^{-1}(N)$ is a neighborhood of $x$, so there exists some $B \in \mathcal{B}$ such that $B \subseteq f^{-1}(N)$. Equivalently, $f(B) \subseteq N$, so since $N$ is arbitrary, $f(\mathcal{B}) \to f(x)$.
\\
\\
*Suppose $f(\mathcal{B}) \to f(x)$ whenever $\mathcal{B} \to x$: let $x \in \operatorname{cl}(A)$, we need to show that $f(x) \in \operatorname{cl}(f(A))$. By \hyperref[topo-filt-seq-conv]{Theorem \ref*{topo-filt-seq-conv}}, there must be some filter base $\mathcal{B}$ converging to $x$ such that $A$ is $\mathcal{B}$-frequent. By the hypothesis and \hyperref[img-event-freq]{Proposition \ref*{img-event-freq}}, $f(\mathcal{B})$ converges to $f(x)$ and $f(A)$ is $f(\mathcal{B})$-frequent. We conclude that $f(\operatorname{cl}(A)) \subseteq \operatorname{cl}(f(A))$.
\\
\\
*Suppose $f(\operatorname{cl}(A)) \subseteq \operatorname{cl}(f(A))$ for all $A \subseteq X$ (or $\operatorname{cl}(A) \subseteq f^{-1}(\operatorname{cl}(f(A)))$): substituting $A = f^{-1}(Y \setminus B)$, we get
\begin{align*}
    \operatorname{cl}(f^{-1}(Y \setminus B)) = \operatorname{cl}(A) \subseteq f^{-1}(\operatorname{cl}(f(A))) = f^{-1}(\operatorname{cl}(f(f^{-1}(Y \setminus B)))
\end{align*}
The LHS reduces to $\operatorname{cl}(f^{-1}(Y \setminus B)) = \operatorname{cl}(X \setminus f^{-1}(B)) = X \setminus \operatorname{int}(f^{-1}(B))$. For the RHS, since $f(f^{-1}(Y \setminus B)) \subseteq Y \setminus B$, we have $f^{-1}(\operatorname{cl}(f(f^{-1}(Y \setminus B))) \subseteq f^{-1}(\operatorname{cl}(Y \setminus B)) = f^{-1}(Y \setminus \operatorname{int}(B)) = X \setminus f^{-1}(\operatorname{int}(B))$. Combining the above results together, we obtain
\begin{align*}
    X \setminus \operatorname{int}(f^{-1}(B)) & \subseteq X \setminus f^{-1}(\operatorname{int}(B)) \mbox{ or}
    \\
    \operatorname{int}(f^{-1}(B)) & \supseteq f^{-1}(\operatorname{int}(B))
\end{align*}
\\
*Suppose $f^{-1}(\operatorname{int}(B)) \subseteq \operatorname{int}(f^{-1}(B))$ for all $B \subseteq Y$: let $V$ be an open set of $Y$, and substitute $B = V$ into the hypothesis, we get $f^{-1}(V) = f^{-1}(\operatorname{int}(V)) \subseteq \operatorname{int}(f^{-1}(V))$. On the other hand, $\operatorname{int}(f^{-1}(V)) \subseteq f^{-1}(V)$, so we get $f^{-1}(V) = \operatorname{int}(f^{-1}(V))$, i.e. $f^{-1}(V)$ is open.
\end{proof}
\begin{proposition}[Continuity in terms of generation] \label{cont-gen-equiv-def}
Given $\mathcal{S}$ generates $Y$, then $f: X \to Y$ is continuous if and only if $f^{-1}(A)$ is open for every $A \in \mathcal{S}$.
\end{proposition}
\begin{proof}
The forward direction is straightforward, so we will prove the backward one. Since $\mathcal{S}$ generates $Y$, every open set $U$ in $Y$ is a union of (open sets) $\{ V_i \}_{i \in I}$, with each $V_i$ is a finite intersection of (open) sets in $\mathcal{S}$ (\hyperref[topo-gen-steps]{Theorem \ref*{topo-gen-steps}}). The inverse image preserves both intersection and union, so each $f^{-1}(V_i)$ is a \textit{finite} intersection of sets of the form $f^{-1}(A)$ ($A \in \mathcal{S}$), each is open by the hypothesis. Therefore, $f^{-1}(V_i)$ is open, and so $f^{-1}(U) = \bigcup_{i \in I} f^{-1}(V_i)$ is also open.
\end{proof}
\begin{theorem}[Category of topological space] \label{topo-cat}\ 
\begin{enumerate}
    \item The topological spaces, together with continuous functiosn, form a category, denoted as $\mathbf{Top}$.
    \item The constant map $c_s: X \to Y, x \mapsto s$ for a fixed $s \in Y$ is continuous. In particular, any map from a singleton to another space is automatically continuous.
    \item The intial object is the empty space $\varnothing$, and the termimal object is the singleton space $\{ p \}$ (any such space are essentially the same categorically).
    \item $X$ is discrete if any function $f: X \to Y$ from $X$ is continuous.
    \\
    $Y$ is indiscrete if any function $f: X \to Y$ to $Y$ is continuous.
    \item If $Y$ is discrete, then $f: X \to Y$ is continuous iff each fiber $f^{-1}(y)$ is open in $X$.
    \\
    If $X$ is indiscrete, then $f: X \to Y$ is continuous iff every open sets in $Y$ either contains the image $f(X)$ of $X$, or is disjoint from it.
\end{enumerate}
\end{theorem}
\begin{proof} \ \\
\underline{Part 1:} the identity map $\operatorname{id}_X$ is continuous since $\operatorname{id}_X^{-1}(U) = U$ is open whenever $U$ is open in $X$. Next, suppose $f: X \to Y$ and $g: Y \to Z$ are continuous. If $W$ is open in $Z$, then $g^{-1}(W)$ is open in $Y$, and $f^{-1}(g^{-1}(W)) = (g \circ f)^{-1}(W)$ is open in $X$. By definition $g \circ f$ is continuous.
\\
\underline{Part 2:} if $c_s(x) = s$ for all $x \in X$, then given an open set $V$ in $Y$, either $s \in V$, which $c_s^{-1}(V) = X$, or $s \notin V$, and $c_s^{-1}(V) = \varnothing$. In either case, the inverse image of $V$ is always open.
\\
\underline{Part 3:} there is only one map (the empty map) from $\varnothing$ to any space $X$, and it is trivially continuous as the inverse of any open subset of $X$ is empty. Similarly, there is only one map (the constant map) from $X$ to $\{ p \}$, and we already show in part (2) that this map is continuous.
\\
\underline{Part 4:} if $X$ is discrete, and $f: X \to Y$ is any map, then $f^{-1}(V)$ is always open regardless of whether $V$ is open in $Y$. Vice versa, if any function from $X$ is continuous, then consider $Y = \{ 0, 1 \}$ with the discrete topology, with $f(S) = 0$ and $f(X \setminus S) = 1$. As $f$ is continuous, $f^{-1}(0) = S$ is open (since $Y$ is discrete). But $S$ is an arbitrary subset of $X$, so $X$ is discrete by definition.
\\
\\
If $Y$ is indiscrete, and $f: X \to Y$ is any map, there are only 2 choices for open sets in $Y$: if $V = Y$, then $f^{-1}(V) = X$. If $V = \varnothing$, then $f^{-1}(V) = \varnothing$. We always have the inverse image of open sets in $Y$ to be open, thus $f$ is continuous. Vice versa, if any function to $Y$ is continuous, then consider the identity map $\operatorname{id}_Y : Y \to Y$ (where the former is endowed with indiscrete topology). If $U$ is open in $Y$, then $U$ is open (through the inverse image under $\operatorname{id}_Y$) with respect to the indiscrete topology on $Y$, and so either $U = Y$ or $U = Y$.
\\
\underline{Part 5:} if $Y$ is discrete, then $\{ y \}$ is open. Given $f: X \to Y$ a continuous map, the fiber $f^{-1}(y)$ must then be open in $X$. Vice versa, given every fiber is open in $X$, if $V$ is open in $Y$, then $f^{-1}(V)$ must be open since it is a union of fibers $f^{-1}(y)$ for $y \in V$. By definition, $f$ is continuous.
\\
\\
If $X$ is indiscrete, and $f: X \to Y$ is continuous. For each open set $V$ in $Y$, either $f^{-1}(V) = \varnothing$, which implies $f(X) \cap V = \varnothing$, or $f^{-1}(V) = X$, which implies $f(X) \subseteq V$. Vice versa, if for all open set $V$ in $Y$, either $f(X) \cap V = \varnothing$ or $f(X) \subseteq V$, then either $f^{-1}(V) = \varnothing$ (since otherwise, there will be some $x \in X$ such that $f(x) \in V$), or $X \subseteq f^{-1}(V)$ (equivalently, $X = f^{-1}(V)$). As $\varnothing$ and $X$ is open in $X$, we conclude $f$ is continuous.
\end{proof}
\begin{proposition} \label{comp-topo-cont} \ 
\begin{enumerate}
    \item $\operatorname{id}_X : (X, \mathcal{T}_1) \to (X, \mathcal{T}_2)$ is continuous if and only if $\mathcal{T}_1 \supseteq \mathcal{T}_2$.
    \item Covariance on the domain: if $f: (X, \mathcal{T}_1) \to Y$ is continuous, then $f: (X, \mathcal{T}_2) \to Y$ is continuous if $\mathcal{T}_1$ is coarser than $\mathcal{T}_2$.
    \item Contravariance on the codomain: if $f: X \to (Y, \mathcal{S}_1)$ is continuous, then $f: X \to (Y, \mathcal{S}_2)$ is continuous if $\mathcal{S}_1$ is finer than $\mathcal{S}_2$.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} suppose $\operatorname{id}_X : (X, \mathcal{T}_1) \to (X, \mathcal{T}_2)$ is continuous. Whenever $U \in \mathcal{T}_2$, we get $\operatorname{id}_X^{-1}(U) = U \in \mathcal{T}_1$. On the other hand, if $\mathcal{T}_1 \supseteq \mathcal{T}_2$, then $U \in \mathcal{T}_2$ implies $U = \operatorname{id}_X^{-1}(U) \in \mathcal{T}_1$.
\\
\underline{Part 2:} if $V$ is open in $Y$, then $f^{-1}(V) \in \mathcal{T}_1$. Since $\mathcal{T}_1 \subseteq \mathcal{T}_2$, $f^{-1}(V) \in \mathcal{T}_2$. But $V$ is arbitrary, so $f: (X, \mathcal{T}_2) \to Y$ is continuous.
\\
\underline{Part 3:} if $V \in \mathcal{S}_2$, then $V \in \mathcal{S}_1$, thus $f^{-1}(V)$ is open in $X$. By definition, $f: X \to (Y, \mathcal{S}_2)$ is continuous.
\end{proof}
\begin{proposition} \ 
\begin{enumerate}
    \item The closure of inverse image is a subset of the inverse image of closure.
    \item Surjective image of a dense set is dense. In fact, if the image of the space is dense, then the image of any dense subset is also dense.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} if $f: X \to Y$ is continuous and $B$ is a subset of $Y$, then $f^{-1}(B) \subseteq f^{-1}(\operatorname{cl}(B))$ by monotonicity (of both closure and inverse image). By minimality, $\operatorname{cl}(f^{-1}(B)) \subseteq f^{-1}(\operatorname{cl}(B))$.
\\
\underline{Part 2:} suppose $f: X \to Y$ is a continuous function with dense image $\operatorname{cl}(f(X)) = Y$, and $D$ is a dense set in $X$. By \hyperref[cont-equiv-def]{Theorem \ref*{cont-equiv-def}}, $\operatorname{cl}(f(D)) \supseteq f(\operatorname{cl}(D)) = f(X)$. Taking the closure on both side, we get $\operatorname{cl}(f(D)) \supseteq \operatorname{cl}(f(X)) = Y$, or $\operatorname{cl}(f(D)) = Y$.
\end{proof}
Given $X, Y$ topological spaces, we write $C(X, Y)$ to be the set of continuous functions $X \to Y$. If $X = Y$, we shorten to $C(X)$.
\\
\\
Let $S = \{ 0, 1 \}$ with the topology to be $\{ \varnothing, \{ 1 \}, S \}$. Such space is called the \emph{SierpiÅski space}.
\begin{theorem}[Representation Theorem]
The functor $\mathcal{T}$ that sends a space to its underlying topology, and a continuous map $f: X \to Y$ to $\mathcal{T}f: \mathcal{T}(Y) \to \mathcal{T}(X)$ (where $\mathcal{T}f(V) = f^{-1}(V)$) is representable, that is there is some space $J$ such that $\mathcal{T}(-)$ is naturally isomorphic to $C(-, J)$
\end{theorem}
\begin{proof}
The space $J$ we need is the SierpiÅski space $S$. First, however, we shall verify that $\mathcal{T}$ is a contravariant functor. This is straight from construction and
\begin{enumerate}
    \item $\mathcal{T}\operatorname{id}_X (U) = \operatorname{id}_X^{-1}(U) = U$ for any open set $U$, i.e. $\mathcal{T}$ maps identities to identities.
    \item Given $f: X \to Y$ and $g: Y \to Z$ continuous, we get $\mathcal{T}f \circ \mathcal{T}g (W) = \mathcal{T}f(g^{-1}(W)) = f^{-1}(g^{-1}(W)) = (g \circ f)^{-1}(W) = \mathcal{T}(g \circ f) (W)$ open in $X$ whenver $W$ is open in $Z$.
\end{enumerate}
Next, we show that $\mathcal{T}(-) \cong C(-, S)$. Let $\eta_X : \mathcal{T}(X) \to C(X, S)$ be the map where $\eta_X (U) = 1_U$ (here, $1_U(x) = 1$ iff $x \in U$). Then $\eta_X$ is
\begin{enumerate}
    \item Well-defined: given $U$ open in $X$, then $1_U$ is continuous. Indeed, as $S$ only has 3 open sets, we just need to test whether $1_U^{-1}(1) = U$ is open, which is true.
    \item Has an inverse: $\eta_X^{-1}(f) = f^{-1}(1)$. Indeed, the map is well-defined since $\{ 1 \}$ is open in $S$. Furthermore, if $f = \eta_X (U)$, then $\eta_X^{-1}(f) = 1_U^{-1}(1) = U$, and if $U = \eta_X^{-1}(f)$, then we know that $f(U) = 1$ and $f(X \setminus U) = 0$, and so $f = 1_U = \eta_X(U)$.
    \item Both $\eta: \mathcal{T} \to C(-, S)$ and its inverse $\lambda$ are natural transformation: let $f: X \to Y$ be a continuous map.
    \begin{enumerate}
        \item $\eta_Y \circ \mathcal{T}f = C(f, S) \circ \eta_X$: indeed, for all $V \in \mathcal{T}(Y)$ and $x \in X$, we get
        \begin{align*}
            (\eta_Y \circ \mathcal{T}f) (V)(x) & = \eta_Y(f^{-1}(V)) (x) = 1_{f^{-1}(V)}(x) = \begin{cases}
            1 & \mbox{if } x \in f^{-1}(V)
            \\
            0 & \mbox{if } x \notin f^{-1}(V)
            \end{cases}
            \\
            (C(f, S) \circ \eta_X) (V) & = (\eta_X (V) \circ f) (x) = 1_V(f(x)) = \begin{cases}
            1 & \mbox{if } f(x) \in V
            \\
            0 & \mbox{if } f(x) \notin V
            \end{cases}
        \end{align*}
        Note that the last expression on each line is equal to each other.
        \item $\lambda_X \circ C(f, S) = \mathcal{T}f \circ \lambda_Y$: indeed for all $g \in C(Y, S)$ and $x \in X$, we get
        \begin{align*}
            (\lambda_X \circ C(f, S)) (g) & = \lambda_X (g \circ f) = (g \circ f)^{-1}(1)
            \\
            (\mathcal{T}f \circ \lambda_Y)(g) & = \mathcal{T}f (g^{-1}(1)) = f^{-1}(g^{-1}(1))
        \end{align*}
    \end{enumerate}
\end{enumerate}
\end{proof}
\ \\
An isomorphism in $\mathbf{Top}$ is called a \emph{homeomorphism}. Any property that is preserve through homeomorphism is called a \emph{topological invariant}. As for mono- and epi-morphisms, we will discuss later what they correspond to.
\begin{remark}
The followings are examples of topological invariants:
\begin{enumerate}
    \item The cardinality of the space $X$, and the cardinality of the topology on it.
    \item The weight $w(X)$ of a space $X$.
    \item The density $d(X)$ of a space $X$.
\end{enumerate}
\end{remark}
\begin{proof} Let $f: (X, \mathcal{T}_X) \to (Y, \mathcal{T}_Y)$ be a homeomorphism.
\\
\underline{Part 1:} As $f$ is also a bijection between sets, we get $|X| = |Y|$. As for topology, note that if $g: Y \to X$ is the inverse map to $f$, then $\mathcal{T}f \circ \mathcal{T} g = \mathcal{T}(f \circ g) = \mathcal{T}\operatorname{id}_Y = \operatorname{id}_{\mathcal{T}(Y)}$ and $\mathcal{T}g \circ \mathcal{T}f = \operatorname{id}_{\mathcal{T}(X)}$ similarly. In other words, $\mathcal{T}f$ is a bijection between topologies on $X$ and $Y$, i.e. the cardinality of topologies are equal.
\\
\underline{Part 2:} we show that if $\mathcal{B}$ is a basis of $X$, then $f(\mathcal{B})$ is also a basis of $Y$. Since $f^{-1}$ is also continuous, the inverse image of each $B \in \mathcal{B}$ under $f^{-1}$ is open. We also have $f(X) = f \left( \bigcup \mathcal{B} \right) = \bigcup f(\mathcal{B}) = Y$ since $f$ is a bijection. Finally, given any $B_1, B_2 \in \mathcal{B}$, then there exists some $B \in \mathcal{B}$ such that $B \subseteq B_1 \cap B_2$, hence $f(B) \subseteq f(B_1 \cap B_2) \subseteq f(B_1) \cap f(B_2)$.
\\
\\
From there, there is a one-to-one correspondence between bases of $X$ and bases of $Y$, and $|\mathcal{B}| = |f(\mathcal{B})|$ for any basis $\mathcal{B}$ (or even arbitary collection of subsets of $X$). Hence, $w(X) = \inf \{ |\mathcal{B}| : \mathcal{B} \mbox{ is a basis of } X \} = \inf \{ |f(\mathcal{B})| : \mathcal{B} \mbox{ is a basis of } X \} = \inf \{ |\mathcal{C}| : \mathcal{C} \mbox{ is a basis of } Y \} = w(Y)$.
\\
\underline{Part 3:} $f$ is homeomorphism, so $f$ is surjective in particular. Then any dense set in $X$ is sent to another dense set in $Y$, so $d(X) \geq d(Y)$. Similarly, $d(Y) \geq d(X)$.
\end{proof}

\subsection{Open map. Closed map}
Let $f: X \to Y$ be a function between topological spaces. Then
\begin{enumerate}
    \item $f$ is open if the image of any open set is also open.
    \item $f$ is closed if the image of any closed set is also closed.
\end{enumerate}
\begin{proposition}[Equivalent definition] \ 
\begin{enumerate}
    \item Open maps: TFAE
    \begin{enumerate}
        \item $f: X \to Y$ is open
        \item {[Basis]} $f(B)$ is open whenever $B \in \mathcal{B}$, where $\mathcal{B}$ is a basis.
        \item {[Neighborhood]} $f$ sends each neighborhood of a point $x$ to a neighborhood of $f(x)$.
        \item $f(\operatorname{int}(A)) \subseteq \operatorname{int}(f(A))$ for all $A \subseteq X$.
        \item Whenever $C$ is closed in $X$, then $\{ y \in Y : f^{-1}(y) \subseteq C \}$ is closed in $Y$.
    \end{enumerate}
    \item Closed maps: $f: X \to Y$ is closed iff $\operatorname{cl}(f(A)) \subseteq f(\operatorname{cl}(A))$ for any subset $A$ of $X$.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} we will show $(a) \Rightarrow (b) \Rightarrow (c) \Rightarrow (d) \Rightarrow (e) \Rightarrow (a)$.
\\
*Suppose $f: X \to Y$ is open: since a basis must contain only open set, we have $f(B)$ is open whenver $B \in \mathcal{B}$.
\\
\\
*Suppose, given a basis $\mathcal{B}$, that $f(B)$ is open whenever $B$ is in $\mathcal{B}$: if $N$ is a neighborhood of $x$, there must exists some $U$ open and $B \in \mathcal{B}$ such that $p \in B \subseteq U \subseteq N$. We then have $f(B)$ is open and $f(p) \in f(B) \subseteq f(N)$. In other words, $f(N)$ is a neighborhood of $f(p)$.
\\
\\
*Suppose $f$ sends each neighborhood of $x$ to a neighborhood of $f(x)$ for every $x \in X$: since $\operatorname{int}(A)$ is a neighborhood of every point in it $f(\operatorname{int}(A))$ is a neighborhood of every point in $f(\operatorname{int}(A))$. By \hyperref[neighborhood-simple-facts]{Remark \ref*{neighborhood-simple-facts}}, $f(\operatorname{int}(A))$ is open. Since $\operatorname{int}(A) \subseteq A$, we get $f(\operatorname{int}(A)) \subseteq f(A)$. By maximality, $f(\operatorname{int}(A)) \subseteq \operatorname{int}(f(A))$.
\\
\\
*Suppose $f(\operatorname{int}(A)) \subseteq \operatorname{int}(f(A))$ for all $A \subseteq X$: let $C$ be a closed set in $X$. Then $X \setminus C$ is open, so $f(X \setminus C) = f(\operatorname{int}(X \setminus C)) \subseteq \operatorname{int}(f(X \setminus C))$. On the other hand, $\operatorname{int}(f(X \setminus C)) \subseteq f(X \setminus C)$, so we must have $f(X \setminus C) = \operatorname{int}(f(X \setminus C))$, or simply, $f(X \setminus C)$ is open.
\\
\\
Consider $D = \{ y \in Y : f^{-1}(y) \subseteq C \}$: if $y \notin D$, then $f^{-1}(y) \not\subseteq C$, or equivalently, $f^{-1}(y) \cap (X \setminus C) \neq \varnothing$. In other words, there exists $x \in X \setminus C$ such that $f(x) = y \in Y \setminus D$. Therefore, if we let $y$ varies in $Y \setminus D$, $f(X \setminus C)$ must contain $Y \setminus D$, or equivalently, $D \supseteq Y \setminus f(X \setminus C)$. Vice versa, if $y \notin f(X \setminus C)$, then $y \neq f(x)$ for all $x \in X \setminus C$. Note that $y \neq f(x)$ is the same as saying $x \notin f^{-1}(y)$, so $X \setminus C$ is a subset of $X \setminus f^{-1}(y)$. Equivalently, $f^{-1}(y)$ is a subset of $C$, thus $y \in D$. We conclude that $D = Y \setminus f(X \setminus C)$ is closed, since we already show $f(X \setminus C)$ is open.
\\
\\
*Suppose $\{ y \in Y : f^{-1}(y) \subseteq C \}$ is closed in $Y$ whenever $C$ is closed in $X$: note that we have prove that $\{ y \in Y : f^{-1}(y) \subseteq C \}$ is the same as $Y \setminus f(X \setminus C)$. Given $U$ open set in $X$, then $X \setminus U$ is closed, so $Y \setminus f(X \setminus (X \setminus U)) = Y \setminus f(U)$ must be closed, which in turn makes $f(U)$ open.
\\
\\
\underline{Part 2:} if $f$ is closed, then $f(\operatorname{cl}(A))$ is a closed set containing $f(A)$ (since $\operatorname{cl}(A)$ contains $A$). By minimality, $f(\operatorname{cl}(A))$ contains $\operatorname{cl}(f(A))$ also. Vice versa, suppose $f(\operatorname{cl}(A)) \supseteq \operatorname{cl}(f(A))$ for all $A \subseteq X$. Let $C$ be a closed set in $X$, then $f(C) = f(\operatorname{cl}(C)) \supseteq \operatorname{cl}(f(C))$. We also have the reverse inclusion since the closure of a set always contain that set. Hence,  $f(C) = \operatorname{cl}(f(C))$, i.e. $f(C)$ is closed.
\end{proof}
\begin{proposition} \label{topo-open-closed-map-prop}\ 
\begin{enumerate}
    \item Composition of open (resp. closed) maps is open (resp. closed).
    \item A bijective map is open if and only if it is closed.
    \item Every homeomorphism is both open and closed. In fact, a bijective continuous map is a homemorphism if and only if it is open, or equivalently, if and only if it is closed.
    \item Inverse image of continuous and open maps: let $f: X \to Y$ be a function between topological spaces, and $B$ be a subset of $Y$
    \begin{enumerate}
        \item If $f$ is continuous, then $\operatorname{cl}(f^{-1}(B)) \subseteq f^{-1}(\operatorname{cl}(B))$ and $f^{-1}(\operatorname{int}(B)) \subseteq \operatorname{int}(f^{-1}(B))$.
        \item If $f$ is open, then $f^{-1}(\operatorname{cl}(B)) \subseteq \operatorname{cl}(f^{-1}(B))$ and $\operatorname{int}(f^{-1}(B)) \subseteq f^{-1}(\operatorname{int}(B))$.
    \end{enumerate}
    \item Let $f: X \to Y$ be a continuous open map and $A \subseteq X, B \subseteq Y$
    \begin{enumerate}
        \item $\operatorname{cl}(f^{-1}(B)) = f^{-1}(\operatorname{cl}(B))$
        \item $f^{-1}(\operatorname{int}(B)) = \operatorname{int}(f^{-1}(B))$
        \item $f^{-1}(\partial B) = \partial f^{-1}(B)$
        \item Suppose $f$ is surjective, then $B$ is regular open (resp. regular closed) in $Y$ if and only if $f^{-1}(B)$ is regular open (resp. regular closed) in $X$
        \item If $\operatorname{cl}(A) = \operatorname{cl}(\operatorname{int}(A))$ then
        \begin{align*}
            \operatorname{cl}(f(A)) & = \operatorname{cl}(f(\operatorname{int}(A))) = \operatorname{cl}(f(\operatorname{int}(\operatorname{cl}(A))))
            \\
            & = \operatorname{cl}(\operatorname{int}(f(A))) = \operatorname{cl}(f(\operatorname{cl}(A)))
        \end{align*}
        In particular,
        \begin{enumerate}
            \item If $A$ is regular closed, then so is $\operatorname{cl}(f(A))$.
            \item If $A$ is regular open, then so is $Y \setminus \operatorname{cl}(f(X \setminus A))$.
        \end{enumerate}
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} suppose $f: X \to Y$ and $g: Y \to Z$ are open maps. Let $U$ to be an open set of $X$, we need to show that $g \circ f (U)$ is also open in $Z$. Indeed, $f(U)$ is open in $Y$ since $f$ is open, and $g(f(U))$ is open in $Z$ since $g$ is open. Same argument for closed maps by replacing any occurrence of ``open''  with ``closed''.
\\
\\
\underline{Part 2:} suppose $f: X \to Y$ is bijective. If $f$ is open, then $f(X \setminus C) = Y \setminus f(C)$ (since $f$ is both injective and surjective) is open whenever $C$ is closed, and so $f(C)$ should be closed. Same argument for $f$ closed (by swapping between ``open'' and ``closed'').
\\
\\
\underline{Part 3:} suppose $f: X \to Y$ is a bijective continuous map, then by part (2), open and closed are equivalent, so we only need to prove one more equivalence between, say, open and homeomorphism. If $f$ is homeomorphic, then the inverse is necessarily continuous, i.e. $f(U) = (f^{-1})^{-1}(U)$ is open in $Y$ whenever $U$ is open in $X$. Vice versa, if $f$ is open, then the inverse is continuous since $(f^{-1})^{-1}(U) = f(U)$ is open whenever $U$ is open. By definition, $f$ is a homeomorphism.
\\
\\
\underline{Part 4:}
\begin{enumerate}[label=(\alph*)]
    \item Since $f^{-1}(\operatorname{cl}(B))$ is a closed set containing $f^{-1}(B)$, we get $\operatorname{cl}(f^{-1}(B)) \subseteq f^{-1}(\operatorname{cl}(B))$ by minimality. Similarly, $f^{-1}(\operatorname{int}(B))$ is an open subset of $f^{-1}(B)$, so $f^{-1}(\operatorname{int}(B)) \subseteq \operatorname{int}(f^{-1}(B))$ by maximality.
    \item Since $f$ is open, $f(X \setminus \operatorname{cl}(f^{-1}(B)))$ is open. Note that $\operatorname{cl}(f^{-1}(B)) \supseteq f^{-1}(B)$, so $X \setminus \operatorname{cl}(f^{-1}(B)) \subseteq X \setminus f^{-1}(B)$. Thus, $f(X \setminus \operatorname{cl}(f^{-1}(B))) \subseteq f(X \setminus f^{-1}(B)) = f(f^{-1}(Y \setminus B)) \subseteq Y \setminus B$. By minimality of interior, $f(X \setminus \operatorname{cl}(f^{-1}(B))) \subseteq \operatorname{int}(Y \setminus B) = Y \setminus \operatorname{cl}(B)$. Finally, applying the inverse image to both side, and note that $f^{-1}(f(A)) \supseteq A$, we get
    \begin{align*}
        X \setminus \operatorname{cl}(f^{-1}(B)) & \subseteq f^{-1}(f(X \setminus \operatorname{cl}(f^{-1}(B)))) \subseteq f^{-1}(Y \setminus \operatorname{cl}(B))
        \\
        & = X \setminus f^{-1}(\operatorname{cl}(B))
    \end{align*}
    or equivalently, $f^{-1}(\operatorname{cl}(B)) \supseteq f^{-1}(\operatorname{cl}(B))$
    \\
    \\
    Since $\operatorname{int}(f^{-1}(B)) \subseteq f^{-1}(B)$ and $f(f^{-1}(B)) \subseteq B$, we get $f(\operatorname{int}(f^{-1}(B))) \subseteq B$. Since $f$ is open, $f(\operatorname{int}(f^{-1}(B)))$ is open, so $f(\operatorname{int}(f^{-1}(B))) \subseteq \operatorname{int}(B)$ by maximality. We then apply the inverse image to both side to get $f^{-1}(f(\operatorname{int}(f^{-1}(B)))) \subseteq f^{-1}(\operatorname{int}(B))$. As $f^{-1}(f(A))$ contains $A$, we conclude that $\operatorname{int}(f^{-1}(B)) \subseteq f^{-1}(\operatorname{int}(B))$.
\end{enumerate}
\ 
\\
\underline{Part 5:}
\begin{enumerate}[label=(\alph*)]
    \item Follows from part (4).
    \item Follows from part (4).
    \item Applying part (5a) and the fact that $\partial B = \operatorname{cl}(B) \cap \operatorname{cl}(Y \setminus B)$, we get
    \begin{align*}
        f^{-1}(\partial B) & = f^{-1}(\operatorname{cl}(B) \cap \operatorname{cl}(Y \setminus B))
        \\
        & = \operatorname{cl}(f^{-1}(B)) \cap \operatorname{cl}(f^{-1}(Y \setminus B))
        \\
        & = \operatorname{cl}(f^{-1}(B)) \cap \operatorname{cl}(X \setminus f^{-1}(B)) = \partial f^{-1}(B)
    \end{align*}
    \item Note that $f^{-1}(\operatorname{int}(\operatorname{cl}(B))) = \operatorname{int}(f^{-1}(\operatorname{cl}(B))) = \operatorname{int}(\operatorname{cl}(f^{-1}(B)))$. So if $B$ is regular open, then $f^{-1}(B) = \operatorname{int}(\operatorname{cl}(f^{-1}(B)))$. Vice versa, if $f^{-1}(B)$ is regular open, we have $f^{-1}(\operatorname{int}(\operatorname{cl}(B))) = f^{-1}(B)$. Since $f$ is surjective (i.e. $f(f^{-1}(T)) = T$ for any $T \subseteq Y$)
    \begin{align*}
        \operatorname{int}(\operatorname{cl}(B)) = f(f^{-1}(\operatorname{int}(\operatorname{cl}(B)))) = f(f^{-1}(B)) = B
    \end{align*}
    Similar argument for regular closed case (or we can just use complementary to the previous result).
    \item Given $\operatorname{cl}(A) = \operatorname{cl}(\operatorname{int}(A))$, we observe the following inclusion using Hasse diagram, with $S \to T$ represents the inclusion $S \subseteq T$
    \begin{align*}
        \xymatrix{
            & f(A) \ar[d]_{(i)} &
            \\
            & f(\operatorname{cl}(A)) \ar@{=}[d] &
            \\
            & f(\operatorname{cl}(\operatorname{int}(A))) \ar[d]_{(ii)}
            \\
            & \operatorname{cl}(f(\operatorname{int}(A))) \ar[dl]_{(iii)} \ar[d]_{(iv)} \ar[dr]^{(v)} &
            \\
            \operatorname{cl}(f(\operatorname{cl}(\operatorname{int}(A)))) \ar@{=}[dr]_{(vi)} & \operatorname{cl}(f(\operatorname{int}(\operatorname{cl}(A)))) \ar[d]_{(vii)} & \operatorname{cl}(\operatorname{int}(f(A))) \ar[dd]^{(viii)}
            \\
            & \operatorname{cl}(f(\operatorname{cl}(A))) \ar[d]_{(ix)} &
            \\
            & \operatorname{cl}(\operatorname{cl}(f(A))) \ar@{=}[r] & \operatorname{cl}(f(A))
        }
    \end{align*}
    since
    \begin{enumerate}[label=(\roman*)]
        \item Comes from apply the image (under $f$) to $A \subseteq \operatorname{cl}(A)$ (as it is monotonic)
        \item Comes from substituting $S = \operatorname{int}(A)$ to $f(\operatorname{cl}(S)) \subseteq \operatorname{cl}(f(S))$ (a result of $f$ being continuous).
        \item Comes from applying image (under $f$) and then the closure operator to $\operatorname{cl}(\operatorname{int}(A)) \supseteq \operatorname{int}(A)$.
        \item Comes from applying the interior operator, image, and the closure operator to $A \subseteq \operatorname{cl}(A)$.
        \item Comes from applying the closure operator to $f(\operatorname{int}(A)) \subseteq \operatorname{int}(f(A))$ (a result of $f$ being open).
        \item Comes from the hypothesis $\operatorname{cl}(\operatorname{int}(A)) = \operatorname{cl}(A)$
        \item Comes from applying the image and closure operator to $\operatorname{int}(B) \subseteq B$ where $B = \operatorname{cl}(A)$.
        \item Comes from applying the image and closure operator to $\operatorname{int}(B) \subseteq B$ where $B = f(A)$.
        \item Comes from apply the closure operator to $f(\operatorname{cl}(A)) \subseteq \operatorname{cl}(f(A))$.
    \end{enumerate}
    By minimality of closure operator on $f(A)$, any closed set in between collapse to $\operatorname{cl}(f(A))$, i.e.
    \begin{align*}
        \operatorname{cl}(f(A)) & = \operatorname{cl}(f(\operatorname{int}(A))) = \operatorname{cl}(f(\operatorname{int}(\operatorname{cl}(A))))
        \\
        & = \operatorname{cl}(\operatorname{int}(f(A))) = \operatorname{cl}(f(\operatorname{cl}(A)))
    \end{align*}
    In particular,
    \begin{enumerate}[label=(\roman*)]
        \item If $A$ is regular closed in $X$, we get $\operatorname{cl}(A) = A = \operatorname{cl}(\operatorname{int}(A))$, so
        \begin{gather*}
            \operatorname{cl}(f(A)) = \operatorname{cl}(f(\operatorname{int}(A))) = \operatorname{cl}(\operatorname{int}(f(A)))
        \end{gather*}
        Since $\operatorname{int}(\operatorname{cl}(f(A))) \subseteq \operatorname{cl}(f(A))$, we get $\operatorname{cl}(\operatorname{int}(\operatorname{cl}(f(A)))) \subseteq \operatorname{cl}(\operatorname{cl}(f(A))) = \operatorname{cl}(f(A))$. For the reverse inclusion, since $\operatorname{cl}(f(A)) \supseteq f(A)$, we apply the closure and interior operators to get
        \begin{align*}
            \operatorname{cl}(\operatorname{int}(\operatorname{cl}(f(A)))) \supseteq \operatorname{cl}(\operatorname{int}(f(A))) = \operatorname{cl}(f(A))
        \end{align*}
        We conclude $\operatorname{cl}(f(A))$ is regular closed.
        \item if $A$ is regular open, then $X \setminus A$ is regular closed, $f(X \setminus A)$ is regular closed, and $Y \setminus f(X \setminus A)$ is regular open.
    \end{enumerate}
\end{enumerate}
\end{proof}

\subsection{Continuity at a point}
Recall that a function $f: X \to Y$ between topological spaces is continuous at a point $p$ in $X$ if $f^{-1}(N)$ is a neighborhood of $p$ whenever $N$ is a neighborhood of $f(p)$.
\begin{proposition}[Sequential continuity] \label{topo-cont-point-eq-seq-cont}
$f: X \to Y$ is continuous at $p$ if and only if $f(\mathcal{B}) \to f(p)$ whenever $\mathcal{B} \to p$.
\end{proposition}
\begin{proof}
Suppose $f$ is continuous at $p$, and $\mathcal{B}$ converges to $p$. For all neighborhood $N$ of $f(p)$, we have $f^{-1}(N)$ is a neighborhood of $p$ by definition. Thus, there exists some $B \in \mathcal{B}$ such that $B \subseteq f^{-1}(N)$. In other words, $f(B) \subseteq N$. By definition, $f(\mathcal{B}) \to f(p)$.
\\
\\
*Vice versa, suppose $f(\mathcal{B}) \to f(p)$ whenever $\mathcal{B} \to p$. In particular, $f(\mathcal{N}_p) \to f(p)$ where $\mathcal{N}_p$ is the neighborhood filter at $p$. Equivalently, for all $M$ neighborhood of $f(p)$, there exists a neighborhood $N$ of $p$ such that $f(N) \subseteq M$, or $N \subseteq f^{-1}(M)$. Since $\mathcal{N}_p$ is a neighborhood filter, $f^{-1}(M)$ is also a neighborhood of $p$. As $M$ varies, $f$ is continuous at $p$.
\end{proof}
\begin{proposition}[Pointed category]
If $f: X \to Y$ is continuous at $p$ and $g: Y \to Z$ is continuous at $f(p)$, then $g \circ f$ is continuous at $p$.
\end{proposition}
\begin{proof}
If $N$ is a neighborhood of $g(f(p))$, then $g^{-1}(N)$ is a neighborhood of $f(p)$, and so $f^{-1}(g^{-1}(N)) = (g \circ f)^{-1}(p)$ is a neighborhood of $p$. By definition, $g \circ f$ is continuous at $p$.
\end{proof}
\ \\
More generally, given a function $f: X \to Y$ between topological spaces, and a filter base $\mathcal{B}$ that converges to $p$ in $X$, we say $q$ is a \emph{$\mathcal{B}$-limit of $f$ at $p$} if for all neighborhood $N$ of $q$, there exists some $B \in \mathcal{B}$ such that $f(B) \subseteq N$. We denote $q \in \lim_{\mathcal{B} \to p} f(\mathcal{B})$
\begin{remark}
From \hyperref[topo-cont-point-eq-seq-cont]{Proposition \ref*{topo-cont-point-eq-seq-cont}}, $f$ is continuous at $p$ if and only if $f(p) \in \lim_{\mathcal{B} \to p} f(\mathcal{B})$ for all $\mathcal{B} \to p$.
\end{remark}
\begin{example} \label{topo-sided-lim} \ 
Given $X = Y = \mathbb{R}$, there are several limits used in real analysis
\begin{enumerate}
    \item When $\mathcal{B} = \{ (a, p) : a < p \}$, the $\mathcal{B}$-limit is called \emph{left-sided limit}.
    \\
    We denote such limit as $\lim_{x \to p^-} f(x)$.
    \item When $\mathcal{B} = \{ (p, b) : b > p \}$, the $\mathcal{B}$-limit is called \emph{right-sided limit}.
    \\
    We denote such limit as $\lim_{x \to p^+} f(x)$.
    \item When $\mathcal{B} = \{ (a, b) \setminus \{ p \} : a < p < b \}$, the $\mathcal{B}$-limit is called the \emph{deleted limit} of $f$ (at $p$). If the deleted limit coincide with the value of $f$ at $p$ (i.e. $f(p)$), then we recover the continuity of $f$ at $p$.
\end{enumerate}
\underline{Note:}
\begin{enumerate}
    \item The one-sided limits can be adopted to a more general situation when $X$ is an ordered set, and $Y$ is an arbitrary topological space (see the next section about the induced topology on ordered set).
    \item As for the deleted limit of a function at a point, it works between topological spaces in general. However, when $p$ is an isolated point of $X$, we have $Y = \lim_{\mathcal{B} \to p} f(\mathcal{B})$. So, in most case, we always assume $p$ to be a limit point of $X$.
\end{enumerate}
\end{example}
\begin{proof}
Note that when $p$ is isolated point of $X$, this means that $\{ p \}$ is itself open. Thus, $\mathcal{B} = \{ N \setminus \{ p \} : N \mbox{ is a neighborhood of } p \}$ contains empty set, and so for $f(\mathcal{B})$. Thus, $f(\mathcal{B})$ converges to each point in $Y$.
\end{proof}

\newpage

\section{Order topology}
If $(L, \leq)$ is a linearly (or totally) ordered set, then the order topology on $L$ is generated by the basis consisting of open intervals $(a, b) = \{ x \in L : a < x < b \}$, and open rays $(a, \infty) = \{ x \in L : x > a \}, (-\infty, b) = \{ x \in L : x < b \}$.
\begin{remark}
In fact, the order topology can be generated by just open rays. The open intervals is just to make the collection into a basis.
\end{remark}
\begin{proof}
Since $\bigcap_{i = 1}^n (a_i, \infty) = (\max_{i = 1}^n a_i, \infty) = (a, \infty)$, and $\bigcap_{j = 1}^m (-\infty, b_j) = (-\infty, \min_{j = 1}^m b_j) = (-\infty, b)$, we get
\begin{align*}
    \bigcap_{i = 1}^n (a_i, \infty) \cap \bigcap_{j = 1}^m (-\infty, b_j) = (a, b)
\end{align*}
Furthermore, given $U_1, U_2$ be either open intervals or rays, we consider the following cases
\begin{enumerate}
    \item $U_1 = (a_1, b_1), U_2 = (a_2, \infty)$: then $U_1 \cap U_2 = (\max(a_1, a_2), b_1)$
    \item $U_1 = (a_1, b_1), U_2 = (-\infty, b_2)$: then $U_1 \cap U_2 = (a_1, \min(b_1, b_2))$
    \item $U_1 = (a_1, b_1), U_2 = (a_2, b_2)$: then $U_1 \cap U_2 = (\max(a_1, a_2), \min(b_1, b_2))$
    \item $U_1 = (a_1, \infty), U_2 = (a_2, \infty)$: then $U_1 \cap U_2 = (\max(a_1, a_2), \infty)$
    \item $U_1 = (a_1, \infty), U_2 = (-\infty, b_2)$: then $U_1 \cap U_2 = (a_1, b_2)$
    \item $U_1 = (-\infty, b_1), U_2 = (-\infty, b_2)$: then $U_1 \cap U_2 = (-\infty \min(b_1, b_2))$
\end{enumerate}
\end{proof}
\begin{remark}
With the order topology, the closed intervals $[a, b]$ and closed rays $[a, \infty)$ and $(-\infty, b]$, as the name suggests, are closed.
\end{remark}
\begin{remark}
The concept of eventuality and stationary for subsets of $L$ is defined based upon the \textit{eventuality filter base} on $L$.
\end{remark}
\begin{proposition} \ 
Suppose the order on $X$ is dense
\begin{enumerate}
    \item $X$ is dense-in-itself, i.e. every point in $X$ is a limit point.
    \item The closure of the basic open sets are basic closed sets
    \begin{enumerate}
        \item $\operatorname{cl}(p, q) = [p, q]$.
        \item $\operatorname{cl}(p, \infty) = [p, \infty)$.
        \item $\operatorname{cl}(-\infty, q) = (-\infty, q]$.
    \end{enumerate}
    As a result, $\operatorname{cl}(p, q] = \operatorname{cl}[p, q) = [p, q]$.
    \item The interior of basic closed sets are basic open sets
    \begin{enumerate}
        \item $\operatorname{int}[p, q] = (p, q)$, unless either $p = \min X$ or $q = \max X$.
        \item $\operatorname{int}[p, \infty) = (p, \infty)$ unless $p = \min X$.
        \item $\operatorname{int}(-\infty, q] = (-\infty, q)$ unless $q = \max X$.
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} for each $p$ and neighborhood $N$ around $p$, we show that there is some point in $N$ other than $p$. By definition of order topology, either
\begin{enumerate}
    \item $p \in (a, b) \subseteq N$ for some $a, b \in X$: there exists some $q \in (a, p)$ (the ordering on $X$ is dense), so $N$ contains at least one point different from $p$.
    \item $p \in (a, \infty) \subseteq N$ for some $a \in X$: there exists some $q \in (a, p)$, so $N$ contains at least one point different from $p$.
    \item $p \in (-\infty, b) \subseteq N$ for some $b \in X$: there exists some $q \in (p, b)$, so $N$ contains at least one point different from $p$.
\end{enumerate}
\underline{Part 2:} since $[p, q] = X \setminus [(-\infty, p) \cup (q, \infty)]$ is closed, $\operatorname{cl}(p, q) \subseteq [p, q]$. If $N$ is a neighborhood of $p$, either
\begin{enumerate}
    \item $p \in (a, b) \subseteq N$ for some $a, b \in X$: there exists some $r \in (p, b) \subseteq (p, q)$, so $N \cap (p, q)$ is not empty.
    \item $p \in (-\infty, b) \subseteq N$ for some $b \in X$: there exists some $r \in (p, b) \subseteq (p, q)$, so $N \cap (p, q)$ is not empty.
    \item $p \in (a, \infty) \subseteq N$ for some $a \in X$: then $(p, q) \subseteq (a, \infty)$, and so $N \cap (p, q)$ is not empty.
\end{enumerate}
In any case $N \cap (p, q)$ is not empty, so $p \in \operatorname{cl}(p, q)$. Similarly, $q \in \operatorname{cl}(p, q)$. We conclude $\operatorname{cl}(p, q) = [p, q]$. The other intervals follows analogously.
\\
\underline{Part 3:} since $(p, q)$ is open, $\operatorname{int}[p, q] \supseteq (p, q)$. If $N$ is a neighborhood of $p$, then either
\begin{enumerate}
    \item $p \in (a, b) \subseteq N$ for some $a, b \in X$: then there exists $r \in (a, p)$. Thus, $N$ is not a subset of $[p, q]$ since it contains $r$.
    \item $p \in (a, \infty) \subseteq N$ for some $a \in X$: then there exists $r \in (a, p)$. Thus, $N$ is not a subset of $[p, q]$ since it contains $r$.
    \item $p \in (-\infty, b) \subseteq N$ for some $b \in X$: if there does not exist $r < p$, then $p = \min L$ (since $X$ is totally ordered), a contradiction. Thus, $N$ is not a subset of $[p, q]$ since it contains $r$.
\end{enumerate}
In any case, $N$ cannot be a subset of $[p, q]$, so $p$ cannot be an interior point of $[p, q]$. Similarly, $q$ cannot be an interior point of $[p, q]$. We conclude $\operatorname{int}[p, q] = (p, q)$. The other intervals follows analogously.
\end{proof}
\begin{theorem}[Monotone Convergence Theorem] \label{topo-ord-mono-conv}
Let $X$ be a Dedekind-complete ordered set. If $x: A \to X$ is a bounded above, increasing net, i.e.
\begin{enumerate}
    \item $x_\alpha \leq x_\beta$ whenever $\alpha \leq \beta$.
    \item There exists some $p \in X$ such that $x_\alpha \leq p$ for all $\alpha \in A$.
\end{enumerate}
Then it converges to $\sup_{\alpha \in A} x_\alpha$. Similarly, if $x: A \to X$ is a bounded below, decreasing net, then it converges to $\inf_{\alpha \in A} x_\alpha$.
\end{theorem}
\begin{proof}
We only show the supremum version, the infimum version is similar. Since $(x_\alpha)_{\alpha \in A}$ is bounded above, $p = \sup_{\alpha \in A} x_\alpha$ exists. For each neighborhood $N$ of $p$, there either exists
\begin{enumerate}
    \item $u, v \in X$ such that $p \in (u, v) \subseteq N$: by definition of supremum, there exist some $\eta \in A$ such that $u < x_\eta \leq p$. Since $(x_\alpha)_{\alpha \in A}$ is increasing, we have $u < x_\eta \leq x_\alpha \leq p$ for all $\alpha \geq \eta$. In particular, $x_\alpha \in (u, v) \subseteq N$ for all $\alpha \geq \eta$.
    \item $u \in X$ such that $p \in (u, \infty) \subseteq N$: similarly, to 1st case, there exists some $\eta \in A$ such that $x_\alpha \in N$ for all $\alpha \geq \eta$.
    \item $v \in X$ such that $p \in (-\infty, v) \subseteq N$: Since $x_\alpha \leq p$ by definition, we have $x_\alpha \in N$ for all $\alpha \in A$. In particular, pick some $\eta \in A$ and we get $x_\alpha \in N$ for all $\alpha \geq \eta$.
\end{enumerate}
In any case, there always some $\eta \in A$ such that $x_\alpha \in N$ for all $\alpha \geq \eta$.
\end{proof}
\begin{proposition}[Monotonicity] \label{topo-ord-dom-monic}
Let $(x_\alpha)_{\alpha \in A}$ converges to $p$, $(y_\alpha)_{\alpha \in A}$ converges to $q$. If $(x_\alpha)_{\alpha \in A}$ is eventually dominated by $(y_\alpha)_{\alpha \in A}$ (i.e. there exists some $\lambda \in A$ such that $x_\alpha \leq y_\alpha$ for all $\alpha \geq \lambda$), then $p \leq q$.
\end{proposition}
\begin{proof}
Suppose otherwise, that $p > q$. Then $(-\infty, p)$ is a neighborhood of $q$, so there exists some $\gamma \in A$ such that $y_\alpha < p$ for all $\alpha \geq \gamma$. We also have $(q, \infty)$ is a neighborhood of $p$, so there exists another $\xi \in A$ such that $x_\alpha > q$ for all $\alpha \geq \xi$. Since $A$ is directed, there exists $\eta \in A$ greater than or equal to $\gamma$, $\xi$, and $\lambda$. Therefore, $q < x_\alpha \leq y_\alpha < p$ for all $\alpha \geq \eta$. In particular, $(q, p)$ is not empty, so let $r \in (q, p)$. Then $(-\infty, r)$ is a neighborhood of $q$, so there exists some $\nu \in A$ such that $y_\alpha \in (-\infty, r)$ for all $\alpha \geq \nu$. Vice versa, $(r, \infty)$ is a neighborhood of $p$, so there exists some $\mu \in A$ such that $x_\alpha \in (r, \infty)$ for all $\alpha \geq \mu$. Let $\lambda \in A$ be an upper bound of $\eta, \mu, \nu$, we then have $x_\alpha > r$ and $x_\alpha \leq y_\alpha < r$ for all $\alpha \geq \lambda$, a contradiction.
\end{proof}
\begin{theorem}[Squeeze theorem]
Let $A$ be a directed set, and $x, y, z: A \to L$ be nets on $L$ such that $x_\alpha \leq y_\alpha \leq z_\alpha$ for all $\alpha \in A$. If $x_\alpha \to p$ and $z_\alpha \to p$, then $y_\alpha \to p$.
\end{theorem}
\begin{proof}
Given any basic open neighborhood $N$ of $p$ (i.e. $N$ is either an interval, or a ray), there must exists $\eta_x, \eta_z \in A$ such that $x_\alpha \in N$ for all $\alpha \geq \eta_x$ and $z_\alpha \in N$ for all $\alpha \geq \eta_z$. Since $A$ is directed, there exists some $\eta \in A$ such that $\eta \geq \eta_x, \eta_z$. Hence, $x_\alpha, z_\alpha \in N$ for all $\alpha \geq \eta$. However, since $N$ is basic (and in particular, convex), $[x_\alpha, z_\alpha] \subseteq N$. Therefore, we also have $y_\alpha \in N$ for all $\alpha \geq \eta$. Since this holds for any basic open neighborhood of $p$, and the basic open sets generate the topology, we conclude that $y_\alpha \to p$.
\end{proof}
\begin{proposition}
Order-isomorphism is a homeomorphism between order topologies.
\end{proposition}
\begin{proof}
Suppose $f: (P, \leq_P) \to (Q, \leq_Q)$ is an order-isomorphism. In particular, $f^{-1}$ is monotone, so $f^{-1}((b_1, b_2)) = (f^{-1}(b_1), f^{-1}(b_2))$. Similarly, $f^{-1}(b, \infty) = (f^{-1}(b), \infty)$ and $f^{-1}(-\infty, b) = (-\infty, f^{-1}(b))$. We just test on all basic open sets whose inverse images are also open, so $f$ must be continuous. Vice versa, we can show analogously that $f^{-1}$ is continuous. Therefore, $f$ is a homeomorphism.
\end{proof}
\ \\
\begin{proposition} \ 
\begin{enumerate}
    \item If $X$ is not bounded above, any dense subset is cofinal.
    \item Dually, if $X$ is not bounded below, any dense subset of coinitial.
\end{enumerate}
 As a result, $\operatorname{cf} X \leq d(X)$.
\end{proposition}
\begin{proof}
Let $S$ be a dense set. If it is not cofinal, then there exists some $p \in X$ such that $s \leq p$ for all $s \in S$. Thus, $\operatorname{cl}(S) \subseteq (-\infty, p]$. But since $X$ is not bounded above, there exists some $q > p$, so $q \notin \operatorname{cl}(S)$, a contradiction. The dual version is proved similarly.
\end{proof}
\begin{theorem}
Let $L, X$ be totally ordered sets, with $L$ unbounded (so the cofinality of $L$ is at least $\omega$). If $(x_i)_{i \in L}$ is an increasing sequence in $X$, then either
\begin{enumerate}
    \item $(x_i)_{i \in L}$ is eventually constant, i.e. there exists some $p \in X$ and $k \in L$ such that $x_i = p$ for all $i \geq k$.
    \item There exists a \textit{strictly} increasing, cofinal subsequence $(y_\alpha)_{\alpha < \kappa}$ (where $\kappa = \operatorname{cf} L$). Note, however, that such subsequence may not be necessarily unbounded in $X$.
\end{enumerate}
\end{theorem}
\begin{proof}
Denote $S = \{ x_i : i \in L \} \subseteq X$. For each $s \in S$, let $j_s$ to be some element in $L$ such that $x_{j_s} = s$. We show that $(j_s)_{s \in S}$ is strictly increasing. By definition, we know that $j_s \neq j_t$ whenever $s \neq t$. If $s < t$ yet $j_s > j_t$, then, by monotonicity of $(x_i)_{i \in L}$, $s = x_{j_s} \geq x_{j_t} = t$, a contradiction.
\\
\\
Now, if $(j_s)_{s \in S}$ is bounded, then let $k$ be an upper bound of it. Denote $p = x_k$, then $p \geq x_{j_s} = s$ for all $s \in S$ by monotonicity. By definition, $p = \max S$, and so, for all $i \geq k$, we get $x_i = p$ by monotonicity.
\\
\\
Otherwise, $(j_s)_{s \in S}$ is unbounded in $L$, so there exists a cofinal subsequence $(\mu_\alpha)_{\alpha < \kappa}$ of $(j_s)_{s \in S}$, where $\kappa$ is the cofinality of $L$. Since an increasing function preserves cofinality, $(x_{\mu_\alpha})_{\alpha < \kappa}$ is a cofinal subsequence of $(x_{j_s})_{s \in S}$. By definition of $j_s$, $(x_{\mu_\alpha})_{\alpha < \kappa}$ is a strictly increasing, cofinal subsequence of $(x_i)_{i \in L}$.
\end{proof}
\underline{Proof Note:} this uses axiom of choice to pick out a representative $x_\eta = s$ for each $s \in S$ (and also to pick out a cofinal subsequence of $(j_s)_{s \in S}$). However, if $L$ is well-ordered, then there is no need for choice.
\begin{corollary}
If $\operatorname{cf} L > \operatorname{cf} S$ for all $S \subseteq X$, then any increasing function $f: L \to X$ is eventually constant.
\end{corollary}
\begin{proof}
If it is not eventually constant, then there exists a strictly increasing, cofinal subsequence $(f(i_\alpha))_{\alpha < \kappa}$ (with $\kappa = \operatorname{cf} L$) of $(f(i))_{i \in L}$. But $\kappa > \lambda = \operatorname{cf} f(L)$, so there also exists a strictly increasing, cofinal subsequence $(f(j_\beta))_{\beta < \lambda}$ of $(f(i_\alpha))_{\alpha < \kappa}$. Hence, $(f(j_\beta))_{\beta < \lambda}$ is a strictly increasing, cofinal subsequence of $(f(i))_{i \in L}$.
\\
\\
However, $(j_\beta)_{\beta < \lambda}$ cannot be cofinal in $L$ (since it would contradict the minimality), so there must be an upper bound $k$ of it. Since $f$ is increasing, $f(k) \geq f(j_\beta)$ for all $\beta < \lambda$. But $(f(j_\beta))_{\beta < \lambda}$ is cofinal in $f(L)$, so for each $i \in L$, there exists some $\beta < \lambda$, such that $f(i) \leq f(j_\beta) \leq f(k)$. This implies that $f$ is eventually constant, a contradiction.
\end{proof}

\subsection{Discrete ordering}
Given $a < b$ in $X$, we say $a$ is the \emph{predecessor} of $b$ (or $b$ is the {successor} of $a$) if the open interval $(a, b)$ is empty. We then denote $a <^* b$.
\begin{remark} \label{ord-pred-succ-unique}
The predecessor of $p \in X$, if exists, is unique. Similarly, the successor of $p$, if exists, is unique.
\end{remark}
\begin{proof}
Suppose $a, a' <^* p$ (in particular, $a, a' < p$), then $(a, p) = (a', p) = \varnothing$. WLOG, we can assume that $a \leq a'$. If $a < a'$, then $a' \in (a, p)$, a contradiction to $(a, x) = \varnothing$. Therefore, $a = a'$. By similar argument, we can show that the successor of $x$, if exists, is unique.
\end{proof}
\begin{lemma} \label{ord-z-mod}
Let $X$ be totally ordered. If we define $\sim$ as the relation such that $a \sim b$ if there is only finitely many points in $X$ between $a$ and $b$, then
\begin{enumerate}
    \item $\sim$ is an equivalence relation.
    \item $X / \sim$ is totally ordered by: $C < D$ if and only if $x < y$ for all $x \in C, y \in D$.
    \item $X$ is the ordered sum of these equivalence classes (the index set is, of course, $X / \sim$).
\end{enumerate}
Such relation $\sim$ is called the \emph{$\mathbb{Z}$-modulo} relation (not to be confused with $\mathbb{Z}$-module, which refers to abelian group).
\end{lemma}
\begin{proof} \ \\
\underline{Part 1:}
\begin{enumerate}[label=(\alph*)]
    \item Since $(a, a)$ is empty, $a \sim a$.
    \item If $a \sim b$ then $b \sim a$, since we do not need to know whether $a \leq b$ or $b \geq a$, we just need to count the points in between $a$ and $b$ (so it will be $|(a, b)|$ if $a \leq b$, and $|(b, a)|$ if $a \geq b$).
    \item Suppose $a \sim b$ and $b \sim c$: consider the following case
    \begin{enumerate}[label = \roman*.]
        \item $a \leq b \leq c$: then $(a, c) = (a, b) \cup \{ b \} \cup (b, c)$ is finite (since it is a finite union of finite sets).
        \item $a \leq c \leq b$: then $(a, c) = (a, b) \setminus [(c, b) \cup \{ c \}]$ is finite (since it is a subset of a finite set).
        \item $b \leq a \leq c$: then $(a, c) = (b, c) \setminus [(b, a) \cup \{ a \}]$ is finite.
        \item $b \leq c \leq a$: then $(c, a) = (b, a) \setminus [(b, c) \cup \{ c \}]$ is finite.
        \item $c \leq b \leq a$: then $(c, a) = (c, b) \cup \{ b \} \cup (b, a)$ is finite.
        \item $c \leq a \leq b$: then $(c, a) = (c, b) \setminus [(a, b) \cup \{ a \}]$ is finite.
    \end{enumerate}
    Therefore, $a \sim c$.
\end{enumerate}
\underline{Part 2:}
\begin{enumerate}[label = (\alph*)]
    \item Irreflexivity: $C \not< C$ since $x \not< x$ for any $x \in C$.
    \item Transitivity: if $C < D$ and $D < E$, then $x < y < z$ for all $x \in C, y \in D, z \in E$. By transitivity of the order on $X$, $C < E$.
    \item Totality: given $a \in C$ and $b \in D$, then either $a < b$ or $b > a$ since we assume $C \neq D$ (and so $C \cap D = \varnothing$). WLOG, let's say $a < b$, we will show $C < D$. Suppose otherwise, that $x > y$ for some $x \in C$ and $y \in D$, we consider the following cases
    \begin{enumerate}[label = \roman*.]
        \item $x \leq a$: then $b > a \geq x > y$. By definition, $(b, y)$ contains finitely many points, so $(b, a)$ also contains finitely many point, so $b \sim a$, or equivalently, $C = D$, a contradiction.
        \item $x > a$, $y \geq b$: then $x > y \geq b > a$. By the same argument as in previous case, we derive a contradiction.
        \item $x > a$, $y < b$: note that both $(a, x)$ and $(y, b)$ are finite sets such that $(a, x) \cup (y, b) = (a, b)$ (since $x > y$), so $(a, b)$ is also finite, contradicting $a \not\sim b$.
    \end{enumerate}
\end{enumerate}
\underline{Part 3:} the ordered sum of $C \in X/\sim$ is $\sum_{C \in X / \sim} C = \{ (x, C) : x \in C \in X / \sim \}$ (which is a subset of $X \times (X / \sim)$). The ordering is $(x, C) < (y, D)$ if and only if either $C = D$ and $x < y$, or $C < D$. However, $C < D$ implies that $x < y$ by part (2), so the ordering is simplified to $(x, C) < (y, D)$ iff $x < y$. The isomorphism from $X$ to $\sum_{C \in X / \sim} C$ is $f(x) = (x, [x])$, and its inverse is $g(x, C) = x$. Each of them is order-preserving since $x < y$ if and only if $(x, [x]) < (y, [y])$ by definition.
\end{proof}
\begin{lemma} \label{ord-pred-succ-disc}
If $X$ is discrete under the order topology, and $p$ is a point in $X$, then \textit{exactly} one of the following holds (unless $X$ is a singleton)
\begin{enumerate}
    \item $p$ is the minimum of $X$, and the successor of $p$ exists.
    \item The predecessor and successor of $X$ exist.
    \item $p$ is the maximum of $X$, and the predecessor of $p$ exists.
\end{enumerate}
\end{lemma}
\begin{proof}
Every $p \in X$ is isolated, so there exists a neighborhood $N$ of $p$ such that $N \cap X = \{ p \} = N$. There also exists some $a, b \in X$ such that either
\begin{enumerate}
    \item $p \in (a, b) \subseteq N$: then we have $(a, b) = \{ p \}$. In particular, since $(a, b)$ is the disjoint union of $(a, p)$, $\{ p \}$, $(p, b)$, $(a, p)$ and $(p, b)$ must be empty. In other words, $a <^* p$ and $b >^* p$.
    \item $p \in (a, \infty) \subseteq N$: then we have $(a, \infty) = \{ p \}$. Again, $(a, \infty)$ is the disjoint union of $(a, p)$, $\{ p \}$, and $(p, \infty)$, we get $(a, p) = \varnothing$ (i.e. $a <^* p$) and $(p, \infty) = \varnothing$ (i.e. $p = \max X$).
    \item $p \in (-\infty, b) \subseteq N$: by similar argument in case 2, we get $p = \min X$ and $b >^* p$.
\end{enumerate}
The minimum cannot have a predecessor (an element before the minimum), and the maximum cannot have a successor. This excludes points that either satisfies (1) and (2), or (2) and (3). If there exists a point that satisfies both (1) and (3), then indeed $X$ is just a singleton (otherwise the maximum and the minimum have to be distinct).
\end{proof}
\begin{theorem}[Classification of discrete order]
If $X$ is discrete under order topology, then it is (or rather, is isomorphic to) either
\begin{enumerate}
    \item A finite set.
    \item $I \times \mathbb{Z}$ (with lexicographical ordering).
    \item A sum of $\mathbb{Z}_{\geq 0}$ and $I \times \mathbb{Z}$.
    \item A sum of $I \times \mathbb{Z}$ and $\mathbb{Z}_{\leq 0}$.
    \item A sum of $\mathbb{Z}_{\geq 0}$, $I \times \mathbb{Z}$, and $\mathbb{Z}_{\leq 0}$.
\end{enumerate}
Furthermore
\begin{enumerate}
    \item The converse also holds, i.e. the order topology on each of these sets is discrete.
    \item These ordered sets are pairwise non-isomorphic, except only the following:
    \begin{enumerate}
        \item $I \times \mathbb{Z} \cong J \times \mathbb{Z}$ iff $I \cong J$.
        \item $\mathbb{Z}_{\geq 0} + I \times \mathbb{Z} \cong \mathbb{Z}_{\geq 0} + J \times \mathbb{Z}$ iff $I \cong J$.
        \item $I \times \mathbb{Z} + \mathbb{Z}_{\leq 0} \cong J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$ iff $I \cong J$.
        \item $\mathbb{Z}_{\geq 0} + I \times \mathbb{Z} + \mathbb{Z}_{\leq 0} \cong \mathbb{Z}_{\geq 0} + J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$ iff $I \cong J$.
    \end{enumerate}
\end{enumerate}
\end{theorem}
\begin{proof}
To reduce the cases that we need to consider, we can assume that $X$ is infinite. With respect to the $\mathbb{Z}$-modulo relation in \hyperref[ord-z-mod]{Lemma \ref*{ord-z-mod}}, we shall prove each $C \in X / \sim$ is isomorphic to either $\mathbb{Z}, \mathbb{Z}_{\geq 0}, \mathbb{Z}_{\leq 0}$. Note that
\begin{enumerate}
    \item If $\min C$ exists: then there is no predecessor of $\min C$ in $X$ (that will contradicts the minimality). According to \hyperref[ord-pred-succ-disc]{Lemma \ref*{ord-pred-succ-disc}}, $\min C$ has to be $\min X$.
    \item If $\max C$ exists: then there is no successor of $\max C$ in $X$. Thus, $\max C$ has to be $\max X$.
\end{enumerate}
So if both $\min C$ and $\max C$ exist, then $C = [\min C, \max C] = [\min X, \max X] = X$ and $C$ is finite. This contradicts $X$ being infinite.
\\
\\
Therefore, an equivalence class $C$ either
\begin{enumerate}
    \item Has $\min C$, but not $\max C$: let $\mu: C \to \mathbb{Z}_{\geq 0}$ which sends each $x \in C$ to $|[\min C, x)|$ - the number of elements between $\min C$ inclusively, and $x$ exclusively.
    \begin{enumerate}
        \item $\mu$ is surjective: if $x \in C$ does not have a successor, then $x = \max X$, which contradicts $\max C$ does not exist (\hyperref[ord-pred-succ-disc]{Lemma \ref*{ord-pred-succ-disc}}). Suppose $x^+$ is the successor of $x$, then $[\min C, x^+) = [\min C, x) \cup \{ x \}$, and so $\mu(x^+) = |[\min C, x)| + |\{ x \}| = \mu(x) + 1$. By induction
        \begin{enumerate}
            \item The base step $n = 0$: $\mu(\min C) = |[\min C, \min C)| = 0$.
            \item The inductive step: suppose $\mu(x) = n$ for some $x \in C$, then $\mu(x^+) = \mu(x) + 1 = n + 1$.
        \end{enumerate}
        we conclude $\mu$ is surjective.
        \item Next, we will show that $\mu$ is injective: suppose $\mu(x) = \mu(y)$ but $x < y$. Then $x^+ \leq y$ since there is no point in $(x, x^+)$ by definition of successor. Thus, $[\min C, y)$ contains $[\min C, x^+)$ and so $\mu(y) \geq \mu(x^+) > \mu(x)$, a contradiction.
        \item Finally, $\mu$ is order-preserving (thus, an order-isomorphism): this is in the proof of injection.
    \end{enumerate}
    We conclude $C$ is isomorphic to $\mathbb{Z}_{\geq 0}$.
    \item Has $\max C$, but $\min C$: similar argument, but use $\mu: C \to \mathbb{Z}_{\leq 0}$ that maps $x$ to $-|(x, \max C]|$ (notice the minus sign) as the isomorphism between $C$ and $\mathbb{Z}_{\leq 0}$.
    \item Has neither $\min C$ nor $\max C$: again, according to \hyperref[ord-pred-succ-disc]{Lemma \ref*{ord-pred-succ-disc}}, each $x \in C$ has predecessor and successor. Fix some $p \in C$, and let $\mu: C \to \mathbb{Z}$ send each $x \in C$ to either $|[p, x)|$ if $x \geq p$, or $-|(x, p]|$ if $x \leq p$. Follow the proofs of 1st and 2nd cases, we can show that
    \begin{enumerate}
        \item $C_{\leq p} = \{ x \in C : x \leq p \}$ is order-isomorphic to $\mathbb{Z}_{\leq 0}$: just restrict $\mu$ to $C_{\leq p}$.
        \item $C_{\geq p} = \{ x \in C : x \geq p \}$ is order-isomorphic to $\mathbb{Z}_{\geq 0}$: just restrict $\mu$ to $C_{\geq p}$.
    \end{enumerate}
    Since $\mu(p)$ is always $0$ regardless of either definition (as $(p, p] = [p, p) = \varnothing$), we can patch $C_{\leq p}$ and $C_{\geq p}$ into $C$ to show that $\mu$ is an order-isomorphism between $C$ and $\mathbb{Z}$.
\end{enumerate}
\ \\
*Finally, we show that $X$ is order-isomorphic to either type 2, 3, 4, or 5. Based on whether $X$ is bounded above or below (or both, or neither), we divide into 4 cases, .
\begin{enumerate}
    \item Neither $\min X$ nor $\max X$ exists: each $C$ is then cannot have maximum or minimum. Therefore, each equivalence class must be isomorphic to $\mathbb{Z}$, and so
    \begin{align*}
        X = \sum_{C \in X / \sim} C \cong (X / \sim) \times \mathbb{Z}
    \end{align*}
    \item $\min X$ exists, but not $\max X$: there is only one (equivalence) class $C_i^*$ with minimum in it, and no class with maximum in it. $C_i^*$ must be less than any other class since $\min X \in C_i^*$. However, $C_i^*$ is isomorphic to $\mathbb{Z}_{\geq 0}$, while other classes are isomorphic to $\mathbb{Z}$. Hence, 
    \begin{align*}
        X = C_i^* + \sum_{\substack{C \in X / \sim \\ C \neq C_i^*}} C \cong \mathbb{Z}_{\geq 0} + [(X / \sim) \setminus \{ C_i^* \}] \times \mathbb{Z}
    \end{align*}
    \item $\max X$ exists, but not $\min X$: similar to the 2nd case, if we denote $C_f^*$ to be the (only) equivalence class with maximum, then
    \begin{align*}
        X = \sum_{\substack{C \in X / \sim \\ C \neq C_i^*}} C + C_f^* \cong [(X / \sim) \setminus \{ C_f^* \}] \times \mathbb{Z} + \mathbb{Z}_{\leq 0}
    \end{align*}
    \item Both $\max X$ and $\min X$ exist: then there is only class $C_i^*$ with minimum, $C_f^*$ with maximum, and every class in between can neither have minimum nor maximum. Thus,
    \begin{align*}
        X = C_i^* + \sum_{\substack{C \in X / \sim \\ C \neq C_i^*, C_f^*}} C + C_f^* \cong \mathbb{Z}_{\geq 0} + [(X / \sim) \setminus \{ C_i^*, C_f^* \}] \times \mathbb{Z} + \mathbb{Z}_{\leq 0}
    \end{align*}
\end{enumerate}
\ \\
*Converse:
\begin{enumerate}
    \item If $X$ is finite: after relabeling, we can assume that $X = \{ 1, 2, 3, \hdots, n \}$ with natural ordering. Thus, $\{ 1 \} = (-\infty, 2)$, $\{ n \} = (n - 1, \infty)$, and $\{ i \} = (i-1, i+1)$ are open.
    \item If $X = I \times \mathbb{Z}$: then for any $(i, n) \in I \times \mathbb{Z}$, then $(i, n)$ is sandwiched between $(i, n-1)$ and $(i, n+1)$ so $\{ (i, n) \}$ is open.
    \item If $X = \mathbb{Z}_{\geq 0} + I \times \mathbb{Z}$, then each point in $X$ is either in $\mathbb{Z}_{\geq 0}$ or in $I \times \mathbb{Z}$. The first case is just $\mathbb{N}$ with order topology, and it is discrete. The second case is proven above.
    \item Similar argument for the remaining case.
\end{enumerate}
\ \\
*Uniqueness:
\begin{enumerate}
    \item A finite (totally) ordered set is determined uniquely by its cardinality, and it cannot be isomorphic to the other sets in the list since they are all infinite.
    \item If $f: I \times \mathbb{Z} \to J \times \mathbb{Z}$ is an order-isomorphism: observe that $f$ has to map $\{ i \} \times \mathbb{Z}$ to some $\{ j \} \times \mathbb{Z}$. Indeed, for each $n \in \mathbb{Z}$, if $f(i, n + 1)$ is not a successor of $f(i, n)$, then there is some $(j, m)$ in between them. However, $f^{-1}$ is also order-preserving, so $f^{-1}(j, m)$ has to be between $(i, n)$ and $(i, n+1)$, which there is none. In other words, $f(i, n+1)$ has to be the successor of $f(i, n)$ for all $i \in I$ and $n \in \mathbb{Z}$. Simply put, $f(i, n+1) = (j, m+1)$ whenever $f(i, n) = (j, m)$. Fix $f(i, 0) = (j, m)$, then by induction, one can show that $f(i, n) = (j, m + n)$ and $f(i, -n) = (j, m - n)$ for all $n \in \mathbb{N}$. Hence, $f(i, n) = (j, m + n)$ for all $n \in \mathbb{Z}$. This shows that $f(\{ i \} \times \mathbb{Z}) = \{ j \} \times \mathbb{Z}$.
    \\
    \\
    Define $\varphi: I \to J$ which maps $i$ to $j$ such that $f(\{ i \} \times \mathbb{Z}) = \{ j \} \times \mathbb{Z}$. This map is
    \begin{enumerate}
        \item Well-defined: if $\{ j_1 \} \times \mathbb{Z} = \{ j_2 \} \times \mathbb{Z}$, then $(j_1, m_1) = (j_2, m_2)$ for some $m_1, m_2 \in \mathbb{Z}$, and so $j_1 = j_2$.
        \item Injective: if $\varphi(i_1) = \varphi(i_2) = j$, then $f^{-1}(j, 0) \in \{ i_1 \} \times \mathbb{Z}$ and $f^{-1}(j, 0) \in \{ i_2 \} \times \mathbb{Z}$. In particular, $f^{-1}(j, 0) = (i_1, n_1) = (i_2, n_2)$ for some $n_1, n_2 \in \mathbb{Z}$. Thus, $i_1 = i_2$.
        \item Surjective: given $j \in J$, note the symmetry between $f$ and $f^{-1}$, we must have $f^{-1}(j \times \mathbb{Z}) = \{ i \} \times \mathbb{Z}$ for some $i \in I$. We then get $j \times \mathbb{Z} = f(\{ i \} \times \mathbb{Z})$ and $\varphi(i) = j$.
        \item Order-preserving: if $i_1 < i_2$, let $\varphi(i_1) = j_1, \varphi(i_2) = j_2$. In particular, $f(i_1, 0) = (j_1, m_1)$ and $f(i_2, 0) = (j_2, m_2)$ for some $m_1, m_2 \in \mathbb{Z}$. Since $i_1 < i_2$, $(i_1, 0) < (i_2, 0)$, and so $(j_1, m_1) < (j_2, m_2)$. But $j_1 \neq j_2$ because $\varphi$ is injective, so we must have $j_1 < j_2$ (due to lexicorgraphical ordering).
    \end{enumerate}
    Therefore, $I$ and $J$ are order-isomorphic. In other words, $I \times \mathbb{Z}$ is not isomorphic to $J \times \mathbb{Z}$ whenever $I$ is not isomorphic to $J$.
    \item Suppose $f: \mathbb{Z}_{\geq 0} + I \times \mathbb{Z} \to \mathbb{Z}_{\geq 0} + J \times \mathbb{Z}$ is an isomorphism: we will use $n \in \mathbb{Z}$ to denote the elements of initial segment $\mathbb{Z}_{\geq 0}$, and $(i, n)$ (or $(j, m)$ to denote the elements of $I \times \mathbb{Z}$ (or $J \times \mathbb{Z}$).
    \\
    \\
    Since $0$ is the minimum of $\mathbb{Z}_{\geq 0} + I \times \mathbb{Z}$, $f(0)$ has to be the minimum of $\mathbb{Z}_{\geq 0} + J \times \mathbb{Z}$. Otherwise, if $a < f(0)$ for some $a \in \mathbb{Z}_{\geq 0} + J \times \mathbb{Z}$, then $f^{-1}(a) < 0$, a contradiction. With the same successor argument as before, we can show by induction that $f(n) = n$ for all $n \in \mathbb{Z}_{\geq 0}$. Hence, by cutting out the initial segment, we obtain an isomorphism between $I \times \mathbb{Z}$ and $J \times \mathbb{Z}$. Therefore, $I$ is isomorphic to $J$.
    \item Similarly, we can show that
    \begin{enumerate}
        \item If $I \times \mathbb{Z} + \mathbb{Z}_{\leq 0} \cong J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$, then $I \cong J$.
        \item If $\mathbb{Z}_{\geq 0} + I \times \mathbb{Z} + \mathbb{Z}_{\leq 0} \cong \mathbb{Z}_{\geq 0} + J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$, then $I \cong J$.
    \end{enumerate}
     by first prove the initial segments are isomorphic and final segments are isomorphic, then cut out those to obtain an isomorphism of $I \times \mathbb{Z}$ and $J \times \mathbb{Z}$.
    \item Suppose $f: I \times \mathbb{Z} \to \mathbb{Z}_{\geq 0} + J \times \mathbb{Z}$ is an isomorphism. Then $f^{-1}(0) = (i, n)$ has to be the minimum of $I \times \mathbb{Z}$, which is not since $(i, n - 1) < (i, n)$. Similar argument for
    \begin{enumerate}
        \item $f: I \times \mathbb{Z} \to J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$.
        \item $f: I \times \mathbb{Z} \to \mathbb{Z}_{\geq 0} + J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$.
        \item $f: \mathbb{Z}_{\geq 0} + I \times \mathbb{Z} \to J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$.
        \item $f: \mathbb{Z}_{\geq 0} + I \times \mathbb{Z} \to \mathbb{Z}_{\geq 0} + J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$.
        \item $f:I \times \mathbb{Z} + \mathbb{Z}_{\leq 0} \to \mathbb{Z}_{\geq 0} + J \times \mathbb{Z} + \mathbb{Z}_{\leq 0}$.
    \end{enumerate}
    by looking at minimum/maximum element.
\end{enumerate}
\end{proof}
\underline{Note:} some author may use $\mathbb{N}$ instead of $\mathbb{Z}_{\geq 0}$ and $\mathbb{N}^*$ (the reverse order of $\mathbb{N}$) instead of $\mathbb{Z}_{\leq 0}$.

\subsection{One-sided limit}
Let $f: X \to Y$ be a function from a (totally) ordered set $X$ to a topological space $Y$. Suppose further, for the sake of convenience, that $p$ is neither the minimum nor the maximum of $X$. Recall from \hyperref[topo-sided-lim]{Example \ref*{topo-sided-lim}} that
\begin{enumerate}
    \item $q$ is a left-sided limit of $f$ at $p$, if for all neighborhood $N$ of $q$, there exists some $a < p$ such that $f(x) \in N$ for all $a < x < p$.
    \item $q$ is a right-sided limit of $f$ at $p$, if for all neighborhood $N$ of $q$, there exists some $b > p$ such that $f(x) \in N$ for all $p < x < b$.
    \item $q$ is a limit of $f$ at $p$, if for a neighborhood $N$ of $f(p)$, there exists some $a < p < b$ such that $f(x) \in N$ for all $a < x < b$, $x \neq p$.
    \\
    \\
    Note that this definition is the same one as in \hyperref[topo-sided-lim]{Example \ref*{topo-sided-lim}} because of
    \begin{enumerate}
        \item The open intervals and open rays form the basis of $X$.
        \item $p$ is neither the maximum nor the maximum of $X$, so there is always some open interval lies inside an open ray.
    \end{enumerate}
\end{enumerate}
\begin{proposition}[Existence of limit]
$q$ is a limit of $f$ at $p$ if and only if it is a left-sided and a right-sided limit at $p$.
\end{proposition}
\begin{proof}
The forward direction is straight from definition. So suppose $q$ is the left-sided and right-sided limit of $f$ at $p$. Then for all neighborhood $N$ of $q$, there exists some $a < p$ and $b > p$ such that $f(x) \in N$ for all $x \in (a, p) \cup (b, p) = (a, b) \setminus \{ p \}$. By definition, $q$ is the limit of $f$ at $p$.
\end{proof}

\subsection{Limit inferior and limit superior}
Let $(x_\alpha)_{\alpha \in A}$ be a net in a complete ordered set $X$ (i.e. Dedekind-complete ordered set with maximum and minimum).
\begin{enumerate}
    \item The \emph{limit inferior} of $(x_\alpha)_{\alpha \in A}$ is defined as
    \begin{align*}
        \liminf_{\alpha \in A} x_\alpha = \lim_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta
    \end{align*}
    \item The \emph{limit inferior} of $(x_\alpha)_{\alpha \in A}$ is defined as
    \begin{align*}
        \limsup_{\alpha \in A} x_\alpha = \lim_{\alpha \in A} \sup_{\beta \geq \alpha} x_\beta
    \end{align*}
\end{enumerate}
\begin{remark}
Both limits
\begin{enumerate}
    \item Are well-defined because of the completeness of $X$.
    \item Exist because of the \hyperref[topo-ord-mono-conv]{monotone convergence theorem}. In fact,
    \begin{enumerate}
        \item $\liminf_{\alpha \in A} x_\alpha = \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$.
        \item $\limsup_{\alpha \in A} x_\alpha = \inf_{\alpha \in A} \sup_{\beta \geq \alpha} x_\beta$.
    \end{enumerate}
    So the limit inferior and the limit superior are unique.
\end{enumerate}
\begin{proof}
Since $\{ x_\beta : \beta \geq \alpha_1 \} \subseteq \{ x_\beta : \beta \geq \alpha_2 \}$ whenever $\alpha_1 \geq \alpha_2$, we get $\inf_{\beta \geq \alpha_1} x_\beta \geq \inf_{\beta \geq \alpha_2} x_\beta$ and $\sup_{\beta \geq \alpha_1} x_\beta \leq \sup_{\beta \geq \alpha_2} x_\beta$. We also have $\inf_{\beta \geq \alpha} x_\alpha$ and $\sup_{\beta \geq \alpha} x_\alpha$ sandwiched between the minimum and the maximum of $X$.
\end{proof}
\end{remark}
\begin{proposition}[Equivalent definition] \label{topo-ord-lim-inf-sup-event-freq}
Let $(x_\alpha)_{\alpha \in A}$ be a net and $p$ be a point in $X$
\begin{enumerate}
    \item TFAE
    \begin{enumerate}
        \item $p$ is a limit inferior of $(x_\alpha)_{\alpha \in A}$.
        \item $p$ is the supremum of all eventual lower bounds of the net.
        \item $x_\alpha > r$ eventually for all $r < p$, and $x_\alpha < s$ frequently for all $s > p$.
    \end{enumerate}
    \item TFAE
    \begin{enumerate}
        \item $p$ is a limit superior of $(x_\alpha)_{\alpha \in A}$
        \item $p$ is the infimum of all eventual upper bounds of the net.
        \item $x_\alpha > r$ frequently for all $r < p$, and $x_\alpha < s$ eventually for all $s > p$.
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
Part (2) is just the dual version of part (1), so the proof is similar once we show part (1) is true.
\\
\underline{Part 1:} we prove the following direction $(a) \Rightarrow (b) \Rightarrow (c) \Rightarrow (a)$.
\\
\\
*Suppose $p$ is a limit inferior $(x_\alpha)_{\alpha \in A}$, or $p = \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$. If $s$ is an eventual lower bound, then there exists $\eta \in A$ such that $x_\beta \geq s$ for all $\beta \geq \eta$. In other words, $s \leq \inf_{\beta \geq \eta} x_\beta$, so $s \leq \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta = p$. On the other hand, any $s < p$ is an eventual lower bound. Indeed, by definition of supremum, there exists some $\eta \in A$ such that $s < \inf_{\beta \geq \eta} x_\beta$. So $p$ is the supremum of all eventual lower bounds.
\\
\\
*Suppose $p$ is the supremum of all eventual lower bounds of the net. If $r < p$, then there is some eventual lower bound $l$ of the net such that $r < l \leq p$. Equivalently, there is some $\lambda \in A$ such that $x_\alpha \geq l > r$ for all $\alpha \geq \lambda$. In particular, $x_\alpha > r$ eventually. On the other hand, suppose $s > p$, yet $x_\alpha < s$ not frequently. In other words, $x_\alpha \geq s$ eventually (\hyperref[event-freq-equiv]{Lemma \ref*{event-freq-equiv}}), so $s \leq p$ by definition of $p$, a contradiction.
\\
\\
*Suppose $p$ is such that $x_\alpha > r$ eventually for all $r < p$, and $x_\alpha < s$ frequently for all $s > p$. If $p < \liminf_{\alpha \in A} x_\alpha = \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$, then there exists some $\eta \in A$ such that $p < \inf_{\beta \geq \eta} x_\beta$. If $s = \inf_{\beta \geq \eta} x_\beta$, then $x_\alpha < s$ frequently. In particular, there exists some $\beta \geq \eta$ such that $x_\beta < s$. But $x_\beta \geq \inf_{\beta \geq \eta} x_\eta$ by definition, so this is a contradiction.
\\
\\
Vice versa, if $p > \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$, let $r = \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$. Then $x_\alpha > r$ eventually, i.e. there exists some $\eta \in A$ such that $x_\alpha > \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$ for all $\alpha \geq \eta$. Consider the following cases
\begin{enumerate}
    \item If $(r, p)$ is empty: then $x_\alpha \geq p$ for all $\alpha \geq \eta$. Hence, $\inf_{\beta \geq \eta} x_\beta \geq p$, and so $\sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta \geq p$, contradicting the assumption.
    \item If $(r, p)$ is not empty: then let $s \in (r, p)$, and $\theta \in A$ be such that $x_\alpha > s$ for all $\alpha \geq \theta$. Thus, $\inf_{\beta \geq \theta} x_\beta \geq s$, and so $\sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta \geq s$, contradicting $s \in (r, p)$.
\end{enumerate}
\end{proof}
\begin{proposition}
Let $(x_\alpha)_{\alpha \in A}$ be a net in $X$
\begin{enumerate}
    \item $\inf_{\alpha \in A} x_\alpha \leq \liminf_{\alpha \in A} x_\alpha \leq \limsup_{\alpha \in A} x_\alpha \leq \sup_{\alpha \in A} x_\alpha$
    \item If $E$ is the set of cluster points of $(x_\alpha)_{\alpha \in A}$ (or rather cluster points of the eventuality filter base), then $\liminf_{\alpha \in A} x_\alpha = \min E$ and $\limsup_{\alpha \in A} x_\alpha = \max E$. In particular, $E$ cannot be empty (as long as the space is order-complete).
    \item If $(y_\alpha)_{\alpha \in A}$ is another net (with the same directed set) such that it dominates $(x_\alpha)_{\alpha \in A}$ (i.e. $y_\alpha \geq x_\alpha$ eventually), then
    \begin{align*}
        \limsup_{\alpha \in A} y_\alpha & \geq \limsup_{\alpha \in A} x_\alpha
        \\
        \liminf_{\alpha \in A} y_\alpha & \geq \liminf_{\alpha \in A} x_\alpha
    \end{align*}
    \item $(x_\alpha)_{\alpha \in A}$ converges to $p$ if and only if $p = \limsup_{\alpha \in A} x_\alpha = \liminf_{\alpha \in A} x_\alpha$.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} since $\inf_{\alpha \in A} x_\alpha$ is a lower bound of $(x_\alpha)_{\alpha \in A}$, we have $\liminf_{\alpha \in A} x_\alpha \geq \inf_{\alpha \in A} x_\alpha$ (\hyperref[topo-ord-lim-inf-sup-event-freq]{Proposition \ref*{topo-ord-lim-inf-sup-event-freq}}). Similarly, we get $\limsup_{\alpha \in A} \leq \sup_{\alpha \in A} x_\alpha$. As for the remaining inequality $\liminf_{\alpha \in A} x_\alpha \leq \limsup_{\alpha \in A} x_\alpha$, we can instead show $\sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta \leq \inf_{\alpha \in A} \sup_{\beta \geq \alpha} x_\beta$. For any $\eta, \gamma \in A$, there exists $\theta \in A$ such that $\theta \geq \eta, \gamma$. Hence,
\begin{align*}
    \inf_{\beta \geq \eta} x_\beta \leq \inf_{\beta \geq \theta} x_\beta \leq \sup_{\beta \geq \theta} x_\beta \leq \sup_{\beta \geq \gamma} x_\beta
\end{align*}
Since $\eta, \gamma$ are arbitrary, we get $\sup_{\eta \in A} \inf_{\beta \geq \eta} x_\beta \leq \inf_{\gamma \in A} \sup_{\beta \geq \gamma} x_\beta$.
\\
\\
\underline{Part 2:} let $p$ be a cluster point of $(x_\alpha)_{\alpha \in A}$, or equivalently, for any neighborhood $N$ of $p$ and $\alpha \in A$, there exists some $\eta \geq \alpha$ such that $x_\eta \in N$. If $p < \liminf_{\alpha \in A} x_\alpha$, then there exists some $\lambda \in A$ such that $r = \inf_{\beta \geq \lambda} x_\beta > p$, or $x_\beta > p$ for all $\beta \geq \lambda$. Set $N = (-\infty, r)$ and $\alpha = \lambda$, we get some $\eta \geq \lambda$ such that $x_\eta \in N$. In other words, $x_\eta < \inf_{\beta \geq \lambda} x_\beta$ for some $\eta \geq \lambda$, a contradiction. Similarly, asssuming $p > \limsup_{\alpha \in A} x_\alpha$ will lead to a contradiction, so $p$ must be between the limit inferior and the limit superior of $(x_\alpha)_{\alpha \in A}$.
\\
\\
*To finish, we need to show that those limits are also cluster points of $(x_\alpha)_{\alpha \in A}$. Let $m = \liminf_{\alpha \in A} x_\alpha$, $N$ be a neighborhood of $m$, and $\alpha \in A$
\begin{enumerate}
    \item If $N$ contains $(r, \infty)$ for some $r < m$: then there exists some $\lambda \in A$ such that $r < \inf_{\beta \geq \lambda} x_\beta$, or $x_\beta > r$ for all $\beta \geq \lambda$. Since $A$ is directed, there must be some $\eta \geq \alpha$ and $\eta \geq \lambda$, so we have $x_\eta > r$. In other words, $x_\eta \in N$ for some $\eta \geq \alpha$.
    \item If $N$ contains $(-\infty, s)$ for some $s > m$: then $s > \inf_{\beta \geq \alpha} x_\beta$ in particular. By definition of infimum, there exists some $\eta \geq \alpha$ such that $x_\eta < s$, or $x_\eta \in N$.
    \item Finally, if $N$ contains $(r, s)$ for some $r < m < s$: first, let $\lambda \in A$ such that $r < \inf_{\beta \geq \lambda} x_\beta$. Again $A$ is directed, so there exists some $\theta \geq \alpha$ and $\theta \geq \lambda$. On the other hand, $s > \sup_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$, so we get $s > \inf_{\beta \geq \theta} x_\beta$. By definition, there is some $\eta \geq \theta \geq \alpha$ such that $x_\eta < s$. But since $\eta \geq \theta \geq \lambda$, we also have $x_\eta > r$ (recall $r < \inf_{\beta \geq \lambda} x_\beta$ at the beginning). In summary, we get $x_\eta \in N$ for some $\eta \geq \alpha$.
\end{enumerate}
In any case, we get $x_\eta \in N$ for some $\eta \geq \alpha$. As $N$ and $\alpha$ varies, $m = \liminf_{\alpha \in A} x_\alpha$ is a cluster point of $(x_\alpha)_{\alpha \in A}$. Similarly, $M = \limsup_{\alpha \in A} x_\alpha$ is also a cluster point of $(x_\alpha)_{\alpha \in A}$.
\\
\\
\underline{Part 3:} let $\eta \in A$ be such that $y_\alpha \geq x_\alpha$ for all $\alpha \geq \eta$. From there, we get $\inf_{\beta \geq \alpha} y_\beta \geq \inf_{\beta \geq \alpha} x_\beta$ for all $\alpha \geq \eta$. Hence the net $(\inf_{\beta \geq \alpha} y_\beta)_{\alpha \in A}$ dominates $(\inf_{\beta \geq \alpha} x_\alpha)_{\alpha \in A}$. By \hyperref[topo-ord-dom-monic]{Proposition \ref*{topo-ord-dom-monic}}, $\lim_{\alpha \in A} \inf_{\beta \geq \alpha} y_\beta \geq \lim_{\alpha \in A} \inf_{\beta \geq \alpha} x_\beta$. Similarly, $\limsup_{\alpha \in A} y_\alpha \geq \limsup_{\alpha \in A} x_\alpha$.
\\
\\
\underline{Part 4:} if $p = \limsup_{\alpha \in A} x_\alpha = \liminf_{\alpha \in A} x_\alpha$, then for any $r < p < s$, we have $x_\alpha > r$ and $x_\alpha < s$ eventually (\hyperref[topo-ord-lim-inf-sup-event-freq]{Proposition \ref*{topo-ord-lim-inf-sup-event-freq}}). Since $(r, s)$ is a basic open neighborhood of $p$ (with $(r, s) \subseteq (r, \infty), (-\infty, s)$), we have $x_\alpha \in N$ eventually for each neighborhood $N$ of $p$. By definition, $(x_\alpha)_{\alpha \in A}$ converges to $p$.
\\
\\
If $(x_\alpha)_{\alpha \in A}$ converges to $p$, then for all $r < p < s$, $x_\alpha$ is eventually in $(r, s)$. Since eventual implies frequent (\hyperref[event-freq-equiv]{Lemma \ref*{event-freq-equiv}}), we know that $x_\alpha > r$ eventually, and $x_\alpha < s$ frequently. Thus, as $r, s$ vary, $p$ must be the limit inferior of $(x_\alpha)_{\alpha \in A}$. Similarly, $p$ is the limit superior of $(x_\alpha)_{\alpha \in A}$.
\end{proof}
The \emph{oscillator} of the net $(x_\alpha)_{\alpha \in A}$ is defined to be the closed interval with limit supremum and limit infimum as the endpoints.
\begin{remark}
The oscillator is always non-empty (as long as $X$ is completely ordered). It contains exactly 1 element if and only if the net is convergent.
\end{remark}
\ \\
We can also define limit supremum and infimum for a function $f: X \to L$ from a topological space $X$ to a complete totally ordered $L$. Let $\mathcal{B} \to p$, then
\begin{enumerate}
    \item The limit supremum of $f$ at $p \in X$ with respect to $\mathcal{B}$ (or $\mathcal{B}$-limit supremum) is the limit of the net $\sup f(B)$ indexed by $B \in \mathcal{B}$. Notationally
    \begin{align*}
        \limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \lim_{B \in \mathcal{B}} \sup_{x \in B} f(x)
    \end{align*}
    \item The limit infimum of $f$ at $p \in X$ with respect $\mathcal{B}$ (or $\mathcal{B}$-limit supremum) is the limit of the net $\inf f(N)$ indexed by neighborhoods $N$ at $p$. Notationally
    \begin{align*}
        \liminf_{\mathcal{B} \to p} f(\mathcal{B}) = \lim_{B \in \mathcal{B}} \inf_{x \in B} f(x)
    \end{align*}
\end{enumerate}
Again, one can verify that these are well-defined and exist (hint: use monotone convergence theorem). In fact, $\limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \inf_{B \in \mathcal{B}} \sup_{x \in B} f(x)$ and $\liminf_{\mathcal{B} \to p} f(\mathcal{B}) = \sup_{B \in \mathcal{B}} \inf_{x \in B} f(x)$.
\begin{proposition} \ 
\begin{enumerate}
    \item TFAE
    \begin{enumerate}
        \item $u$ is the limit supremum of $f$ at $p$ with respect to $\mathcal{B}$.
        \item $u$ is the infimum of upper bounds of $f(B)$ for all $B \in \mathcal{B}$.
        \item For all $s > u$, there exists $B \in \mathcal{B}$ such that $f(x) < s$ for all $x \in B$. And for all $r < u$, and for all $B \in \mathcal{B}$, there exists some $x \in B$ such that $f(x) > r$.
    \end{enumerate}
    Dually, TFAE
    \begin{enumerate}
        \item $l$ is the limit infimum of $f$ at $p$.
        \item $l$ is the supremum of lower bounds of $f(B)$ for all $B \in \mathcal{B}$.
        \item For all $r < l$, there exists $B \in \mathcal{B}$ such that $f(x) > r$ for all $x \in B$. And for all $s > l$, and for all $B \in \mathcal{B}$, there exists some $x \in B$ such that $f(x) < s$.
    \end{enumerate}
    \item $\inf_{x \in X} f(x) \leq \liminf_{\mathcal{B} \to p} f(\mathcal{B}) \leq \limsup_{\mathcal{B} \to p} f(\mathcal{B}) \leq \sup_{x \in X} f(x)$
    \item If $E_\mathcal{B}$ denotes the set of cluster points of $f(\mathcal{B})$, then $\limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \max E_\mathcal{B}$ and $\liminf_{\mathcal{B} \to p} f(\mathcal{B}) = \min E_\mathcal{B}$.
    \item If $\mathcal{C}$ refines $\mathcal{B}$ (and both converges at $p$), then
    \begin{align*}
        \limsup_{\mathcal{C} \to p} f(\mathcal{C}) & \leq \limsup_{\mathcal{B} \to p} f(\mathcal{B})
        \\
        \liminf_{\mathcal{C} \to p} f(\mathcal{C}) & \geq \liminf_{\mathcal{B} \to p} f(\mathcal{B})
    \end{align*}
    \item If $f(x) \leq g(x)$ for all $x \in X$, then
    \begin{align*}
        \limsup_{\mathcal{B} \to p} f(\mathcal{B}) & \leq \limsup_{\mathcal{B} \to p} g(\mathcal{B})
        \\
        \liminf_{\mathcal{B} \to p} f(\mathcal{B}) & \leq \liminf_{\mathcal{B} \to p} g(\mathcal{B})
    \end{align*}
    \item TFAE
    \begin{enumerate}
        \item $f$ is continuous at $p$.
        \item $\limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \liminf_{\mathcal{B} \to p} f(\mathcal{B})$
        \item $\limsup_{\mathcal{N}_p \to p} f(\mathcal{N}_p) = \liminf_{\mathcal{N}_p \to p} f(\mathcal{N}_p)$, where $\mathcal{N}_p$ is the neighborhood filter at $p$.
    \end{enumerate}
    If one of these holds, then we also have $\limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \liminf_{\mathcal{B} \to p} f(\mathcal{B}) = f(p)$
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} we only show the limit supremum part, with $(a) \Rightarrow (b) \Rightarrow (c) \Rightarrow (a)$ direction.
\\
\\
*Suppose $u$ is the limit supremum of $f$ at $p$ with respect to $\mathcal{B}$. Then $u = \inf_{B \in \mathcal{B}} \sup_{x \in B} f(x)$. If $s$ is an upper bound of $f(B)$, then $s \geq \sup_{x \in B} f(x)$, and so $s \geq u$ by definition of infimum. On the other hand, whenever $s > u$, then there exists some $B_s \in \mathcal{B}$ such that $s > \sup_{x \in B_s} f(x)$. Thus, $r = \sup_{x \in B_s} f(x) < s$ is an upper bound of $f(B_s)$. By definition, $u$ is the infimum of upper bounds of $f(B)$ for all $B \in \mathcal{B}$.
\\
\\
*Suppose $u$ is the infimum of upper bounds of $f(B)$ for all $B \in \mathcal{B}$. If $s > u$, then there is some $s' \in L$ and $B \in \mathcal{B}$ such that $s > s' \geq f(x)$ for all $x \in B$. On the other hand, if $r < u$, yet there exists $B_0 \in \mathcal{B}$ such that $f(x) \leq r$ for all $x \in B_0$. Equivalently $\sup_{x \in B_0} f(x) \leq r < u$, which contradicts the hypothesis since $r$ is smaller than $u$ while being an upper bound of $f(B_0)$.
\\
\\
*Suppose
\begin{enumerate}
    \item For all $s > u$, there exists $B \in \mathcal{B}$ such that $f(x) < s$ for all $x \in B$.
    \item For all $r < u$, and for all $B \in \mathcal{B}$, there exists some $x \in B$ such that $f(x) > r$.
\end{enumerate}
If $u > \limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \inf_{B \in \mathcal{B}} \sup_{x \in B} f(x)$, then there exists some $B_0 \in \mathcal{B}$ such that $u > \sup_{x \in B_0} f(x)$. Let $r = \sup_{x \in B_0} f(x)$, then by the hypothesis, there must be some $x_0 \in B_0$ such that $f(x_0) > r$, which contradicts $\sup_{x \in B_0} f(x) \geq f(x_0)$.
\\
\\
Vice versa, if $u < \limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \inf_{B \in \mathcal{B}} \sup_{x \in B} f(x)$, let $s = \inf_{B \in \mathcal{B}} \sup_{x \in B} f(x)$. Then there exists some $B_0 \in \mathcal{B}$ such that $f(x) < s$ for all $x \in B_0$. Consider the following cases.
\begin{enumerate}
    \item If $(u, s)$ is empty: then $f(x) \leq u$ for all $x \in B_0$. Hence, $\sup_{x \in B_0} f(x) \leq u$, which means $\inf_{B \in \mathcal{B}} \sup_{x \in B} f(x) \leq u$, contradicting the assumption.
    \item If $(u, s)$ contains some $t \in L$: by the hypothesis, there exists some $B_0 \in \mathcal{B}$ such that $f(x) < t$ for all $x \in B_0$. Thus, $\sup_{x \in B_0} f(x) \leq t$, so $u < \inf_{B \in \mathcal{B}} \sup_{x \in B} f(x) \leq t$, contradicting $t < s = \limsup_{\mathcal{B} \to p} f(\mathcal{B})$.
\end{enumerate}
Each case leads to a contradiction, so we must have $u \geq \limsup_{\mathcal{B} \to p} f(\mathcal{B})$. Combining with the prior result, we get $u = \limsup_{\mathcal{B} \to p} f(\mathcal{B})$.
\\
\\
\underline{Part 2:} since $B \subseteq X$, $\inf_{x \in B} f(x) \geq \inf_{x \in X} f(x)$. Hence, since $\mathcal{B}$ is non-empty, $\liminf_{\mathcal{B} \to p} f(\mathcal{B}) \geq \inf_{x \in B_0} f(x) \geq \inf_{x \in X} f(x)$ (fix some $B_0 \in \mathcal{B}$). Similarly, $\limsup_{\mathcal{B} \to p} f(\mathcal{B}) \leq \sup_{x \in X} f(x)$. As for the remaining inequality, for any $B_1, B_2 \in \mathcal{B}$, let $B \in \mathcal{B}$ be such that $B \subseteq B_1 \cap B_2$. From there, we get $\sup_{x \in B_1} f(x) \geq \sup_{x \in B} f(x) \geq \inf_{x \in B} f(x) \geq \inf_{x \in B_2} f(x)$. As $B_1$ and $B_2$ vary, we must have $\inf_{B \in \mathcal{B}} \sup_{x \in B} f(x) \geq \sup_{B \in \mathcal{B}} \inf_{x \in B} f(x)$.
\\
\\
\underline{Part 3:} let $p$ be a cluster point of $f(\mathcal{B})$. If $p < \liminf_{\mathcal{B} \to p} f(\mathcal{B})$, then there exists some $B_0 \in \mathcal{B}$ such that $p < r = \inf_{x \in B_0} f(x)$. Let $N = (-\infty, r)$ be a neighborhood of $p$, and $B = B_0$, then $f(B_0) \cap (-\infty, r)$ is not empty. Thus, there is some $x_0 \in B_0$ such that $f(x_0) < r$, which contradicts $\inf_{x \in B_0} f(x) \geq f(x_0)$. Similarly, we can show $p \leq \limsup_{\mathcal{B} \to p} f(\mathcal{B})$ through contradiction.
\\
\\
*To finish, we show that these limit extrema are also cluster point of $f(\mathcal{B})$. Denote $u = \limsup_{\mathcal{B} \to p} f(\mathcal{B})$, $N$ be a neighborhood of $m$, and $B \in \mathcal{B}$
\begin{enumerate}
    \item If $N$ contains $(-\infty, s)$ for some $s > u$: there exists some $B_0 \in \mathcal{B}$ such that $s > \sup_{x \in B_0} f(x)$, or $f(x) < s$ for all $x \in B_0$. Since $\mathcal{B}$ is a filter base, there is some $B' \in \mathcal{B}$ such that $B' \subseteq B \cap B_0$, so $f(x) < s$ for all $x \in B'$. In other words, $f(B') \subseteq N$, so $f(B) \cap N \supseteq f(B')$.
    \item If $N$ contains $(r, \infty)$ for some $r < u$: then $r < \sup_{x \in B} f(x)$ in particular. By definition of supremum, there is some $z \in B$ such that $r < f(z)$, so $f(B) \cap N$ contains $f(z)$.
    \item If $N$ contains $(r, s)$ for some $r < u < s$: there exists some $B_0 \in \mathcal{B}$ such that $s > \sup_{x \in B_0} f(x)$, or $f(x) < s$ for all $x \in B_0$. There also exists some $B' \in \mathcal{B}$ such that $B' \subseteq B \cap B_0$, so $f(x) < s$ for all $x \in B'$. On the other hand, $r < \inf_{B \in \mathcal{B}} \sup_{x \in B} f(x)$, so $r < \sup_{x \in B'} f(x)$ in particular. Hence, there exists some $x' \in B'$ such that $f(x') > r$. Since $f(x') < s$ (as $x' \in B' \subseteq B_0$) We conclude that $f(B) \cap N$ contains $f(x')$.
\end{enumerate}
In any case, $f(B) \cap N$ is always non-empty, so we conclude $\limsup_{\mathcal{B} \to p} f(\mathcal{B})$ is a cluster point of $f(\mathcal{B})$. Similarly, $\liminf_{\mathcal{B} \to p} f(\mathcal{B})$ is a cluster point of $f(\mathcal{B})$.
\\
\\
\underline{Part 4:} for each $B \in \mathcal{B}$, there exists $C \in \mathcal{C}$ such that $C \subseteq B$. This means $\sup_{x \in C} f(x) \leq \sup_{x \in B} f(x)$. Let $\mathcal{C}_0 = \{ C \in \mathcal{C} : C \subseteq B \mbox{ for some } B \in \mathcal{B} \}$, we then get $\inf_{B \in \mathcal{B}} \sup_{x \in B} f(x) \geq \inf_{C \in \mathcal{C}_0} \sup_{x \in C} f(x) \geq \inf_{C \in \mathcal{C}} \sup_{x \in C} f(x)$. Similarly, $\liminf_{\mathcal{B} \to p} f(\mathcal{B}) \leq \limsup_{\mathcal{C} \to p} f(\mathcal{C})$.
\\
\\
\underline{Part 5:} by the hypothesis, $\sup_{x \in B} f(x) \leq \sup_{x \in B} g(x)$ for each $B \in \mathcal{B}$. Thus, $\inf_{B \in \mathcal{B}} \sup_{x \in B} f(x) \leq \inf_{B \in \mathcal{B}} \sup_{x \in B} g(x)$. Similarly, $\liminf_{\mathcal{B} \to p} f(\mathcal{B}) \leq \liminf_{\mathcal{B} \to p} g(\mathcal{B})$.
\\
\\
\underline{Part 6:} we prove $(a) \Rightarrow (b) \Rightarrow (c) \Rightarrow (a)$.
\\
\\
*If $f$ is continuous at $p$: then $f(\mathcal{B}) \to p$ whenever $\mathcal{B} \to p$ (\hyperref[topo-cont-point-eq-seq-cont]{Proposition \ref*{topo-cont-point-eq-seq-cont}}).
\begin{enumerate}
    \item For the neighborhood $(-\infty, s)$, there exists $B_s \in \mathcal{B}$ such that $f(B_s) \subseteq (-\infty, s)$.
    \item For the neighborhood $(r, \infty)$, there exists $B_r \in \mathcal{B}$ such that $f(B_r) \subseteq (r, \infty)$. Given $B \in \mathcal{B}$, there exists some $B_0 \in \mathcal{B}$ such that $B_0 \subseteq B_r \cap B$. From there, $f(B_0) \subseteq f(B_r \cap B) \subseteq f(B_r) \cap f(B) \subseteq (r, \infty)$. Since $B_0 \neq \varnothing$, $f(B) \subseteq (r, \infty) \neq \varnothing$ for arbitrary $B \in \mathcal{B}$.
\end{enumerate}
These 2 points characterize $f(p) = \limsup_{\mathcal{B} \to p} f(\mathcal{B})$ (part 1). Similarly, $f(p) = \liminf_{\mathcal{B} \to p} f(\mathcal{B})$.
\\
\\
*If $\limsup_{\mathcal{B} \to p} f(\mathcal{B}) = \liminf_{\mathcal{B} \to p} f(\mathcal{B})$ for all $\mathcal{B} \to p$, then $\limsup_{\mathcal{N}_p \to p} f(\mathcal{N}_p) = \liminf_{\mathcal{N}_p \to p} f(\mathcal{N}_p)$ in particular (as $\mathcal{N}_p \to p$).
\\
\\
*If $\limsup_{\mathcal{N}_p \to p} f(\mathcal{N}_p) = \liminf_{\mathcal{N}_p \to p} f(\mathcal{N}_p)$, denote such limit to be $q$. If $f(p) < q$, then there exists a neighborhood $N_f$ of $p$ such that $f(x) > f(p)$ for all $x \in N_f$ (since $q = \liminf_{\mathcal{N}_p \to p} f(\mathcal{N}_p)$). In particular, $f(p) > f(p)$ (since $p \in N_f$), a contradiction. Similarly, if $f(p) > q = \limsup_{\mathcal{N}_p \to p} f(\mathcal{N}_p)$, then there exists a neighborhood $N_f$ of $p$ such that $f(x) < f(p)$ for all $x \in N_f$, which also leads to a contradiction. We conclude that $q = f(p)$, and so for an arbitrary neighborhood $U$ of $f(p)$
\begin{enumerate}
    \item If $U$ contains $(r, \infty)$ for some $r < f(p)$: there exists a neighborhood $N$ of $p$ such that $f(N) \subseteq (r, \infty) \subseteq U$ (again, $f(p) = \liminf_{\mathcal{N}_p \to p} f(\mathcal{N}_p)$). In other words, $N \subseteq f^{-1}(U)$ and so $f^{-1}(U)$ is also a neighborhood of $p$.
    \item If $U$ contains $(-\infty, s)$ for some $s > f(p)$: similarly, because of $f(p) = \limsup_{\mathcal{N}_p \to p} f(\mathcal{N}_p)$, there exists a neighborhood $N$ of $p$ such that $f(N) \subseteq (-\infty, s) \subseteq U$. We then also have $f^{-1}(U)$ as a neighborhood of $p$.
    \item If $U$ contains $(r, s)$ for some $r < f(p) < s$: there exists neighborhoods $N_r, N_s$ of $p$ such that $f(N_r) \subseteq (r, \infty)$, and $f(N_s) \subseteq (-\infty, s)$. Then $N = N_r \cap N_s$ is a neighborhood of $p$ such that $f(N) \subseteq f(N_r) \cap f(N_s) \subseteq (r, \infty) \cap (-\infty, s) = (r, s) \subseteq U$. So $f^{-1}(U)$ is a neighborhood of $p$.
\end{enumerate}
In any case, $f^{-1}(U)$ is a neighborhood of $p$. As $U$ varies, $f$ is continuous at $p$ by definition.
\end{proof}

\newpage

\section{Subspace Topology}
Let $S$ be a subset of a topological space $X$, then the \emph{subspace topology} on $S$ (relative to $X$) is the following collection $\mathcal{T}_S = \{ U \cap S : U \mbox{ is open in } X \}$
\begin{remark}
It is indeed a topology on $S$.
\end{remark}
\begin{proof} \ 
\begin{enumerate}
    \item Any set in $\mathcal{T}_S$ is of the form $U \cap S$, so it must be a subset of $S$.
    \item $X \cap S = S \in \mathcal{T}_S$ and $\varnothing \cap S = \varnothing \in \mathcal{T}_S$.
    \item If $U, V$ are open set in $X$, then $U \cap V$ is open in $X$ and so $(U \cap S) \cap (V \cap S) = (U \cap V) \cap S \in \mathcal{T}_S$.
    \item If $\{ U_i \}_{i \in I}$ is a family of open sets in $X$, then $\bigcup_{i \in I} U_i$ is open in $X$ and so $\bigcup_{i \in I} (U \cap S) = \left( \bigcup_{i \in I} U_i \right) \cap S \in \mathcal{T}_S$ by distributivity.
\end{enumerate}
\end{proof}
\begin{proposition}[Basic properties] \label{sub-topo-prop-1}\ 
\begin{enumerate}
    \item A set $C$ is closed in $S$ if and only if there exists some closed set $D$ in $X$ such that $C = D \cap S$.
    \item If $S$ is open, then $U$ is open in $S$ if and only if it is open in $X$.
    \\
    Vice versa, if $S$ is closed, then $C$ is closed in $S$ if and only if it is closed in $X$.
    \item If $\mathcal{T}_1 \subseteq \mathcal{T}_2$ are topologies on $X$, and $\mathcal{S}_1, \mathcal{S}_2$ are respectively the subspace topologies on $X$ relative to $\mathcal{T}_1, \mathcal{T}_2$, then $\mathcal{S}_1 \subseteq \mathcal{S}_2$.
    \item If $p \in S$ and $N$ is a neighborhood of $p$ with respect to $X$, then $N \cap S$ is a neighborhood of $p$ with respect to $S$.
    \item If $\mathcal{B}$ is a basis of $X$, then $\mathcal{B}_S = \{ B \cap S : B \in \mathcal{B} \}$ is a basis of $S$.
    \\
    As a result, $w(S) \leq w(X)$.
    \item If $\mathcal{G}$ generates $X$, then $\mathcal{G}_S = \{ G \cap S : G \in \mathcal{G} \}$ generates $X$.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} if $C$ is closed in $S$, then $U = S \setminus C$ is open in $S$, so there exists some $V$ open in $X$ such that $U = V \cap S$. Let $D = X \setminus V$ be a closed set in $X$, then $D \cap S = (X \setminus V) \cap S = S \setminus V = S \setminus (V \cap S) = S \setminus U = C$. If $C = D \cap S$ for some closed set $D$ in $X$, then $S \setminus C = S \setminus (D \cap S) = S \setminus D = S \cap (X \setminus D)$, so $S \setminus C$ must be open in $S$. Equivalently, $C$ is closed in $S$.
\\
\underline{Part 2:} the closed case is proven similarly to the open case (with the help of part 1), so we only prove the latter one. Given $S$ open, if $U$ is open in $S$, then there exists some open $V$ in $X$ such that $U = V \cap S$. But the intersection of 2 open sets is open, so $U$ is open in $X$. Vice versa, if $U$ is open in $X$, then $U = U \cap S$ (since $U \subseteq S$), so $U$ is open in $S$.
\\
\underline{Part 3:} if $U \in \mathcal{S}_1$, then there exists some $V \in \mathcal{T}_1$ such that $U = V \cap S$. But $\mathcal{T}_1 \subseteq \mathcal{T}_2$, so $U = V \cap S$ for some $V \in \mathcal{T}_2$. In other words, $U \in \mathcal{S}_2$.
\\
\underline{Part 4:} if $N$ is a neighborhood of $p$ with respect to $X$, then there exists some open subset $U$ of $N$ in $X$ containing $p$. Then $p \in U \cap S \subseteq N \cap S$ and $U \cap S$ is open in $S$, so $N \cap S$ is a neighborhood of $p$ with respect to $S$.
\\
\underline{Part 5:} by definition of subspace topology, any set in $\mathcal{B}_S$ is open. On the other hand, given any open neighborhood $V$ of $p$ in $S$, there exists some $U$ open in $X$ such that $V = U \cap S$. In particular, $U$ is an open neighborhood of $p$, so there exists some $B \in \mathcal{B}$ such that $p \in B \subseteq U$. But then $B \cap S \in \mathcal{B}_S$ and $p \in B \cap S \subseteq U \cap S = V$. Therefore, $\mathcal{B}_S$ is a basis of $S$.
\\
\underline{Part 6:} by \hyperref[topo-gen-steps]{Theorem \ref*{topo-gen-steps}}, $\mathcal{G}$ generates $X$ if and only if $\mathcal{B} = \mathcal{G}^{FI, M} = \{ \bigcap_{i = 1}^n G_i : G_i \in \mathcal{G} \} \cup \{ \varnothing, X \}$ is a basis on $X$. Since $\mathcal{B}_S = \{ H \cap S : H \in \mathcal{G}^{FI, M} \} = \{ (\bigcap_{i = 1}^n G_i) \cap S : G_i \in \mathcal{G} \} \cup \{ \varnothing, S \} = \{ \bigcap_{i = 1}^n (G_i \cap S) : G_i \in \mathcal{G} \} \cup \{ \varnothing, S \} = \mathcal{G}_S^{FI, M}$, we conclude (by the same theorem mentioned previously) that $\mathcal{G}_S$ generates $S$.
\end{proof}
\begin{proposition}[Operator properties]
Let $A \subseteq S \subseteq X$. We will subscript the operators with either $S$ or $X$ to distinguish between the topologies.
\begin{enumerate}
    \item If $S$ is open (in $X$), $\operatorname{int}_S (A) = \operatorname{int}_X (A)$.
    \item $\operatorname{cl}_S (A) = \operatorname{cl}_X (A) \cap S$.
    \\
    \\
    As a result, $A$ is dense in $S$ (with respect to $S$) if and only if $S = \operatorname{cl}_X (A)$ (i.e. $A$ is dense in $S$ with respect to $X$).
    \item $\operatorname{ext}_S (A) = \operatorname{ext}_X (A) \cap S$.
    \item $\operatorname{lp}_S (A) = \operatorname{lp}_X (A) \cap S$.
    \item $\operatorname{ip}_S (A) = \operatorname{ip}_X (A)$.
    \\
    \\
    As a result, $S$ is a discrete subset of $X$ if and only if $S$ is a discrete space (under subspace topology). In short term, the 2 notions of discreteness are the same, so there will be no confusion when we mention discrete subspace of a space.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} if $S$ is open, then $\operatorname{int}_S (A) \subseteq A$ is open in $X$ by \hyperref[sub-topo-prop-1]{Proposition \ref*{sub-topo-prop-1}}. Thus, $\operatorname{int}_S (A) \subseteq \operatorname{int}_X (A)$. On the other hand, $\operatorname{int}_X (A) \cap S$ is open in $S$ by definition, so $\operatorname{int}_X (A) \cap S \subseteq \operatorname{int}_S (A)$ by maximality. However $\operatorname{int}_X (A) \subseteq A \subseteq S$, so $\operatorname{int}_X (A) \subseteq \operatorname{int}_S (A)$.
\\
\underline{Part 2:} the inclusion $\operatorname{cl}_X (A) \cap S \supseteq \operatorname{cl}_S (A)$ holds by minimality since $\operatorname{cl}_X (A)$ is a closed set containing $A$. For the reverse direction, there exists a closed set $C$ in $X$ such that $\operatorname{cl}_S(A) = C \cap S$. Since $\operatorname{cl}_S(A)$ contains $A$, $C$ contains $A$ and so $C$ contains $\operatorname{cl}_X (A)$. In other words, $\operatorname{cl}_X (A) \cap S \subseteq C \cap S = \operatorname{cl}_S(A)$.
\\
\underline{Part 3:} applying part (2), we get $\operatorname{ext}_S (A) = S \setminus \operatorname{cl}_S (A) = S \setminus (\operatorname{cl}_X (A) \cap S) = (S \setminus \operatorname{cl}_X (A)) \cup (S \setminus S) = S \cap (X \setminus \operatorname{cl}_X (A)) = S \cap \operatorname{ext}_X (A)$.
\\
\underline{Part 4:} suppose $p$ is a limit point of $A$ relative to $S$. If $N$ is a neighborhood of $p$ (relative to $X$), then $N \cap S$ is a neighborhood of $p$ (relative to $S$) by \hyperref[sub-topo-prop-1]{Proposition \ref*{sub-topo-prop-1}}. Therefore, $(N \cap S) \cap A$ contains another point other than $p$. Since $(N \cap S) \cap A \subseteq N \cap A$, $N \cap A$ contains another point other than $p$, and so $p$ is a limit point of $A$ relative to $X$.
\\
\\
Vice versa, suppose $p \in S$ is a limit point of $A$ relative to $X$. Given $V$ an open neighborhood of $p$ relative to $S$, there exists an open set $U$ in $X$ such that $V = U \cap S$, since $p \in V$, $U$ is an open neighborhood of $p$ relative to $X$. By assumption, $U \cap A$ contains another point different from $p$. Since $A \subseteq S$, $U \cap A = V \cap A$, so as $V$ varies, $p$ should be a limit point of $A$ relative to $S$.
\\
\underline{Part 5:}
\begin{align*}
    \operatorname{ip}_S (A) & = \operatorname{cl}_S (A) \setminus \operatorname{lp}_S (A) = \operatorname{cl}_X (A) \cap S \cap [X \setminus (\operatorname{lp}_X (A) \cap S)]
    \\
    & = \operatorname{cl}_X (A) \cap S \cap [(X \setminus \operatorname{lp}_X (A)) \cup (X \setminus S)]
    \\
    & = [\operatorname{cl}_X (A) \cap S \cap (X \setminus \operatorname{lp}_X (A))] \cup [ \operatorname{cl}_X (A) \cap S \cap (X \setminus S)]
    \\
    & = [(\operatorname{cl}_X (A) \setminus \operatorname{lp}_X (A)) \cap S] \cup \varnothing = \operatorname{ip}_X (A) \cap S = \operatorname{ip}_X (A)
\end{align*}
The final equality holds since $\operatorname{ip}_X (A) \subseteq A \subseteq S$.
\\
\\
As a result, if $S$ is a discrete subset of $X$, then $\operatorname{ip}_S (S) = \operatorname{ip}_X (S) = S$. Therefore, with respect to $S$, every point in $S$ must be open, and thus, $S$ is a discrete space. Vice versa, if $S$ is discrete then every point in $S$ must be open relative to $S$, so by definition $S \subseteq \operatorname{ip}_S (S) = \operatorname{ip}_X (S) \subseteq S$, i.e. $S$ is a discrete subset of $X$.
\end{proof}
\begin{proposition}[Categorical properties] \ 
\begin{enumerate}
    \item If $A \subseteq S \subseteq X$, then the subspace topology on $A$ relative to $S$ is the same as the subspace topology on $A$ relative $X$.
    \item Characteristic property: the subspace topology on $S$ is unique in that
    \begin{enumerate}
        \item The inclusion $\iota_S: S \to X$ is continuous
        \item $f: Z \to S$ is continuous if and only if $\iota_S \circ f: Z \to X$ is continuous.
    \end{enumerate}
    \item The subspace topology on $S$ is also the smallest topology such that $\iota_S: S \to X$ is continuous.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 1:} if $U$ is open in $A$ relative to $S$, then there exists $V$ open in $S$ and $W$ open in $X$ such that $U = V \cap A$ and $V = W \cap S$. Combine these 2 equalities, we get $U = W \cap S \cap A = W \cap A$, so $U$ is open in $A$ relative to $X$. Vice versa, if $U$ is open in $A$ relative $X$, there exists $W$ open in $X$ such that $U = W \cap A$. Let $V = W \cap S$, which is open in $S$ relative to $X$, we have $U = W \cap A = W \cap S \cap = V \cap A$ (since $A \subseteq S$, or $A \cap S = A$), so $U$ is open in $A$ relative to $S$.
\\
\\
\underline{Part 2:} we first verify the 2 properties. Since $\iota_S^{-1}(U) = \{ x \in S : \iota_S (x) = x \in U \} = S \cap U$ is open in $S$ whenever $U$ is open in $X$, $\iota_S$ is continuous by definition. If $f: Z \to S$ is continuous, then $\iota_S \circ f: Z \to X$ is continuous (composition of continuous functions is continuous). Vice versa, suppose $\iota_S \circ f$ is continuous. For each $V$ open in $S$, there exists $U$ open in $X$ such that $V = U \cap S$, so $\iota_S^{-1}(U) = V$, Therefore, $f^{-1}(V) = f^{-1}(U \cap S) = f^{-1}(\iota_S^{-1}(U)) = (\iota_S \circ f)^{-1}(U)$ is open in $Z$. We conclude $f$ is continuous.
\\
\\
Next, suppose $\mathcal{T}$ is another topology on $S$ that satisfies the 2 conditions. Then $U \cap S = \iota_S^{-1}(U) \in \mathcal{T}$ for all $U$ open in $X$, so $\mathcal{T}$ is finer than the subspace topology. On the other hand, let $\operatorname{id}_S: S \to (S, \mathcal{T})$ where the former one is endowed with subspace topology. Since we already show that $\iota_S \circ \operatorname{id}_S: S \to X$ is continuous, $\operatorname{id}_S$ must be continuous. By \hyperref[comp-topo-cont]{Proposition \ref*{comp-topo-cont}}, the subspace topology must be finer than $\mathcal{T}$. We conclude $\mathcal{T}$ is the subspace topology.
\\
\underline{Part 3:} this follows from the uniqueness proof of part (2).
\end{proof}
\ \\
A subset $L$ of a linearly ordered set $X$ is \emph{convex} if $(a, b) \subseteq L$ whenever $a, b \in L$.
\begin{proposition}[Order vs. Subspace]
Let $L$ be a subset of a linearly ordered set $X$, endowed with order topology
\begin{enumerate}
    \item Let $\mathcal{T}_L$ and $\mathcal{T}_{\leq}$ be the subspace topology and order topologies on $L$ (with respect to the topology and order on $X$), then $\mathcal{T}_L$ is finer $\mathcal{T}_{\leq}$
    \item Equality happens (between the 2 topologies) when $L$ is convex.
\end{enumerate}
\end{proposition}
\begin{proof}
We will compare the topologies based on their corresponding bases (recall \hyperref[topo-compare-basis]{Lemma \ref*{topo-compare-basis}}): the basis for $\mathcal{T}_L$ consists of $(a, b) \cap L$, $(a, \infty) \cap L$, $(-\infty, b) \cap L$ ($a, b \in X$) (\hyperref[sub-topo-prop-1]{Proposition \ref*{sub-topo-prop-1}}), and the basis for $\mathcal{T}_{\leq}$ consists of ($p, q \in L$)
\begin{enumerate}
    \item $(p, q)_L = \{ x \in L : p < x < q \} = (p, q) \cap L$
    \item $(p, \infty)_L = \{ x \in L : x > p \} = (p, \infty) \cap L$
    \item $(-\infty, q)_L = \{ x \in L : x < q \} = (-\infty, q) \cap L$
\end{enumerate}
\underline{Part 1:} from the above, the basis for $\mathcal{T}_{\leq}$ is a subcollection of the basis for $\mathcal{T}_L$, so $\mathcal{T}_{\leq} \subseteq \mathcal{T}_L$.
\\
\underline{Part 2:} to show the reverse inclusion, we consider the following basic open sets of $\mathcal{T}_L$, and show that there exists $U \in \mathcal{T}_{\leq}$ around each point $p$ in the sets. Note that every mention of neighborhood is relative to $\mathcal{T}_{\leq}$.
\begin{enumerate}
    \item $z \in (a, \infty) \cap L$: divide into the several cases
    \begin{enumerate}
        \item $L = \{ z \}$: then $L \cap (a, \infty) = \{ z \}$ and so $L$ is the neighborhood of $z$ such that $L \subseteq L \cap (a, \infty)$.
        \item $p < z < q$ for some $p, q \in L$, and $p \leq a \leq q$: then $a \in L$ and $(a, q) \subseteq L$ (i.e. $(a, q)_L = (a, q)$). Hence, $(a, q)$ is an open neighborhood of $z$, such that $(a, q) \subseteq (a, \infty) \cap L$.
        \item $p < z < q$ for some $p, q \in L$, and $a < p$: then $(p, q)$ is a neighborhood of $z$ such that $(p, q) \subseteq (a, \infty) \cap L$ (since $L$ is convex).
        \item $p < z < q$ for some $p, q \in L$ and $a > q$: this never happen, since it would mean $a < z < q < a$, a contradiction.
        \item $z = \max L$, and $a \geq p$ for some $p \in L \setminus \{ z \}$ (note we already examine the case $L = \{ z \}$ in the beginning): then $a \in L$ (as $z > a \geq p$) and $(a, \infty)_L = (a, z] \subseteq (a, \infty)$. Thus, $(a, z]$ is a neighborhood of $z$ such that $(a, z] \subseteq (a, \infty) \cap L$.
        \item $z = \max L$, and $a < p$ for some $p \in L \setminus \{ z \}$: then $(p, \infty)_L = (p, z]$ is non-empty since $p \neq z$, and $(p, z] \subseteq (a, \infty)$. Therefore, $(p, z]$ is a neighborhood of $z$ such that $(p, z] \subseteq (a, \infty) \cap L$.
        \item $z = \min L$, and $a \geq q$ for some $q \in L \setminus \{ z \}$: this cannot happen since we would get $q \leq a < z \leq q$, a contradiction.
        \item $z = \min L$, and $a < q$ for some $q \in L \setminus \{ z \}$: then $(-\infty, q)_L = [z, q)$ is not empty since $q \neq z$, and $[z, q) \subseteq (a, \infty)$. Hence, $[z, q)$ is a neighborhood of $z$ such that $[z, q) \subseteq (a, \infty) \cap L$.
    \end{enumerate}
    \item $z \in (-\infty, b) \cap L$: similar to $z \in (a, \infty) \cap L$
    \item $z \in (a, b) \cap L$: let $N^+$ be a neighborhood of $z$ such that $N^+ \subseteq (a, \infty) \cap L$ (1st type), and $N^-$ be a neighborhood of $z$ such that $N^- \subseteq (-\infty, b) \cap L$ (2nd type). Denote $N = N^+ \cap N^-$, then we get a neighborhood of $z$ such that $N \subseteq (a, \infty) \cap L \cap (-\infty, b) \cap L = (a, b) \cap L$.
\end{enumerate}
We conclude that $\mathcal{T}_L \subseteq \mathcal{T}_{\leq}$, or $\mathcal{T}_L = \mathcal{T}_{\leq}$ simply.
\end{proof}

\subsection{Continuous function on a subspace}
\begin{proposition}[Restriction] \label{topo-res-cont}
Let $f: X \to Y$ be a continuous function, $S \subseteq X$, $T \supseteq f(X)$
\begin{enumerate}
    \item The (domain) restriction $f \mid_S : S \to Y$ is continuous.
    \item Vice versa, the codomain restriction $f \mid^T : X \to T$ is continuous.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} $f \mid_S$ is just $f \circ \iota_S$, so $f \mid_S$ is continuous because it is the composition of continuous functions.
\\
\underline{Part 2:} if $V$ is open in $T$, then there exists $U$ open in $Y$ such that $V = T \cap U$. We have $f^{-1}(U)$ open in $X$, so $(f \mid^T)^{-1}(V) = f^{-1}(V) = f^{-1}(T \cap U) = f^{-1}(T) \cap f^{-1}(U) = X \cap f^{-1}(U) = f^{-1}(U)$ is also open in $X$. By definition, $f \mid^T$ is continuous.
\end{proof}
Given a continuous map $f: X \to Y$
\begin{enumerate}
    \item If the restriction $f_X : X \to f(X)$ is a homeomorphism, then we say $f$ is an \emph{topological embedding}. Additionally, if the image $f(X)$ is open (resp. closed), we say that $f$ is an open (resp. closed) embedding.
    \\
    \\
    \underline{Note:} by definition, an embedding is always injective.
    \item If the image $f(X)$ is dense in $Y$, we say $f$ is \emph{dominant}.
    \\
    \underline{Note:} a surjective (continuous) map is always dominant, but not vice versa.
    \item If, for each point $p$ in $X$ there exists an \textit{open} neighborhood $U$ of $p$ such that $f_U : U \to f(U)$ is a homeomorphism, then we say $f$ is a \emph{local homeomorphism}.
    \item If $Y \subseteq X$, and $f \circ \iota_Y = \operatorname{id}_Y$, then we say $f$ is a \emph{retract} of $X$ into $Y$.
    \\
    \underline{Note:} a retract always surjective (since it is a left inverse of some function).
\end{enumerate}
\begin{proposition}[Functional properties] \ 
\begin{enumerate}
    \item If $f: X \to Y$ is a homeomoprhism, and $S \subseteq X$, then the restriction $f_S : S \to f(S)$ is also a homeomorphism.
    \item Given $f: X \to Y$ an injective continuous map.
    \begin{enumerate}
        \item $f$ is an open map iff $f$ is an open embedding.
        \item $f$ is a closed map iff $f$ is a closed embedding.
    \end{enumerate}
    \item Composition of embeddings is an embedding.
    \\
    Composition of open embeddings is an open embedding.
    \\
    Composition of closed embeddings is a closed embedding.
    \\
    Composition of dominant maps is dominant.
    \\
    Composition of local homeomorphism is a local homeomorphism.
    \\
    Composition of retracts is another retract.
    \item The map $\iota_S: S \xhookrightarrow{} X$ is an embedding. It is open iff $S$ is open, and it is closed iff $S$ is closed.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} note that $f_S$ and similarly $(f_S)^{-1} = f^{-1}_{f^{-1}(S)}$ is continuous by \hyperref[topo-res-cont]{Proposition \ref*{topo-res-cont}}.
\\
\underline{Part 2:}
\begin{enumerate}[label=(\alph*)]
    \item If $f$ is open, then $f(X)$ is open, so we only need to show $f_X: X \to f(X)$ is a homeomorphism. Denote $g: f(X) \to X$ to be the inverse of $f_X$. If $U$ is open in $X$, then $g^{-1}(U) = f(U)$ is also open by assumption. By definition, $g$ is continuous. Vice versa, if $f$ is an open embedding, then $f(X)$ is open and $f(U)$ is open in $f(X)$ whenever $U$ is open in $X$ (since $f_X: X \to f(X)$ is a homeomorphism). Therefore, $f(U)$ is open in $Y$ because of \hyperref[sub-topo-prop-1]{Proposition \ref*{sub-topo-prop-1}}. Since $U$ is arbitrary, $f$ must be open.
    \item Similar to part (2a).
\end{enumerate}
\underline{Part 3:} given $f: X \to Y$ and $g: Y \to Z$
\begin{enumerate}[label=(\alph*)]
    \item If $f, g$ are embedding, then $f_X : X \to f(X) \subseteq Y$ and $g_Y: Y \to g(Y) \subseteq Z$ are homeomorphisms. So by part (1), $g_{f(X)}: f(X) \to g(f(X))$ is a homeomorphism, and $(g \circ f)_X : X \to g(f(X)) \subseteq Z$ (which is the composition of $f_X$ and $g_{f(X)}$) is a homeomorphism. By definition, $g \circ f$ is an embedding.
    \item If $f, g$ are open embedding, then $g \circ f$ is an embedding by part (3a). By part (2a), $f, g$ are open maps, so $g \circ f$ is also open by \hyperref[topo-open-closed-map-prop]{Proposition \ref*{topo-open-closed-map-prop}}. By part (2a), $g \circ f$ is an open embedding.
    \item Similar to part (3b).
    \item If $f, g$ are dominant, then $\operatorname{cl}_Y (f(X)) = Y$, and $\operatorname{cl}_Z (g(Y)) = Z$. By \hyperref[cont-equiv-def]{continuity}, we have $\operatorname{cl}_Z (g(f(X))) \supseteq g(\operatorname{cl}_Y f(X)) = g(Y)$. Applying the closure on both side we get $\operatorname{cl}_Z (g(f(X))) \supseteq \operatorname{cl}_Z (g(Y)) = Z$. Thus, $g \circ f$ is dominant.
    \item If $f, g$ are local homeomorphism, then for each $p \in X$, there exists open neighborhood $U$ of $p$ and open neighborhood $V$ of $f(p)$ such that $f_U: U \to f(U)$ and $g_V: V \to g(V)$ are homeomorphism. Let $W = f^{-1}(V) \cap U$ be an open neighborhood of $p$ such that $W \subseteq U$ and $f(W) \subseteq V$. The restriction $f_W : W \to f(W)$ (from $U$ to $W$) of the homeomorphism $f_U$ is still a homeomorphism by part (1), and $g_{f(W)} : f(W) \to g(f(W))$ (from $V$ to $f(W)$) is similarly a homeomorphism. Therefore, $(g \circ f)_W : W \to g(f(W))$ is also a homeomorphism, which concludes $g \circ f$ is a local homeomorphism as $p$ varies in $X$.
    \item If $f, g$ are retracts, then $f \circ \iota_{YX} = \operatorname{id}_Y$ and $g \circ \iota_{ZY} = \operatorname{id}_Z$ (note that $Z \subseteq Y \subseteq X$, and $\iota_{ZY} : Z \xhookrightarrow{} Y$, $\iota_{YX} : Y \xhookrightarrow{} X$). We then have $\iota_{YX} \circ \iota_{ZY}$ is the inclusion $\iota_{ZX}$ of $Z$ into $X$ and
    \begin{align*}
        (g \circ f) \circ \iota_{ZX} = g \circ (f \circ \iota_{YX}) \circ \iota_{ZY} = g \circ \operatorname{id}_Y \circ \iota_{ZY} = \operatorname{id}_Z
    \end{align*}
\end{enumerate}
\underline{Part 4:} $\iota_S$ is injective and continuous, and given $U$ open in $\iota_S (S) = S$, then $(\iota_S^{-1})^{-1}(U) = \iota_S (U) = U$ is also open in $S$. By definition, the inverse $\iota_S^{-1}$ is continuous, and so $\iota_S$ is an embedding.
\\
\\
If $S$ is open (in $X$), then $\iota_S (S) = S$ is open in $X$, thus $\iota_S$ is an open embedding by definition. If $\iota_S$ is an open embedding, then $\iota_S (S)$ is open. The closed case follows similarly
\end{proof}
\begin{proposition}[Categorical properties] \ 
\begin{enumerate}
    \item A (continuous) map is a monomorphism iff it is injective.
    \item A map is a epimorphism iff it is surjective.
    \item A map is an extremal monomorphism iff it is an embedding.
    \\
    In fact, all extremal monomorphisms in the $\mathbf{Top}$ category are also regular (which is stronger).
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} suppose $f: X \to Y$ is a monomorphism, i.e. for any continuous map $g_1, g_2 : Z \to X$, $f \circ g_1 = f \circ g_2$ implies $g_1 = g_2$. Given $f(x) = f(y)$, let $g_x : \{ p \} \to X, p \mapsto x$ and $g_y: \{ p \} \to X, p \mapsto y$. These are continuous (\hyperref[topo-cat]{Theorem \ref*{topo-cat}}), and $f \circ g_1 (p) = f(x) = f(y) = f \circ g_2 (p)$, so $g_x = g_y$, i.e. $x = y$. By definition, $f$ is injective. The reverse direction is just a basic fact of set theory.
\\
\underline{Part 2:} suppose $f: X \to Y$ is not surjective, i.e. there exists some $y_0 \in Y$ such that $f(x) \neq y_0$ for all $x \in X$. Endow $Z = \{ 0, 1 \}$ with indiscrete topology, and let $h_1 : Y \to Z$ to be the constant map at $1$, $h_f : Y \to Z$ to be the characteristic function of $f(X) \subset Y$ (i.e. $h_f (y) = 1$ if $y \in f(X)$, and $0$ otherwise). We then get $h_1(f(x)) = 1 = h_f (f(x))$, yet $h_1 \neq h_f$ since $h_1(y_0) = 1$ yet $h_f(y_0) = 0$. By definition, $f$ is not an epimorphism. The converse, again, is just a basic fact of set theory.
\\
\underline{Part 3:} since regular monomorphism is extremal, we can show instead every extremal monomorphism is an embedding, and every embedding is a regular monomorphism.
\\
\\
Recall that an extremal monomorphism $f: X \to Y$ is a monomorphism such that whenever $f = g \circ e$ for an epimorphism $e: X \to Z$ (with $g: Z \to Y$), then $e$ is an isomorphism. Let $e = f_X : X \to f(X)$ and $g = \iota_{f(X)} : f(X) \xhookrightarrow{} Y$, then $e$ is surjective. By part (2), $e$ is an epimorphism, so it must be an isomorphism. In other words, $f$ must be an embedding.
\\
\\
Next, if $f: X \to Y$ is an embedding, let $h_1, h_f : Y \to Z$ be defined as in part (2). We then have $h_1(f(x)) = 1 = h_f(f(x))$. In addition, if $e: S \to Y$ is a continuous function such that $h_1 \circ m = h_f \circ m$, then we have $e(s) \in f(X)$ for all $s \in S$ (since $h_f(e(s)) = h_1 (e(s)) = 1$). If $u: S \to X$ is a function such that $e = f \circ u$, then $e(s) = f(u(s))$. Since $f$ is injective $u$ is uniquely defined by sending $s$ to $f^{-1}(e(s))$ (it is well-defined since we already show that $e(S) \subseteq f(X)$). If $u$ is continuous, then we have $f$ as the equalizer between $h_1$ and $h_f$ (in simple term, $f$ is a regular monomorphism). If $W$ is open in $X$, then
\begin{enumerate}
    \item $f(W) = O \cap f(X)$ for some open set $O$ in $Y$.
    \item $e^{-1}(f(W)) = e^{-1}(O)$ is open in $S$.
    \item $u^{-1}(W) = \{ s \in S : u(s) \in W \} = \{ s \in S : f^{-1}(e(s)) \in W \} = \{ s \in S : e(s) \in f(W) \} = e^{-1}(f(W))$ which is also open in $S$ by the previous point.
\end{enumerate}
\end{proof}

\subsection{Deleted Limit}
Let $X$ be a topological space, $p$ be a point in $X$, and $\mathcal{B}$ be a filter base converging to $p$. We can then talked about the deleted filter base $\tilde{\mathcal{B}} = \{ B \setminus \{ p \} : \}$ on the subspace $X \setminus \{ p \}$. We will assume from now on that $B \setminus \{ p \}$ is non-empty for all $B \in \mathcal{B}$.
\begin{remark} \ 
\begin{enumerate}
    \item $\tilde{\mathcal{B}}$ also converges to $p$
    \item If $\mathcal{B} = \mathcal{N}_p$ is the neighborhood filter at $p$, then $\tilde{\mathcal{N}_p}$ is a non-trivial filter base (in fact, a filter) exactly when $p$ is a limit point of $X$.
\end{enumerate}
\end{remark}
\begin{proof}
\underline{Part 1:} straight from $B \setminus \{ p \} \subseteq B$, so $\tilde{\mathcal{B}}$ refines $\mathcal{B}$.
\\
\underline{Part 2:} $\tilde{\mathcal{N}_p}$ is non-trivial if and only if $N \setminus \{ p \} \neq \varnothing$ for all neighborhood $N$ of $p$. Equivalently, $N \cap X = N$ contains another point different from $p$. This, by definition, shows that $p$ is a limit point of $X$.
\end{proof}
Given a function $f: X \setminus \{ p \} \to Y$, then a deleted limit at $p$ with respect to $\mathcal{B}$ is an element of $\lim_{\tilde{\mathcal{B}} \to p} f(\tilde{\mathcal{B}})$.
\begin{proposition}
If $f: X \setminus \{ p \} \to Y$ is continuous, and $g: X \to Y$ is a \emph{continuous extension} of $f$ to the whole space (i.e. $g$ is continuous and $g(x) = f(x)$ for all $x \neq p$), then $g(p)$ is a deleted limit of $f$ at $p$ (with respect to the neighborhood filter $\mathcal{N}_p$).
\end{proposition}
\begin{proof}
Let $N$ be a neighborhood of $g(p)$, then $g^{-1}(N)$ is a neighborhood of $p$, or $g^{-1}(N) \setminus \{ p \}$ is the deleted neighborhood of $p$. But $g^{-1}(N) \setminus \{ p \} \in \tilde{\mathcal{N}_p}$, and $N$ is arbitrary, so we conclude that $g(p) \in \lim_{\tilde{\mathcal{N}_p} \to p} f(\tilde{\mathcal{N}_p})$.
\end{proof}
\begin{remark}
When the deleted limit is unique, such (continuous) extension will be unique, as long as it exists. We will discuss later whether such extension exists.
\end{remark}

\newpage

\section{Product topology}
To prevent degenerate case, we assume axiom of choice for the product to be non-empty. Given a family $\{ X_i \}_{i \in I}$ of topological spaces, there are 2 topologies on the product $\prod_{i \in I} X_i$
\begin{enumerate}
    \item The product topology, generated by $\pi_i^{-1} (U_i)$ for $U_i$ open in $X_i$ and $i \in I$. Here $\pi_i : \prod_{i \in I} X_i \to X_i$ is the projection onto the $i$-th coordinate.
    \item The box topology, with the basis consists of $\prod_{i \in I} U_i$ where each $U_i$ is open in $X_i$.
\end{enumerate}
\begin{remark}
The collection described in the box topology is indeed a basis.
\end{remark}
\begin{proof}
This follows from $\prod_{i \in I} A_i \cap \prod_{i \in I} B_i = \prod_{i \in I} A_i \cap B_i$ (and any topology is closed under finite intersection).
\end{proof}
\begin{proposition} \ 
\begin{enumerate}
    \item The box topology is finer the product topology.
    \item They are equal if and only if cofinitely many $X_i$ is indiscrete. In particular, this holds when the product is finite.
    \item The product of indiscrete spaces is indiscrete in either topologies. The product of discrete spaces is discrete in box topology (but not product topology necessarily if the product is infinite).
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} since $\pi_i^{-1}(U_i)$ is just product of $X_j$ ($j \neq i$) and $U_i$, and $X_j$ is already open, $\pi_i^{-1}(U_i)$ is open in the box topology. By minimality, the product topology is coarser than the box topology.
\\
\underline{Part 2:} suppose cofinitely many $X_i$ is indiscrete, we denote $J = \{ i \in I : X_i \mbox{ is indiscrete } \}$, and relabel $I \setminus J = \{ 1, 2, \hdots, n \}$ . Thus, each \textit{non-empty} $\prod_{i \in I} U_i$ ($U_i$ is open in $X_i$) turns into $\prod_{j \in J} X_j \times \prod_{k = 1}^n U_k$. This coincides with $\bigcap_{k = 1}^n \pi_k^{-1}(U_k)$, and so every basic open set in the box topology is also open in the product topology. By \hyperref[topo-compare-basis]{Lemma \ref*{topo-compare-basis}}, the box topology is coarser than the product topology. Combining part (1), we get the box topology is the same as the product topology.
\\
\\
Vice versa, suppose infinitely many $X_i$ is not indiscrete. We can then pick non-empty $U_i$ open in $X_i$ such that $U_i \neq X_i$ infinitely many $i \in I$. If the box topology is the same as the product topology, there must exists some $V_{i_k} \in X_{i_k}$, $1 \leq k \leq n$, such that $\bigcap_{k = 1}^n \pi_{i_k}^{-1} (V_{i_k}) = \prod_{j \neq i_k} X_j \times \prod_{k = 1}^n V_{i_k} \subseteq \prod_{i \in I} U_i$ (recall \hyperref[topo-gen-steps]{Theorem \ref*{topo-gen-steps}}). Since $U_i \neq X_i$ for infintiely many $i \in I$, we can pick $j \in I \setminus \{ i_1, i_2, \hdots, i_n \}$ such that $U_j \neq X_j$. Yet, looking at index $j$, we can see $X_j$ is not a subset of $U_j$, a contradiction.
\\
\underline{Part 3:} since the only non-empty open set in $X_i$ is $X_i$, the only non-empty open set in $\prod_{i \in I} X_i$ is the space itself.
\\
\\
If $X_i$ is discrete for each $i \in I$: since $\{ p_i \}$ is open in $X_i$, $\{ (p_i)_{i \in I} \}$ is also open. We conclude that $\prod_{i \in I} X_i$, with box topology, is discrete.
\end{proof}
\begin{proposition}[Universal properties of product topology] \ 
\begin{enumerate}
    \item By definition, the projection maps are continuous with respect to product topology. Since the box topology is finer than the product topology, the maps are also continuous with respect to box topology
    \item The product topology is the unique topology such that
    \begin{enumerate}
        \item $\pi_i$ is continuous for each $i \in I$.
        \item If $f_i : Y \to X_i$ is continuous for each $i \in I$, then there exists a unique continuous map $f: Y \to \prod_{i \in I} X_i$ such that $f_i = \pi_i \circ f$. We write $f = (f_i)_{i \in I}$.
    \end{enumerate}
    In categorical terms, product topology on $\prod_{i \in I} X_i$ is the categorical product of $X_i$.
    \item The product topology is the smallest topology such that $\pi_i$ is continuous for all $i \in I$.
\end{enumerate}
\end{proposition}
\begin{proof} \ \\
\underline{Part 2:} we already know $\pi_i$ is continuous in part (1). Given $f_i: Y \to X_i$, if $f: \prod_{i \in I} X_i \to Y$ is such that $f_i = \pi_i \circ f$ for all $i \in I$, then $f_i (y) = \pi_i (f(y))$. In other words, $f(y) = (f_i(y))_{i \in I}$, so $f$ is uniquely defined. We just need to show $f$ is continuous. Note that $f^{-1}(\pi_i^{-1}(U_i)) = (\pi_i \circ f)^{-1}(U_i) = f_i^{-1}(U_i)$ is continuous for all $U_i$ open in $X_i$ and $i \in I$. By \hyperref[cont-gen-equiv-def]{Proposition \ref*{cont-gen-equiv-def}}, $f$ is continuous.
\\
\\
Now, suppose $\mathcal{T}$ is a topology on $\prod_{i \in I}$ satisfies those conditions. Then $\pi_i^{-1}(U_i) \in \mathcal{T}$ for all $U_i$ open in $X_i$ and $i \in I$. By minimality, $\mathcal{T}$ contains the product topology. On the other hand, let $f_i$ be the projection map from $\prod_{i \in I} X_i$ to $X_i$ (with respect to product topology). They are continuous so the identity map $\operatorname{id}_X : \prod_{i \in I} X_i \to (\prod_{i \in I} X_i, \mathcal{T})$ (note $f_i = \operatorname{id}_X \circ \pi_i$) is also continuous. By \hyperref[comp-topo-cont]{Proposition \ref*{comp-topo-cont}}, the product topology contains $\mathcal{T}$, so they must be equal.
\\
\underline{Part 3:} follows from the uniqueness proof of part (2).
\end{proof}
\underline{Note:} from now on, when we mention product space, we will use the product topology on it by default.

\begin{shaded}
\begin{proposition}[Basic properties] \ 
\begin{enumerate}
    \item If $C_i$ is closed in $X_i$, then $\prod_{i \in I} C_i$ is closed in $\prod_{i \in I} X_i$ with respect to both box and product topologies.
    \item If $\mathcal{T}_i \subseteq \mathcal{S}_i$ are topologies on $X_i$, and $\mathcal{T}, \mathcal{S}$ are respectively the product topologies on $\prod_{i \in I} (X_i, \mathcal{T}_i), \prod_{i \in I} (X_i, \mathcal{S}_i)$, then $\mathcal{T} \subseteq \mathcal{S}$. Same for the box topology.
    \item If $\mathcal{B}_i$ is a basis of $X_i$, then $\prod_{i \in I} \mathcal{B}_i$ is a basis for the box topology on $\prod_{i \in I} X_i$.
    \item If $\mathcal{A}_i$ generates the topology on $X_i$ for each $i \in I$, then
    \begin{enumerate}
        \item $\{ \pi_i^{-1} (A_i) : A_i \in \mathcal{A}_i, i \in I \}$ generates the product topology on $\prod_{i \in I} X_i$.
        \item $\prod_{i \in I} \mathcal{A}_i$ generates the box topology on $\prod_{i \in I} X_i$.
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} since $\pi_i$ is continuous (in product topology), $\pi_i^{-1}(C_i)$ is closed in $\prod_{i \in I} X_i$ (with product topology). Intersection of a family of closed sets is still closed, so $\prod_{i \in I} C_i = \bigcap_{i \in I} \pi_i^{-1}(C_i)$ is closed in product topology. It is thus also closed in box topology as the box topology is finer than the product topology.
\\
\\
\underline{Part 2:} we first show the inclusion for product topologies. A basic open set in $(\prod_{i \in I} X_i, \mathcal{T})$ is of the form $\bigcap_{k = 1}^n \pi_{i_k}^{-1}(U_{i_k})$ for some $i_k \in I$ and $U_{i_k} \in \mathcal{T}_{i_k}$. Since $\mathcal{T}_i \subseteq \mathcal{S}_i$ for all $i \in I$, we thus have $\bigcap_{k = 1}^n \pi_{i_k}^{-1}(U_{i_k}) \in \mathcal{S}$. By \hyperref[topo-compare-basis]{Lemma \ref*{topo-compare-basis}}, $\mathcal{T} \subseteq \mathcal{S}$.
\\
\\
As for box topologies, it is even more straightforward. A basic open set in $\mathcal{T}$ is of the form $\prod_{i \in I} U_i$ where $U_i \in \mathcal{T}_i$ for each $i \in I$. Since $\mathcal{T}_i \subseteq \mathcal{S}_i$, we get $\prod_{i \in I} U_i \in \mathcal{S}$. By the same \hyperref[topo-compare-basis]{Lemma \ref*{topo-compare-basis}}, we conclude $\mathcal{T} \subseteq \mathcal{S}$.
\\
\\
\underline{Part 3:} if $V$ is an open set of $\prod_{i \in I} X_i$, and $(x_i)_{i \in I} \in V$, then by definition of box topology, there exists some open set $U_i$ in $X_i$ for each $i \in I$ such that $(x_i)_{i \in I} \in \prod_{i \in I} U_i \subseteq V$. In particular $x_i \in U_i$. Since $\mathcal{B}_i$ is a basis of $X_i$, there also exists $B_i \in \mathcal{B}_i$ such that $x_i \in B_i \subseteq  U_i$. We then have $(x_i)_{i \in I} \in \prod_{i \in I} B_i \subseteq \prod_{i \in I} U_i \subseteq V$. As $x$ and $V$ varies, $\prod_{i \in I} \mathcal{B}_i$ is a basis of the box topology on $\prod_{i \in I} X_i$.
\\
\\
\underline{Part 4:}
\begin{enumerate}[label = (\alph*)]
    \item Since any set in $\mathcal{A}_i$ is open in $X_i$, the inverse of it is open in $\prod_{i \in I} X_i$ (with respect to the product topology). Given any topology $\mathcal{T}$ on $\prod_{i \in I} X_i$ containing every $\pi_i^{-1}(A_i)$ for $A_i \in \mathcal{A}_i$ and $i \in I$, we need to show that it also contains $\pi_i^{-1}(U_i)$ for every open set $U_i$ in $X_i$, and for all $i \in I$. By \hyperref[topo-gen-steps]{Theorem \ref*{topo-gen-steps}}, for each $U_i \in X_i$, there exists a family $\{ \mathcal{F}_\lambda \}_{\lambda \in L}$ of finite families of sets in $\mathcal{A}_i$ such that $U_i = \bigcup_{\lambda \in L} \bigcap \mathcal{F}_\lambda$. Since inverse image preserves union and intersection, we get $\pi_i^{-1}(U_i) = \bigcup_{\lambda \in L} \bigcap_{A \in \mathcal{F}_\lambda} \pi_i^{-1}(A)$. By assumption, $\pi_i^{-1}(A) \in \mathcal{T}$ for each $A \in \mathcal{F}_\lambda$ and $\lambda \in L$. But $\mathcal{T}$ is a topology, so we must have $\bigcap_{A \in \mathcal{F}_\lambda} \pi_i^{-1}(A) \in \mathcal{T}$ (as $\mathcal{F}_\lambda$ is finite) for each $\lambda \in L$, and so $\pi_i^{-1}(U_i) \in \mathcal{T}$. Hence, $\mathcal{T}$ contains the product topology, and by definition, the topology generated by $\{ \pi_i^{-1}(A_i) : A_i \in \mathcal{A}_i, i \in I \}$ is the same as the product topology.
\end{enumerate}

\end{proof}
\begin{proposition}[Operator properties] \ 
\begin{enumerate}
    \item Denote $X = \prod_{i \in I} X_i$
    \begin{enumerate}
        \item If we use the box topology, then $\operatorname{int}_X \left( \prod_{i \in I} A_i \right) = \prod_{i \in I} \operatorname{int}_{X_i} (A_i)$.
        \item If we use the product topology, and $J = \{ i \in I : A_i \neq X_i \}$, then
        \begin{enumerate}
            \item $\operatorname{int}_X \left( \prod_{i \in I} A_i \right) = \varnothing$ if $J$ is infinite.
            \item $\operatorname{int}_X \left( \prod_{i \in I} A_i \right) = \prod_{i \in I \setminus J} X_i \times \prod_{j \in J} \operatorname{int}_{X_j} (A_j)$ if $J$ is finite.
        \end{enumerate}
    \end{enumerate}
    \item $\operatorname{cl}_X \left( \prod_{i \in I} A_i \right) = \prod_{i \in I} \operatorname{cl}_{X_i} (A_i)$ with respect to both box and product topologies.
    \\
    \\
    As a result, if $A_i$ is dense in $X_i$ for each $i \in I$, then $\prod_{i \in I} A_i$ is dense in $\prod_{i \in I} X_i$.
    \item $\operatorname{ext}_X \left( \prod_{i \in I} A_i \right) = \bigcup_{i \in I} \left[ \prod_{j \neq i} X_j \times \operatorname{ext}_{X_i} (A_i) \right]$ with respect to both box and product topologies.
    \item Limit point
    \item Isolated point
    \item Density
    \item Regular
    \item Discrete/Dense-in-itself/Perfect
\end{enumerate}
\end{proposition}
\begin{proposition}[Functional properties] \ 
\begin{enumerate}
    \item Convergence
    \item Continuity
\end{enumerate}
\end{proposition}
\begin{proposition}[Lexicographical vs. Box]
If $\{ X_i \}_{i \in I}$ is an well-ordered family of ordered sets, then the order topology on $\prod_{i \in I} X_i$ (with respect to the lexicographical ordering) is finer than the box topology.
\end{proposition}
\begin{proposition}[Maximum and minimum are continuous]
If $X$ is a linearly ordered set, and $X \times X$ is endowed with product topology, then the maximum function $\max : X \times X \to X$ and the minimum function $\min : X \times X \to X$ are continuous.
\end{proposition}

\subsection{The topology of pointwise convergence}
\begin{theorem}
Let $X$ be a set, and $S$ be the SierpiÅski space. We endow the set of functions $S^X$ with the topology of pointwise convergence. Then given any directed family of subsets $\{ A_i \}_{i \in I}$
\begin{enumerate}
    \item If $A = \lim_{i \in I} A_i$ exists, then $1_A$ is the limit of $(1_{A_i})_{i \in I}$ in $S^X$. Here, $1_A: X \to S$ is the indicator function of $A$: $1_A (x) = 1$ iff $x \in A$.
    \item If $f = \lim_{i \in I} 1_{A_i}$ in $S^X$, then $f = 1_A$ and $A = \lim_{i \in I} A_i$ (where $A = f^{-1}(1)$).
\end{enumerate}
\end{theorem}

\newpage

\section{Initial Topology}

\section{Cauchy spaces}
\begin{theorem}
If $f: \omega_\alpha \to M$ is a continuous function between an ordinal (with $\alpha \geq 1$) and a metric space $M$, then it is eventually constant
\end{theorem}

\section{Hypertopology}
Topology of pointwise convergence, Fell topology, Vietoris topology, Hausdorff metric, Wijsman convergence

\section{Separation Axiom}
\subsection{Hausdorff space}
\begin{theorem}[Closed map lemma]
If $f: X \to Y$ is a continuous map from a compact space $X$ to a Hausdorff space $Y$, then $f$ is closed and proper.
\end{theorem}
\begin{proposition}
The epimorphisms in the category of Hausdorff spaces are exactly the dominant maps (instead of surjections).
\end{proposition}

\section{Axiom of Countability}
{[Reference: \hyperref[https://en.wikipedia.org/wiki/Set-theoretic_topology]{Set-Theoretic Topology}]}
\begin{remark}
If there is only finitely many open neighborhood at $p$, then the character of $X$ at $p$ is 1.
\end{remark}
\begin{proposition}
Let $L$ be a totally ordered space, and $X$ be a topological space such that the cofinality of $L$ is strictly larger than the character of $X$, then every convergent sequence $(x_i)_{i \in L}$ in $X$ is eventually constant.
\end{proposition}
\begin{remark}
In a sense, only countably infinite sequences in $\mathbb{R}$ are of considerable interest, otherwise, we get sequences that are eventually constant.
\end{remark}

\section{Connectedness}
A function $f: X \to Y$ is \emph{locally constant} if $f$ is

\section{Convergent series \& Integral}
\subsection{Unconditional convergence}
Let $(a_i)_{i \in I}$ be a family of points in a topological abelian group $G$, and define
\begin{enumerate}
	\item $[I]^{< \omega}$ is the collection of all finite subsets of $I$.
	\item $a_\Sigma: [I]^{< \omega} \to G$ is the summation net (of $(a_i)_{i \in I}$)
	$$a_\Sigma (S) = \sum_{i \in S} a_i$$
\end{enumerate}
We say that the series $\sum_{i \in I} a_i$ \emph{converge unconditionally} to $b$ if the net $a_\Sigma$ converges to $b$.

\subsection{Directed convergence}
Suppose $(g_\alpha)_{\alpha < \kappa}$ is a transfinite sequence of elements in a Hausdorff topological abelian group $G$. We then construct another transfinite sequence $g_\Omega : \kappa \to G$, called the sequence of \emph{partial sums}
\begin{enumerate}
	\item $g_\Omega (0) = g_0$.
	\item $g_\Omega (\alpha + 1) = g_\Omega (\alpha) + g_{\alpha + 1}$.
	\item If $\lambda$ is a limit ordinal, $g_\Omega (\lambda) = \lim_{\alpha < \lambda} g_\Omega (\alpha)$.
\end{enumerate}
We say that the series $\sum_{\alpha < \kappa} g_\alpha$ \emph{converges (conditionally)} to $h$ if $g_\Omega \to h$.

\newpage
\newpage

\chapter{Mathematical Analysis I}
\begin{theorem}[Silverman-Toeplitz theorem] \end{theorem}
\ \\
\begin{theorem}[\href{http://www.math.ncku.edu.tw/~rchen/Advanced\%20Calculus/Lebesgue\%20Criterion\%20for\%20Riemann\%20Integrability.pdf}{Lebesgue criterion for Riemann integrability}]
$f: [a, b] \to \mathbb{R}$ is Riemann integrable if the set of discontinuities is of Lebesgue measure 0.
\end{theorem}
\ \\
\begin{theorem}[Lebesgue differentiation theorem]
Let $f$ be a locally integrable real or complex-valued function on $\mathbb{R}^n$, then for almost every point $x \in \mathbb{R}^n$, we get
\begin{align*}
\lim_{U \to x} \frac{1}{\lambda(U)} \int_U f d \lambda = f(x)
\end{align*}
where the limit is taken over the open neighborhoods of $x$, and $\lambda$ is the Lebesgue measure on $\mathbb{R}^n$. In fact, since
\begin{align*}
\left| \frac{1}{\lambda(U)} \int_U f d \lambda - f(x) \right| \leq \frac{1}{\lambda(U)} \int_U |f(t) - f(x)| d \lambda(t)
\end{align*}
A stronger statement holds: that the RHS tends to $0$.
\end{theorem}
\ \\
\begin{theorem}[Existence of FHK integral]
Let $F: U \subseteq X \to L(X, Y)$ be a continuous function such that $U$ is an open subset of the normed space $X$, and $L(X, Y)$ is the space of continuous linear map. Let $\gamma: [a, b] \to U$ be a rectifiable curve (i.e. continuous with finite length). Then the Frechet-Henstock-Kurzweil (FHK) integral exists.
\end{theorem}
\begin{theorem}[First Fundamental Theorem of Banach Calculus]
Suppose $F: U \subseteq X \to L(X, Y)$ is a FHK integrable function such that
\begin{enumerate}
    \item $U$ is an open subset of a normed space $X$, and $Y$ is Banach.
    \item For any rectifiable loop in $U$, the FHK integral of $F$ is $0$.
\end{enumerate}
Then there exists some continuous map $f: U \to Y$ such that $F = df$.
\end{theorem}
\begin{theorem}[Second Fundamental Theorem of Banach Calculus]
If $f: U \subseteq X \to Y$ is a differentiable function between an open set $U$ of a normed space $X$, and a Banach space $Y$, then
\begin{align*}
    \int_\gamma df = f(\gamma(b)) - f(\gamma(a))
\end{align*}
for any rectifiable curve $\gamma: [a, b] \to U$.
\end{theorem}

\subsection{Curl}
We assume from now on that $V, W$ are normed spaces, $W$ is Banach, and $U$ is an open subset of $V$. We also denote $L(V, W)$ to be the space of continuous linear map from $X$ to $Y$ (which is Banach given $Y$ is Banach).
\\
\\
Given $F: U \subseteq V \to L(V, W)$ a continuous function, we say that $F$ is \emph{Frechet-curlable} at $p \in U$ if there exists a multilinear map $T: V \times V \to W$ such that
\begin{align*}
\lim_{h, k \to 0} \frac{\left\lVert \int_{\gamma_p (h, k)} F - T(h, k) \right\rVert}{\left\lVert h \right\rVert \cdot \left\lVert k \right\rVert} = 0
\end{align*}
where $\gamma_p (h, k)$ is the loop consisting of 4 line segments: $p \to p + h$, $p + h \to p + h + k$, $p + h + k \to p + k$, and $p + k \to p$. We then denote $K = (\operatorname{curl} F)_p$.
\begin{theorem}
If $F$ is Frechet differentiable at $p$, then it is curlable at $p$, and $(\operatorname{curl} F)_p (u, v) = dF_p (u, v) - dF_p (v, u)$. In other words, the curl of $F$ at $p$ is the alternization of the differential of $F$ at $p$.
\end{theorem}
\begin{corollary}
The curl is always an alternating map.
\end{corollary}
\begin{theorem}[Exterior Derivative]
If $F$ is the Frechet derivative of another map $f: U \subseteq V \to W$, then it is curlable on $U$, and $\operatorname{curl} F = 0$ (or $(\operatorname{curl} F)_p = 0$ for all $p \in U$). In short form, $\operatorname{curl} \circ d = 0$.
\end{theorem}
\begin{proof}
Follows directly from the definition and the fundamental theorem of Banach calculus.
\end{proof}
\begin{theorem}[Exactness]
If the curl of $F$ is $0$ at every point in $U$, then there exists some Frechet differentiable $f: U \to W$ such that $F = df$.
\end{theorem}
Let $F: U \to L(V, L(V, W))$ be continuous, which can also be interpreted as $F: U \to L^2 (V, W)$, where $L^2(V, W)$ is the space of continuous multilinear maps $V \times V \to W$. If $\varphi: [0, 1]^2 \to U$ is a surface in $U$ (i.e. a continuous map), we say that $F$ is FHK integrable to $\varphi$ if there exists some $w_0 \in W$ such that, for all $\varepsilon > 0$, there exists some gauges $\delta_1$ and $\delta_2$ so that
\begin{align*}
& \left \lVert S(F, \mathcal{P}_1 \times \mathcal{P}_2) -  w_0 \right\rVert
\\
& \qquad = \left \lVert \sum_{i = 0}^{n - 1} \sum_{j = 0}^{m - 1} F(\varphi(t_i, s_j))(\varphi(x_{i + 1}, s_j) - \varphi(x_{i}, s_j), \varphi(t_i, y_{j + 1}) - \varphi(t_i, y_{j}))  - w_0 \right\rVert
\\
& \qquad < \varepsilon
\end{align*}
whenever $\mathcal{P}_1 = \{ x_0 = 0 < t_0 < x_1 < \cdots < x_{n - 1} < t_{n - 1} < x_n = 1 \}$ is a tagged $\delta_1$-fine partition, and $\mathcal{P}_2 = \{ y_0 = 0 < s_0 < y_1 < \cdots < y_{m - 1} < s_{m - 1} < y_m = 1 \}$ is a tagged $\delta_2$-fine partition on $[0, 1]$. If so, we denote $w_0 = \iint_\varphi F$.
\begin{theorem}[Stokes-Banach Theorem]
Suppose $F: U \subset V \to L(V, W)$ is curlable on $U$ (i.e. curlable at every point in $U$), then
\begin{align*}
\iint_\varphi \operatorname{curl} F = \int_{\partial\varphi} F
\end{align*}
where $\partial \varphi: [0, 4] \to U$  is defined by
\begin{align*}
(\partial \varphi) (t) = \begin{cases}
    \varphi(0, t) & \mbox{ if } 0 \leq t \leq 1 \\
    \varphi(t - 1, 1) & \mbox{ if } 1 \leq t \leq 2 \\
    \varphi(1, 3 - t) & \mbox{ if } 2 \leq t \leq 3 \\
    \varphi(4 - t, 0) & \mbox{ if } 3 \leq t \leq 4
\end{cases}
\end{align*}
\end{theorem}


\newpage
\newpage

\chapter{Mathematical Logic II}
\section{Deductive system}
\begin{definition}
Let $L$ be a formal language over an alphabet $\Sigma$. In logic, every word in $L$ is said to be a \emph{statement} (or \emph{sentence}).
\end{definition}
\begin{definition}
If $\Lambda$ is a \textit{non-empty} subset of $L$, $\varphi$ is a statement in $L$, the pair $(\Lambda, \varphi)$ is called a \emph{rule} in $L$. In this case, statements in $\Lambda$ are considered to be the \emph{premises}, while $\varphi$ is considered to be the \emph{conclusion} of the rule.
\end{definition}
Note that such rule is an element of $(\mathcal{P}(L) \setminus \{ \varnothing \}) \times L$
\begin{definition}
Given a set $R$ of rules, we say a subset $\Delta$ of $L$ is \emph{closed under application of rules} in $R$ (or \emph{$R$-closed}) if, whenever $(\Lambda, \varphi) \in R$ such that $\Lambda \subseteq \Delta$, we must have $\varphi \in \Delta$.
\end{definition}
\begin{proposition} \label{logic-ent-prop}\ 
\begin{enumerate}
    \item The whole language $L$ and the empty set $\varnothing$ are $R$-closed.
    \item Intersections of $R$-closed sets is another $R$-closed sets.
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} for $L$, $\varphi \in L$ always holds, so $L$ is $R$-closed vacuously. For the empty set, note that the premises of any rule is always non-empty, so $\Lambda \subseteq \varnothing$ is always false (whenever $(\Lambda, \varphi) \in R$), and thus, $\varnothing$ is also $R$-closed vacuously.
\\
\underline{Part 2:} suppose $\{ \Delta_i \}_{i \in I}$ is a family of $R$-closed sets, let $\Theta = \bigcap_{i \in I} \Delta_i$. Given $(\Lambda, \varphi) \in R$, if $\Lambda \subseteq \Theta$, then $\Lambda \subseteq \Delta_i$ for all $i \in I$. By definition, $\varphi \in \Delta_i$, and so $\varphi \in \Theta$. We conclude that $\Theta$ is closed under application of rules in $R$.
\end{proof}
\begin{definition}
Given $\Gamma \subseteq L$, the set of statements \emph{syntactically entailed} from $\Gamma$ under $R$ is defined to be the smallest subset of $L$ such that it contains $\Gamma$ as a subset and it is closed under application of rules in $R$.
\end{definition}
\begin{remark}
Since $L$ is $R$-closed, such set exists, and it is the intersection of all $\Delta \subseteq L$ such that $\Gamma \subseteq \Delta$ and $\Delta$ is $R$-closed (\hyperref[logic-ent-prop]{Proposition \ref*{logic-ent-prop}}).
\end{remark}
If $\varphi$ is \emph{derivable} from $\Gamma$ (under $R$), then we denote $\Gamma \vdash_R \varphi$. If $\Gamma \vdash_R \varphi$ for all $\varphi \in \Delta$, then we succinctly denote $\Gamma \vdash_R \Delta$.
\begin{remark}
$\vdash_R$ is a binary relation on subsets of $L$, with the convention
\begin{enumerate}
    \item $\Gamma \vdash_R \varnothing$ for any $\Gamma \subseteq L$.
    \item $\varnothing \vdash_R \Gamma$ if and only if $\Gamma$ is empty.
\end{enumerate}
\end{remark}
Regarding the simplification of some notations
\begin{enumerate}
    \item If $\Gamma \cup \Pi \vdash_R \Delta \cup \Omega$, we can alternatively write $\Gamma, \Pi \vdash_R \Delta, \Omega$ for simplicity.
    \item If there are finitely many premises (or conclusions), say $\{ \alpha_i : 1 \leq i \leq n \} \vdash_R \{ \beta_j : 1 \leq j \leq m \}$, we can instead write
    \begin{align*}
        \alpha_1, \alpha_2, \hdots, \alpha_n \vdash_R \beta_1, \beta_2, \hdots, \beta_m
    \end{align*}
\end{enumerate}
\begin{proposition} \ 
\begin{enumerate}
    \item Monotone (on the left): if $\Gamma \vdash_R \Delta$ and $\Gamma \subseteq \Gamma'$, then $\Gamma' \vdash_R \Delta$.
    \item Antitone (on the right): if $\Gamma \vdash_R \Delta$ and $\Delta \supseteq \Delta'$, then $\Gamma \vdash_R \Delta'$.
    \item Montone (in the middle): if $\Gamma \vdash_R \Delta$ and $R \subseteq R'$, then $\Gamma \vdash_{R'} \Delta$
    \item Reflexive: $\Gamma \vdash_R \Gamma$.
    \item Transitive: if $\Gamma \vdash_R \Delta$ and $\Delta \vdash_R \Pi$, then $\Gamma \vdash_R \Pi$.
    \item Gentzen cut-elimination: if $\Gamma \vdash_R A, \Delta$ and $\Pi, A \vdash_R \Omega$, then $\Gamma, \Pi \vdash_R \Delta, \Omega$.
\end{enumerate}
\end{proposition}
\ \\
\begin{definition}
A \emph{deductive system} $\mathcal{S}$ (over $L$) is a pair $(\Omega, R)$ where
\begin{enumerate}
    \item $\Omega$ is a set of statements in $L$, called \emph{axioms} of $\mathcal{S}$ (or \emph{laws} in logic).
    \item $R$ is a collection of pairs $(\Lambda, \varphi)$ (where $\Lambda$ is a non-empty subset of $L$ and $\varphi$ is a statement in $L$), called \emph{inference rules} of $\mathcal{S}$.
\end{enumerate}
\end{definition}
\begin{definition}
With respect to $\mathcal{S}$, we define $\Gamma \vdash_{\mathcal{S}} \varphi$ ($\Gamma$ semantically entails $\varphi$ relative to $\mathcal{S}$) iff $\Gamma, \Omega \vdash_R \varphi$.
\end{definition}
\begin{definition}
A formal system $\mathcal{S}$ is \emph{finitary} if there is only finitely many premises for each inference rule. Otherwise, we say $\mathcal{S}$ is \emph{infinitary}.
\end{definition}

\newpage

\section{Formal proof}
A \emph{proof} (or \emph{derivation}) of a statement $\varphi$ from $\Gamma$ is represented by an inverted tree, with each node consists of a single statement, such that
\begin{enumerate}
    \item The root (at the bottom) is $\varphi$.
    \item For each node $\gamma$
    \begin{enumerate}
        \item If it is a leaf (i.e. no children): then $\gamma$ is either an axiom of $\mathcal{S}$ or is in $\Gamma$.
        \item Otherwise, $\gamma$ is the conclusion of an inference rule in $\mathcal{S}$, with the premises to be the node's children.
    \end{enumerate}
\end{enumerate}
\begin{remark} \ 
\begin{enumerate}
    \item Such tree only has finite height since there are only finitely many applications of inference rules before we reach the conclusion $\varphi$. That is the basis of inductive definition/construction.
    \item Hence, if the system $\mathcal{S}$ is finitary, then a proof tree has finitely many nodes. Using post-order traversal (where immediate children of a node are visited before their parent), such tree can be transformed into a sequence of statements $(\gamma_1, \gamma_2, \hdots, \gamma_n = \varphi)$ where, for each $\gamma_i$, either
    \begin{enumerate}
        \item $\gamma_i$ is an axiom of $\mathcal{S}$.
        \item $\gamma_i$ belongs to $\Gamma$.
        \item $\gamma_i$ is the conclusion of some inference rule, with the premises to be those among previous $\gamma_j$ ($j < i$). 
    \end{enumerate}
    \item Compactness: as a result, if $\mathcal{S}$ is finitary, and $\Gamma \vdash_{\mathcal{S}} \varphi$, then there exists a finite subcollection $\Delta$ of $\Gamma$ such that $\Delta \vdash_{\mathcal{S}} \varphi$. In fact, this precisly characterizes the finitary property of a deductive system.
\end{enumerate}
\end{remark}
\begin{proposition} \label{logic-ent-props} \ 
\begin{enumerate}
    \item If $(\Gamma, \varphi)$ is an inference rule in $\mathcal{S}$, then $\Gamma \vdash_\mathcal{S} \varphi$. If $\varphi$ is an axiom of $\mathcal{S}$, then it is a theorem of $\mathcal{S}$.
    \item Monotonicity: if $\Delta$ contains all the statements in $\Gamma$, and $\Gamma$ (syntactically) entails $\varphi$ (relative to $\mathcal{S}$), then $\Delta$ also entails $\varphi$. In particular $\Gamma \vdash_{\mathcal{S}} \varphi$ whenever $\varphi$ is a theorem of $\mathcal{S}$
    \item Preordering:
    \begin{enumerate}
        \item $\Gamma \vdash_{\mathcal{S}} \Gamma$
        \item If $\Gamma \vdash_\mathcal{S} \Delta$ and $\Delta \vdash_{\mathcal{S}} \Theta$, then $\Gamma \vdash_{\mathcal{S}} \Theta$.
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} since $\varphi$ is the conclusion of $\Gamma$ through the inference rule $(\Gamma, \varphi)$, and $\Gamma \vdash_{\mathcal{S}} \gamma$ for all $\gamma \in \Gamma$ (\hyperref[logic-ent-hyp]{2nd condition}), we get $\Gamma \vdash_{\mathcal{S}} \varphi$ (\hyperref[logic-ent-rule]{3rd condition}).
\\
\underline{Part 2:} if $\Gamma \vdash_{\mathcal{S}} \varphi$, then there exists a proof tree of it. The leaves are either axioms of $\mathcal{S}$ or in $\Gamma$. Since $\Gamma \subseteq \Delta$, each leaf is also either an axiom, or in $\Delta$. Thus, such tree is also a proof for $\Delta \vdash_{\mathcal{S}} \varphi$.
\\
\underline{Part 3:}
\begin{enumerate}[label = (\alph*)]
    \item By definition, $\Gamma \vdash_{\mathcal{S}} \lambda$ for each $\lambda \in \Gamma$, so $\Gamma \vdash_{\mathcal{S}} \Gamma$.
    \item Since $\Delta \vdash_{\mathcal{S}} \theta$, for each $\theta \in \Theta$, there exists a proof tree of $\theta$ with each leaf is either an axiom or in $\Delta$. Since $\Gamma \vdash_{\mathcal{S}} \Delta$ and $\Gamma$ entails every axiom of $\mathcal{S}$, $\Gamma$ entails each leaf of the proof tree. Recursively, we know that $\Gamma$ entails $\theta$.
\end{enumerate}
\end{proof}
\ \\
A formal system $\mathcal{S}$ is said to be \emph{inconsistent} over $L$ if every statement in $L$ is a theorem of $\mathcal{S}$.
\begin{proposition}
$\mathcal{S}$ is inconsistent if and only if $\Gamma \vdash_{\mathcal{S}} \varphi$ for arbitrary $\Gamma$ and $\varphi$.
\end{proposition}
\begin{proof}
If $\mathcal{S}$ is inconsistent, then $\varphi$ is a theorem of $\mathcal{S}$, or $\vdash_{\mathcal{S}} \varphi$. By \hyperref[logic-ent-props]{Proposition \ref*{logic-ent-props}}, $\Gamma \vdash_{\mathcal{S}} \varphi$. Vice versa, if $\Gamma \vdash_{\mathcal{S}} \varphi$ for arbitrary $\Gamma$ and $\varphi$, then $\vdash_{\mathcal{S}} \varphi$ in particular. By definition, $\mathcal{S}$ is inconsistent.
\end{proof}
A consistent system is said to be \emph{maximal} if adding any \textit{new} statement (i.e. not an axiom) to it as an axiom will render the system inconsistent. Equivalently, $\mathcal{S}$ is maximally consistent if $\varphi \vdash_{\mathcal{S}} \psi$ for any 2 statements $\varphi, \psi$ in $L$ such that $\varphi$ is not an axiom of $\mathcal{S}$.
\begin{proposition}
Every theorem in a maximally consistent system is an axiom.
\end{proposition}
\begin{proof}
\end{proof}

\newpage

\section{Interpretation}
With respect to a language $L$, an \emph{interpretation} of $L$ is pair $\mathfrak{I} = (\mathcal{U}, \vDash)$ where
\begin{enumerate}
    \item $\mathcal{U}$ is a collection of \emph{structures}.
    \item $\vDash$ is a relation between structures in $\mathcal{U}$ and statements in $L$: if $M \vDash \varphi$, then we say $M$ \emph{satisfies} $\varphi$.
\end{enumerate}
If $M \vDash \lambda$ for all $\lambda \in \Gamma$, then we can write succinctly $M \vDash \Gamma$. In model theory, we say that $M$ is a \emph{model} for $\Gamma$.
\\
\\
If $M \vDash \varphi$ whenever $M \vDash \Gamma$, we say that $\Gamma$ \emph{semantically entails} $\varphi$, and denote $\Gamma \vDash_\mathfrak{I} \varphi$.
\begin{remark}
If $\Gamma$ is empty, then by convention, we say that $\vDash_\mathfrak{I} \varphi$ whenever $M \vDash \varphi$ for all structure $M$. Such $\varphi$ is called a \emph{tautology} (under $\mathcal{I}$).
\end{remark}
\begin{definition}
A collection $\Gamma$ of statements is \emph{satisfiable} if there exists a model for it, i.e. there exists some structure $M$ such that $M \vDash \Gamma$
\end{definition}
\ \\
Let $M$ be a structures in $\mathcal{U}$, and denote $\operatorname{Thm}_{\mathfrak{I}}(M)$ be the collection of sentences in $L$ that $M$ satisfies.
\begin{enumerate}
    \item If $\operatorname{Thm}_{\mathfrak{I}}(M) = \operatorname{Thm}_{\mathfrak{I}}(N)$, i.e. $M$ and $N$ satisfies the same sentences, then we say $M$ and $N$ are \emph{elementarily equivalent}.
    \item $\mathfrak{I}$ is nontrivial, if $\operatorname{Thm}_{\mathfrak{I}}(M) \neq L$ for each structure $M$. In simple term, there is always some sentence in $L$ that a structure cannot satisfiable.
\end{enumerate}
\ \\
Let $\Gamma$ be a collection of statements in $L$, and denote $\operatorname{Mod}_\mathfrak{I} (\Gamma)$ be the class of structures that satisfy $\Gamma$. Note that $\Gamma$ is satisfiable if and only if $\operatorname{Mod}_\mathfrak{I} (\Gamma)$ is non-empty.
\begin{enumerate}
    \item $\mathfrak{I}$ is Boolean, if
    \begin{enumerate}
        \item For each $\alpha \in L$ there exists some $\beta \in L$ such that $M \vDash \alpha$ if and only if $M \not\vDash \beta$.
	\item For each $\alpha,\beta \in L$, there exists some $\gamma, \delta \in L$ such that $\operatorname{Mod}_\mathfrak{I} (\gamma) = \operatorname{Mod}_\mathfrak{I} (\alpha) \cap \operatorname{Mod}_\mathfrak{I} (\beta)$ and $\operatorname{Mod}_\mathfrak{I} (\delta) = \operatorname{Mod}_\mathfrak{I} (\alpha) \cup \operatorname{Mod}_\mathfrak{I} (\beta)$.
    \end{enumerate}
	    \item $\mathfrak{I}$ is compact, if $\operatorname{Mod}_\mathfrak{I} (\Gamma) \neq \emptyset$ whenever $\operatorname{Mod}_\mathfrak{I} (\Gamma_0) \neq \emptyset$ for each finite subcollection $\Gamma_0 \subseteq \Gamma$.
    \item $\mathfrak{I}$ is pointwise-satsifiable, if $\operatorname{Mod}_\mathfrak{I}(\varphi)$ is not empty for each statement $\varphi \in L$.
    \item Equivalently, $\mathfrak{I}$ is nontrivial if and only if $\operatorname{Mod}_{\mathfrak{I}}(L) = \emptyset$, that is, there does not exists a structure that satisfies every sentence in $L$.
\end{enumerate}
\begin{remark}
If $\mathfrak{I}$ is pointwise-satsifiable, then $\mathfrak{I}$ is compact if and only if $\mathcal{U}$ is compact, with the topology generated by $\{ \operatorname{Mod}_\mathfrak{I} (\varphi) : \varphi \in L \}$ as closed sets.
\end{remark}

\newpage

\section{Soundness - Completeness}
A formal system $\mathcal{S}$ together with a formal interpretation $\mathfrak{I}$ over the same language $L$ is then called a \emph{formal logic} over $L$.
\\
\\
A formal logic $(\mathcal{S}, \mathfrak{I})$ is called
\begin{enumerate}
    \item \emph{Coherent}, if
    \begin{enumerate}
        \item Every structure of the interpretation satisfies every law of the deductive system.
        \item If $(\Gamma, \varphi)$ is an inference rule, then a structure $M$ satisfies $\varphi$ whenever it satisfies $\Gamma$.
    \end{enumerate}
    \item \emph{Weakly sound}, if $\vDash_{\mathfrak{I}} \varphi$ whenever $\vdash_{\mathcal{S}} \varphi$.
    \item \emph{Sound} (or \emph{strongly sound}), if $\Gamma \vDash_{\mathfrak{I}} \varphi$ whenever $\Gamma \vdash_{\mathcal{S}} \varphi$.
    \item \emph{Weakly complete}, if $\vdash_{\mathcal{S}} \varphi$ whenever $\vDash_{\mathfrak{I}} \varphi$.
    \item \emph{Complete} (or \emph{strongly complete}), if $\Gamma \vdash_{\mathcal{S}} \varphi$ whenever $\Gamma \vDash_{\mathfrak{I}} \varphi$.
    \item \emph{T-complete}, if $\Gamma \vdash_{\mathcal{S}} L$ whenever $\Gamma \vDash_{\mathfrak{I}} L$.
\end{enumerate}
\begin{proposition} \ 
\begin{enumerate}
    \item Coherence implies soundness, which in turn implies weak soundness.
    \item Completeness implies weak completeness and T-completeness
\end{enumerate}
\end{proposition}
\begin{proposition} \ 
\begin{enumerate}
    \item It (the logic) is sound if and only if whenever $\Gamma$ is satisfiable, then it is consistent.
    \item It is complete if and only if whenever $\Gamma$ is satisfiable, then it is consistent.
    \item If it is complete, and the deductive system is finitary, then the interpretation has compactness property.
\end{enumerate}
\end{proposition}

\subsection{Conjunctive Normal Form - Towards the full Completeness Theorem}
\begin{corollary}
If $\Gamma$ is a collection of formulas with finitely many propositional variables involved, and $\Gamma \vDash \varphi$, then $\Gamma \vdash \varphi$.
\end{corollary}
\begin{proof}[Sketch]
Use truth table to selectively pick out rows where some formula in $\Gamma$ is false (if there is none, then $\varphi$ is actually a tautology, and so the theorem reduces to the first completeness theorem). Note that there are only finitely many of them since there are finitely many propositional variable involved in $\Gamma$. From there, we get a proof of the formula (in conjunctive normal form) where $\Gamma$ is false. Use $\varphi \vee \psi, \neg \psi \vdash \varphi$ to show that $\Gamma$ proves the disjunction of rows where every formula in $\Gamma$ holds. A combination of $(\varphi \to \xi) \wedge (\psi \to \xi) \equiv (\varphi \vee \psi) \to \xi$ and $\overline{p_1}, \overline{p_2}, \hdots, \overline{p_n} \vdash \overline{\varphi}$ is then suffice to get a proof of $\varphi$.
\end{proof}
\begin{lemma}
\begin{align*}
\neg (\psi \wedge \lambda) & \vdash \neg \psi
\end{align*}
\end{lemma}
\begin{corollary}
Assuming the weak Konig's lemma, if $\Gamma \vDash \varphi$, then $\Gamma \vdash \varphi$.
\end{corollary}

\newpage

\section{Translation}
\begin{definition}
Let $f: L \to K$ be a translation map between languages (i.e. a function). The translation of a statement $\varphi$ in $L$ through $f$ is denote as $\varphi^f := f(\varphi)$.
\end{definition}
Let $\mathcal{S}$ be a deductive system over $L$, and $\mathcal{T}$ be a deductive system over $K$.
\begin{definition}
Relative to the translator $f$
\begin{enumerate}
    \item $\mathcal{S}$ is \emph{interpretable} in $\mathcal{T}$ if
    \begin{center}
        $\Gamma^f \vdash_{\mathcal{T}} \varphi^f$ whenever $\Gamma \vdash_{\mathcal{S}} \varphi$.
    \end{center}
    In particular, $f$ translates every theorem of $\mathcal{S}$ into a theorem of $\mathcal{T}$.
    \item $\mathcal{S}$ is \emph{co-interpretable} in $\mathcal{T}$ if
    \begin{center}
        $\Gamma \vdash_{\mathcal{S}} \varphi$ whenever $\Gamma^f \vdash_{\mathcal{T}} \varphi^f$.
    \end{center}
    In particular, if the translation of a statement of $L$ is a theorem of $\mathcal{T}$, then such statement is a theorem of $\mathcal{S}$.
    \item $\mathcal{S}$ is \emph{weakly interpretable} in $\mathcal{T}$ if
    \begin{center}
        $\Gamma^f \cup \{ \varphi^f \}$ is consistent relative to $\mathcal{T}$ whenever $\Gamma \vdash_{\mathcal{S}} \varphi$
    \end{center}
    In particular, the translation of every theorem of $\mathcal{S}$ is consistent with $\mathcal{T}$.
\end{enumerate}
\end{definition}
\ \\
Given a formal system $\mathcal{S}$, the (deductive) \emph{completion} $\mathcal{S}^{\vdash}$ of $\mathcal{S}$ is another formal system such that
\begin{enumerate}
    \item Every theorem of $\mathcal{S}$ is an axiom of $\mathcal{S}^{\vdash}$, and vice versa.
    \item Whenever $\Gamma \vdash_{\mathcal{S}} \varphi$, then $(\Gamma, \varphi)$ is an inference rule of $\mathcal{S}^{\vdash}$, and vice versa.
\end{enumerate}
\begin{remark} \label{logic-thm-infr-dual}
$\varphi$ is a theorem of $\mathcal{S}$ if and only if $(\varnothing, \varphi)$ is an inference rule of $\mathcal{S}^\vdash$ (here, $\varnothing$ denotes the empty collection).
\end{remark}
Given 2 formal systems $\mathcal{S}_1$ and $\mathcal{S}_2$ over the same language, we say
\begin{enumerate}
    \item $\mathcal{S}_1$ is a \emph{subsystem} of $\mathcal{S}_2$ if
    \begin{enumerate}
        \item Every axiom of $\mathcal{S}_1$ is an axiom of $\mathcal{S}_2$.
        \item Every inference rule of $\mathcal{S}_1$ is an inference rule of $\mathcal{S}_2$.
    \end{enumerate}
    \item $\mathcal{S}_1 = \mathcal{S}_2$ if they are subsystem of each other.
    \item $\mathcal{S}_1$ is \emph{deductively weaker} than $\mathcal{S}_2$ (or $\mathcal{S}_2$ is deductively stronger than $\mathcal{S}_1$) if $\mathcal{S}_1^\vdash$ is a subsystem of $\mathcal{S}_2^\vdash$.
    \item $\mathcal{S}_1$ and $\mathcal{S}_2$ are \emph{deductively equivalent} if they are deductively weaker than each other. In other words, 2 systems are deductively equivalent if their completion are the same. 
\end{enumerate}
\begin{proposition} \ 
\begin{enumerate}
    \item Monotonicity: if $\mathcal{S}_1$ is a subsystem of $\mathcal{S}_2$, then $\mathcal{S}_1^\vdash$ is a subsystem of $\mathcal{S}_2^\vdash$. Stated otherwise, $\mathcal{S}_1$ is deductively weaker than $\mathcal{S}_2$ whenever $\mathcal{S}_1$ is a subsystem of $\mathcal{S}_2$.
    \item Idempotency: $(\mathcal{S}^{\vdash})^{\vdash}$ is the same as $\mathcal{S}^{\vdash}$.
    \item Conservativity:
    \begin{enumerate}
        \item If $\mathcal{S} \cup \Gamma$ denotes the formal system where inference rules stays the same, but we add all statements in $\Gamma$ as axioms, then the inference rules in $\mathcal{S}^\vdash$ are the same as those in $(\mathcal{S} \cup \Gamma)^\vdash$.
        \item The completion of $\mathcal{S}$ is (deductively) equivalent to $\mathcal{S}$.
    \end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
\underline{Part 1:} we first show that if $\Gamma \vdash_{\mathcal{S}_1} \varphi$, then $\Gamma \vdash_{\mathcal{S}_2} \varphi$. Indeed,
\begin{enumerate}
    \item If $\varphi$ is an axiom of $\mathcal{S}_1$: then it is also an axiom of $\mathcal{S}_2$, and so $\Gamma \vdash_{\mathcal{S}_2} \varphi$.
    \item If $\varphi$ belongs to $\Gamma$: then $\Gamma \vdash_{\mathcal{S}_2} \varphi$ vacuously.
    \item If $(\Lambda, \varphi)$ is an inference rule of $\mathcal{S}_1$ such that $\Gamma \vdash_{\mathcal{S}_1} \lambda$ for each $\lambda \in \Lambda$. By induction hypothesis, $\Gamma \vdash_{\mathcal{S}_2} \lambda$. Finally, note that $\mathcal{S}_2$ contains all inference rules of $\mathcal{S}_1$, so we must have $\Gamma \vdash_{\mathcal{S}_2} \varphi$ by \hyperref[logic-ent-rule]{definition}.
\end{enumerate}
By induction principle, $\Gamma \vdash_{\mathcal{S}_2} \varphi$ whenever $\Gamma \vdash_{\mathcal{S}_1} \varphi$. By construction, every inference rule of $\mathcal{S}_1^\vdash$ is an inference rule of $\mathcal{S}_2^\vdash$. On the other hand, if we let $\Gamma$ to be empty, then every theorem of $\mathcal{S}_1$ is a theorem of $\mathcal{S}_2$ (\hyperref[logic-thm-infr-dual]{Remark \ref*{logic-thm-infr-dual}}). In other words, every axiom of $\mathcal{S}_1^\vdash$ is an axiom of $\mathcal{S}_2^\vdash$. We conclude that $\mathcal{S}_1^\vdash$ is a subsystem of $\mathcal{S}_2^\vdash$.
\\
\underline{Part 2:} for axioms
\begin{enumerate}
    \item If $\varphi$ is an axiom of $\mathcal{S}^{\vdash}$, then it is a theorem of $\mathcal{S}^{\vdash}$, and so an axiom of $(\mathcal{S}^{\vdash})^{\vdash}$.
    \item If $\varphi$ is an axiom of $(\mathcal{S}^{\vdash})^{\vdash}$, then it is a theorem of $\mathcal{S}^{\vdash}$, so every leaf of a proof tree of $\varphi$ represent a theorem of $\mathcal{S}$. By \hyperref[logic-deductive-reasoning]{Remark \ref*{logic-deductive-reasoning}}, $\varphi$ is then a theorem of $\mathcal{S}$, and so an axiom of $\mathcal{S}^{\vdash}$.
\end{enumerate}
For inference rules
\begin{enumerate}
    \item If $(\Gamma, \varphi)$ is an inference rules of $\mathcal{S}^{\vdash}$, then $\Gamma \vdash_{\mathcal{S}^{\vdash}} \varphi$ by \hyperref[logic-ent-props]{Proposition \ref*{logic-ent-props}}. Thus, $(\Gamma, \varphi)$ is an inference rule of $(\mathcal{S}^{\vdash})^{\vdash}$.
    \item If $(\Gamma, \varphi)$ is an inference rule of $(\mathcal{S}^{\vdash})^{\vdash}$, then $\Gamma \vdash_{\mathcal{S}^{\vdash}} \varphi$ by definition of completion. Thus, there exists a proof tree of $\varphi$ with the leaves represent either axioms of $\mathcal{S}^{\vdash}$ or statements in $\Gamma$. Since every axiom of $\mathcal{S}^{\vdash}$ is a theorem of $\mathcal{S}$, we can construct another proof tree of $\varphi$ such that the leaves represent either axioms of $\mathcal{S}$ or statements in $\Gamma$ (\hyperref[logic-deductive-reasoning]{Remark \ref*{logic-deductive-reasoning}}). Thus, $\Gamma \vdash_{\mathcal{S}} \varphi$, and so $(\Gamma, \varphi)$ is an inference rule of $\mathcal{S}^{\vdash}$.
\end{enumerate}
\underline{Part 3:} just another phrasing of part (2).
\end{proof}
\begin{proposition}[Local property]
$\mathcal{S}_1$ is deductively weaker than $\mathcal{S}_2$ if and only if
\begin{enumerate}
    \item Every axiom of $\mathcal{S}_1$ is a theorem of $\mathcal{S}_2$.
    \item $\Gamma \vdash_{\mathcal{S}_2} \varphi$ whenever $(\Gamma, \varphi)$ is an inference rule of $\mathcal{S}_1$.
\end{enumerate}
\end{proposition}
\begin{proof}
If $\mathcal{S}_1$ is deductively weaker than $\mathcal{S}_2$, then
\begin{enumerate}
    \item Every theorem of $\mathcal{S}_1$ is a theorem of $\mathcal{S}_2$. In particular, every axiom of $\mathcal{S}_1$ is a theorem of $\mathcal{S}_2$.
    \item $\Gamma \vdash_{\mathcal{S}_2} \varphi$ whenever $\Gamma \vdash_{\mathcal{S}_1} \varphi$. In particular, from \hyperref[logic-ent-props]{Proposition \ref*{logic-ent-props}}, we know that $\Gamma \vdash_{\mathcal{S}_2} \varphi$ whenever $(\Gamma, \varphi)$ is an inference rule of $\mathcal{S}_1$.
\end{enumerate}
Vice versa, suppose every axiom of $\mathcal{S}_1$ is a theorem of $\mathcal{S}_2$. If $\Gamma \vdash_{\mathcal{S}_1} \varphi$, and $\Gamma \vdash_{\mathcal{S}_2} \varphi$ for each inference rule $(\Gamma, \varphi)$ of $\mathcal{S}_1$. Inductively, for each $\Gamma \vdash_{\mathcal{S}_1} \varphi$
\begin{enumerate}
    \item If $\varphi$ belongs to $\Gamma$: then $\Gamma \vdash_{\mathcal{S}_2} \varphi$ \hyperref[logic-ent-hyp]{trivially}.
    \item If $\varphi$ is an axiom of $\mathcal{S}_1$: then it is a theorem of $\mathcal{S}_2$, or $\vdash_{\mathcal{S}_2} \varphi$ simply. By \hyperref[logic-ent-props]{Proposition \ref*{logic-ent-props}}, $\Gamma \vdash_{\mathcal{S}_2} \varphi$.
    \item If $(\Lambda, \varphi)$ is an inference rule of $\mathcal{S}_1$ such that $\Gamma$ entails each statement in $\Lambda$ relative to $\mathcal{S}_1$:
    \begin{enumerate}
        \item By induction hypothesis, $\Gamma$ entails each statement in $\Lambda$ relative to $\mathcal{S}_2$.
        \item Since $(\Lambda, \varphi)$ is an inference rule of $\mathcal{S}_1$, $\Lambda$ entails $\varphi$ relative to $\mathcal{S}_2$.
    \end{enumerate}
    From these 2 points, we conclude $\Gamma$ entails $\varphi$ relative to $\mathcal{S}_2$ by \hyperref[logic-ent-rule]{definition} and by.
\end{enumerate}
Hence, every inference rule of $\mathcal{S}_1^\vdash$ is an inference rule of $\mathcal{S}_2^\vdash$. Also, if $\varphi$ is an axiom of $\mathcal{S}_1^\vdash$, then it is a theorem of $\mathcal{S}_1$. Thus, $(\varnothing, \varphi)$ is an inference rule of $\mathcal{S}_1^\vdash$ (\hyperref[logic-thm-infr-dual]{Remark \ref*{logic-thm-infr-dual}}), so by the previous observation, it is also an inference rule of $\mathcal{S}_2$. In other words, $\varphi$ is a theorem of $\mathcal{S}_2$, or equivalently, $\varphi$ is an axiom of $\mathcal{S}_2^\vdash$. We conclude that $\mathcal{S}_1^\vdash$ is a subsystem of $\mathcal{S}_2^\vdash$, or equivalently, $\mathcal{S}_1$ is deductively weaker than $\mathcal{S}_2$.
\end{proof}

\newpage

\section{Semantic Categoricity for Propositional Logic}
Let $F_0$ be the set of all wffs of propositional logic, or simply, the language of propositional logic. A valuation on $F_0$ is defined to be a function $\mathfrak{v}: F_0 \to \{ 0, 1 \}$. We say a valuation is
\begin{enumerate}
    \item \emph{Implicational} if
    \begin{enumerate}
        \item $\mathfrak{v}(\alpha) = 1$ for every axiom $\alpha$.
        \item If $\mathfrak{v}(\varphi) = \mathfrak{v}(\varphi \to \psi) = 1$, then $\mathfrak{v}(\psi) = 1$
    \end{enumerate}
    \item \emph{Negational} if $\mathfrak{v}(\varphi) \neq \mathfrak{v}(\neg \varphi)$ for each wff $\varphi$.
    \item \emph{Propositional} if it is both implicational and negational.
    \item \emph{Coherent} (with respect to propositional logic) if
    \begin{enumerate}
        \item $\mathfrak{v}(\alpha \to \beta) = \mathfrak{v}(\varphi \to \psi)$ whenever $\mathfrak{v}(\alpha) = \mathfrak{v}(\varphi)$ and $\mathfrak{v}(\beta) = \mathfrak{v}(\psi)$.
        \item $\mathfrak{v}(\neg \varphi) = \mathfrak{v}(\neg \psi)$ whenever $\mathfrak{v}(\varphi) = \mathfrak{v}(\psi)$
    \end{enumerate}
\end{enumerate}
\begin{remark}
An implicational valuation will always assign $1$ to every theorem. Additionally, if $\varphi \equiv \psi$, then $\mathfrak{v}(\varphi) = \mathfrak{v}(\psi)$
\end{remark}
\begin{proof}
The first statement follows by induction on proof's length. As for second statement, by definition, $\varphi \to \psi$ and $\psi \to \varphi$ are theorems. Hence, suppose, WLOG, that $\mathfrak{v}(\varphi) = 1$ and $\mathfrak{v}(\psi) = 0$ (since there are only 2 values that can be assigned). Since $\mathfrak{v}(\varphi) = \mathfrak{v}(\varphi \to \psi) = 1$, we get $\mathfrak{v}(\psi) = 1$, a contradiction.
\end{proof}
\begin{proposition}
If $\mathfrak{v}$ is negational, then
\begin{enumerate}
    \item $\mathfrak{v}(\varphi) = \mathfrak{v}(\neg \neg \varphi)$ for each wff $\varphi$.
    \item $\mathfrak{v}(\neg \varphi) = \mathfrak{v}(\neg \psi)$ whenever $\mathfrak{v}(\varphi) = \mathfrak{v}(\psi)$.
\end{enumerate}
\end{proposition}
\begin{proof}
This follows from the fact that there are only 2 possible values to assign each formula to.
\end{proof}
\begin{lemma}
Suppose $\mathfrak{v}$ is propositional, then
\begin{enumerate}
    \item If $\mathfrak{v}(\varphi) = 1$, then $\mathfrak{v}(\varphi \to \gamma) = \mathfrak{v}(\gamma)$ and $\mathfrak{v}(\alpha \to \varphi) = 1$.
    \item If $\mathfrak{v}(\varphi) = 0$, then $\mathfrak{v}(\alpha \to \varphi) = \mathfrak{v}(\neg \alpha)$ and $\mathfrak{v}(\varphi \to \gamma) = 1$.
\end{enumerate}
\end{lemma}
\begin{proof} \ \\
\underline{Part 1:} as $\mathfrak{v}$ is implicational, we get $\mathfrak{v}(\varphi \to (\alpha \to \varphi)) = 1$, and so $\mathfrak{v}(\alpha \to \varphi) = 1$. Now, suppose $\mathfrak{v}(\varphi \to \gamma) \neq \mathfrak{v}(\gamma)$, we consider the following cases
\begin{enumerate}
    \item If $\mathfrak{v}(\varphi \to \gamma) = 1$ and $\mathfrak{v}(\gamma) = 0$: since $\mathfrak{v}(\varphi) = \mathfrak{v}(\varphi \to \gamma) = 1$, we get $\mathfrak{v}(\gamma) = 1$, a contradiction.
    \item If $\mathfrak{v}(\varphi \to \gamma) = 0$ and $\mathfrak{v}(\gamma) = 1$: since $\mathfrak{v}(\gamma) = \mathfrak{v}(\gamma \to (\varphi \to \gamma)) = 1$, we get $\mathfrak{v}(\varphi \to \gamma) = 1$, which again is a contradiction.
\end{enumerate}
\underline{Part 2:} as $\mathfrak{v}$ is negational, we get $\mathfrak{v}(\neg \varphi) = 1$. Apply part 1, we get $\mathfrak{v}(\neg\gamma \to \neg \varphi) = 1$ and $\mathfrak{v}(\neg \varphi \to \neg\alpha) = \mathfrak{v}(\neg\alpha)$. With \hyperref[HPL-A-NP1]{NP1}, we obtain $\mathfrak{v}(\alpha \to \varphi) = \mathfrak{v}(\neg \alpha)$ and $\mathfrak{v}(\varphi \to \gamma) = 1$
\end{proof}
\underline{Note:} part 1 only use implicational property.
\begin{theorem}
A propositional valuation is always coherent.
\end{theorem}
\begin{proof} \ \\
*Note that the 2nd condition is a direct result from negational property, so we only need to prove the 1st one. However, we first need to show that, whenever $\mathfrak{v}(\alpha) = \mathfrak{v}(\beta)$, we have
\begin{enumerate}
    \item $\mathfrak{v}(\alpha \to \gamma) = \mathfrak{v}(\beta \to \gamma)$
    \item $\mathfrak{v}(\lambda \to \alpha) = \mathfrak{v}(\lambda \to \beta)$
\end{enumerate}
Consider the following 2 cases
\begin{enumerate}
    \item If $\mathfrak{v}(\alpha) = \mathfrak{v}(\beta) = 1$: then $\mathfrak{v}(\alpha \to \gamma) = \mathfrak{v}(\gamma) = \mathfrak{v}(\beta \to \gamma)$, and $\mathfrak{v}(\lambda \to \alpha) = 1 = \mathfrak{v}(\lambda \to \beta)$.
    \item If $\mathfrak{v}(\alpha) = \mathfrak{v}(\beta) = 0$: then $\mathfrak{v}(\alpha \to \gamma) = \mathfrak{v}(\gamma) = 1 = \mathfrak{v}(\beta \to \gamma)$, and $\mathfrak{v}(\lambda \to \alpha) = \mathfrak{v}(\neg \lambda) = \mathfrak{v}(\lambda \to \beta)$.
\end{enumerate}
*Hence, assuming $\mathfrak{v}(\alpha) = \mathfrak{v}(\varphi)$ and $\mathfrak{v}(\beta) = \mathfrak{v}(\psi)$, we then have
\begin{align*}
    \mathfrak{v}(\alpha \to \beta) = \mathfrak{v}(\alpha \to \psi) = \mathfrak{v}(\varphi \to \psi)
\end{align*}
\end{proof}
\ \\
A valuation $\mathfrak{v}$ is \emph{trivial} if it assigns $1$ to every wffs.
\begin{remark}
The trivial valuation is implicational and coherent, but not negational.
\end{remark}
\begin{theorem} \label{meta-sufficient-interpretation}
If $\mathfrak{v}$ is implicational, coherent and non-trivial, then
\begin{enumerate}
    \item $\mathfrak{v}(\varphi \to \psi) = 0$ if and only if $\mathfrak{v}(\varphi) = 1$ and $\mathfrak{v}(\psi) = 0$.
    \item $\mathfrak{v}(\neg\varphi) = 0$ if and only if $\mathfrak{v}(\varphi) = 1$.
\end{enumerate}
\end{theorem}
\begin{proof} \ \\
\underline{Part 1:} follows from compatibility by induction on the length of some deduction sequence of a theorem.
\\
\underline{Part 2:} Since it is coherent, $\mathfrak{v}(\varphi \to \psi)$ is a function depending only on the value of $\mathfrak{v}(\varphi)$ and $\mathfrak{v}(\psi)$. In other words, there exists a function $Q: \{ 0, 1 \}^2 \to \{ 0, 1 \}$ such that $\mathfrak{v}(\varphi \to \psi) = Q(\mathfrak{v}(\varphi), \mathfrak{v}(\psi))$.
\\
\\
By the hypothesis, let $p$ be a wff such that $\mathfrak{v}(p) = 0$, and $q$ be a theorem (i.e. $\mathfrak{v}(q) = 1$). Suppose $Q(1, 0) = 1$, we obtain
\begin{enumerate}
    \item $\mathfrak{v}(p \to (q \to p)) = 1 = Q(0, Q(1, 0)) = Q(0, 1)$.
    \item $\mathfrak{v}(q \to (p \to q)) = 1 = Q(1, Q(0, 1)) = Q(1, 1)$ (by the previous points).
    \item $Q(0, 0)$ cannot be $0$ since otherwise, $\mathfrak{v}(p \to (p \to p)) = 1 = Q(0, Q(0, 0)) = Q(0, 0) = 0$, a contradiction.
\end{enumerate}
In other words, $Q(x, y) = 1$ for all $x, y \in \{ 0, 1 \}$. This means that $\mathfrak{v}$ always assign $1$ to every $\varphi \to \psi$, contradicting the nontriviality.
\\
\\
Therefore, $Q(1, 0) = 0$. From there
\begin{enumerate}
    \item $Q(0, 0) = Q(0, Q(1, 0)) = \mathfrak{v}(p \to (q \to p)) = 1$.
    \item $Q(0, 1) = Q(0, Q(0, 0)) = \mathfrak{v}(p \to (p \to p)) = 1$.
    \item $Q(1, 1) = Q(1, Q(0, 1)) = \mathfrak{v}(q \to (p \to q)) = 1$
\end{enumerate}
\underline{Part 3:} since $\mathfrak{v}(p) \neq \mathfrak{v}(q)$, we must have $\mathfrak{v}(\neg p) \neq \mathfrak{v}(\neg q)$, otherwise $\mathfrak{v}(\neg \neg p) = \mathfrak{v}(\neg \neg q) = b$ by coherence. Then, by \hyperref[HPL-T-DN]{DN} (and part 1), we must have $Q(0, b) = 1 = Q(1, b)$ and $Q(b, 0) = 1 = Q(b, 1)$. Checking case-by-case on the possible values of $b$, we conclude impossibility.
\\
Suppose $\mathfrak{v}(\neg p) = 0 = \mathfrak{v}(p)$, and $\mathfrak{v}(\neg q) = 1 = \mathfrak{v}(q)$, then
\begin{align*}
    \mathfrak{v}((\neg p \to \neg q) \to (q \to p)) & = 1
    \\
    & = Q(\mathfrak{v}(\neg p \to \neg q), \mathfrak{v}(q \to p))
    \\
    & = Q(Q(0, 1), Q(1, 0)) = Q(1, 0) = 0
\end{align*}
A contradiction! Thus, it must be the case that $\mathfrak{v}(\neg p) = 1$ and $\mathfrak{v}(\neg q) = 0$. By coherence, we conclude in general that $\mathfrak{v}(\neg \varphi) = 0$ if and only if $\mathfrak{v} (\varphi) = 1$.
\end{proof}
\begin{corollary}
Asssuming $\mathfrak{v}$ is implicational and coherent, then $\mathfrak{v}$ is non-trivial if and only if it is negational.
\end{corollary}

\newpage

\section{Pretext for Axiomatization of Predicate Calculus}
\subsection{Henkin's Model Existence Theorem}
\begin{theorem}
With respect to first-order logic, let $\sigma$ be some signature, and $\Gamma$ be a set of sentences with respect to $\sigma$ such that
\begin{enumerate}
    \item It is complete: for each sentence $\varphi$, either $\varphi \in \Gamma$ or $\neg \varphi \in \Gamma$.
    \item It is consistent: for each sentence $\varphi$, it is impossible that $\varphi \in \Gamma$ and $\neg \varphi \in \Gamma$ simultaneously.
    \item It is saturated: for each sentence of the form $\exists w_1 \exists w_2 \hdots \exists w_n (\varphi(w_1, w_2, \hdots, w_n))$, there exists constants $c_1, c_2, \hdots, c_n \in \sigma$ such that
    \begin{align*}
        \left[ \exists w_1 \exists w_2 \hdots \exists w_n (\varphi(w_1, w_2, \hdots, w_n)) \to \varphi(c_1, c_2, \hdots, c_n) \right] \in \Gamma
    \end{align*}
    We say that $\vec{c}$ is the Henkin's witness of $\exists \vec{w} (\varphi(\vec{w}))$.
\end{enumerate}
Then $\Gamma$ is satisfiable.
\end{theorem}
\begin{proof}
Let $N$ be the collection of terms (e.g. constants, and functions with constant arguments). Define the equivalence relation $\sim_\Gamma$ on $N$ where
\begin{align*}
    t \sim_\Gamma s \mbox{ iff } (t = s) \in \Gamma
\end{align*}
In other words, $t$ and $s$ are the same if it is provable that $t = s$. This is an equivalence relation, inductively from equality and Leibniz's substitution of formulas. Denote $\mathcal{M} = \mathcal{N}/\sim_\Gamma$ (note that completeness plays a role in this as derivability is different from hypothesis). We will prove that $\mathcal{M} \vDash \Gamma$.
\\
\\
For each constant, function, and relation symbol in $\sigma$, define
\begin{enumerate}
    \item If $c$ is a constant symbol, let $c^\mathcal{M} = [c]_\Gamma$ (this includes the Henkin's witnesses).
    \item If $R$ is an $n$-ary relation, let $R^{\mathcal{M}} \subseteq \mathcal{M}^n$ be such that $([t_1]_\Gamma, \hdots, [t_n]_\Gamma) \in R^{\mathcal{M}}$ iff $R(t_1, \hdots, t_n) \in \Gamma$.
    \item If $f$ is an $n$-ary function, let $f^\mathcal{M}: \mathcal{M}^n \to \mathcal{M}$ be such that $f^\mathcal{M}([t_1]_\Gamma, \hdots, [t_n]_\Gamma) = [f(t_1, t_2, \hdots, t_n)]_\Gamma$.
\end{enumerate}
These are well-defined: suppose $t_i \sim_\Gamma s_i$, or $t_i = s_i \in \Gamma$. By Leibniz's principle of substitution, this means
\begin{enumerate}
    \item For an $n$-ary relational symbol $R$: $\Gamma \vdash R(t_1, \hdots, t_n) \leftrightarrow R(s_1, \hdots, s_n)$. Since $\Gamma$ is consistent and complete, either both $R(t_1, \hdots, t_n), R(s_1, \hdots, s_n) \in \Gamma$, or \\ $R(t_1, \hdots, t_n), R(s_1, \hdots, s_n) \notin \Gamma$.
    \begin{align*}
        ([t_1]_\Gamma, \hdots, [t_n]_\Gamma) \in R^{\mathcal{M}} & \mbox{ iff } R(t_1, \hdots, t_n) \in \Gamma
        \\
        & \mbox{ iff } R(s_1, \hdots, s_n) \in \Gamma
        \\
        & \mbox{ iff } ([s_1]_\Gamma, \hdots, [s_n]_\Gamma) \in R^{\mathcal{M}}
    \end{align*}
    \item For an $n$-ary functional symbol $f$: $\Gamma \vdash f(t_1, \hdots, t_n) = f(s_1, \hdots, s_n)$. Again, as $\Gamma$ is consistent and complete, so $f(t_1, \hdots, t_n) = f(s_1, \hdots, s_n) \in \Gamma$. In other words, $[f(t_1, \hdots, t_n)]_\Gamma = [f(s_1, \hdots, s_n)]_\Gamma$.
\end{enumerate}
\ \\
Now, we will do \textit{structural} induction to show that $\mathcal{M} \vDash \Gamma$, i.e. $\mathcal{M} \vDash \varphi$ whenever $\varphi \in \Gamma$.
\begin{enumerate}
    \item If $\varphi \equiv (t = s)$ (where $t,s$ are terms): then $t \sim_\Gamma s$, and so $[t]_\Gamma = [s]_\Gamma$, i.e. $\mathcal{M} \vDash (t = s)$ (since any interpretation leaves the terms the same, and sends $t$ to $[t]_\Gamma$).
    \item If $\varphi \equiv R(t_1, \hdots, t_n)$ (where $t_i$ are terms, \textit{not} variables): by construction, $([t_1]_\Gamma, \hdots, [t_n]_\Gamma) \in R^{\mathcal{M}}$. Therefore, we have $\mathcal{M} \vDash R(t_1, \hdots, t_n)$.
    \item If $\varphi \equiv \neg \psi$: since $\Gamma$ is consistent, $\psi \notin \Gamma$. Under induction hypothesis, $\mathcal{M} \not\vDash \psi$. Since satisfaction is complete (in model-theoretical sense), we must have $\mathcal{M} \vDash \neg \psi$.
    \item If $\varphi \equiv \psi \wedge \xi$: as $\varphi \in \Gamma$, both $\psi, \xi \in \Gamma$. By induction, $\mathcal{M} \vDash \psi$ and $\mathcal{M} \vDash \xi$. By definition of satisfaction, $\mathcal{M} \vDash \psi \wedge \xi$.
    \item If $\varphi \equiv \psi \vee \xi$ or $\varphi \equiv \psi \to \xi$: it follows from the previous 2 points.
    \item If $\varphi \equiv \exists x (\psi(x))$: recall $\Gamma$ is saturated, meaning there exists a term $t$ (possibly some constant symbol) such that $\left[ \exists x (\psi(x)) \to \psi(t) \right] \in \Gamma$. Combining this with the hypothesis $\varphi \in \Gamma$, we know that $\psi(t) \in \Gamma$ (\hyperref[logic-deduct-metathm]{deduction theorem}). By induction, $\mathcal{M} \vDash \psi(t)$.
    \\
    \\
    Hence, we can construct a variable interpretation function $\mathfrak{I}_\psi : \mathbf{Var} \to \mathcal{M}$ by sending every variable to $[t]_\Gamma$. This should make $\mathcal{M}, \mathfrak{I}_\psi \vDash \psi(x)$. By definition, $\mathcal{M} \vDash \exists x (\psi(x))$.
    \item If $\varphi \equiv \forall x (\psi(x))$: first, there exists a term $t$ such that $\left[ \exists x \left( \neg \psi(x) \right) \to \neg \psi(t) \right] \in \Gamma$. Since $\alpha \to \beta$ is logically/provably equivalent to $\neg \beta \to \neg \alpha$,
    \begin{align*}
        \left[ \neg \neg \psi(t) \to \neg \exists x \left( \neg \psi(x) \right) \right] \in \Gamma
        \\
        \mbox{or } \left[ \psi(t) \to \forall x \left( \psi(x) \right) \right] \in \Gamma
    \end{align*}
    Let $\mathfrak{I}: \mathbf{Var} \to \mathcal{M}$ be an interpretation. Denote $[v]_\Gamma = \mathfrak{I}(x)$, then 
\end{enumerate}
\end{proof}

\subsection{Semantical Categoricity}
The way the Hilbert's system is designed makes any \textit{reasonable} interpretation coincide with the semantical way we think about logical connectives. Therefore, we may try to design predicate calculus in the same vein. But how do we semantically interpret?
\\
\\
Given a signature $\sigma$, we say that $(M, \sigma^M)$ is a $\sigma$-structure if, there is one-to-one correspondence between $\sigma$ and $\sigma^M$ (assigning $\varphi$ to $\varphi^M$), such that if $\varphi \in \sigma$ is of arity $n$, then $\varphi^M$ is an $n$-ary relation on $M$ (i.e. $\varphi^M \subseteq M^n$).
\\
\\
Given $M$ to be a $\sigma$-structure, and $\mathfrak{I}: \mathbf{Var} \to M$ to be a variable assignment. We define $M, \mathfrak{I} \vDash \varphi$ inductively as follows
\begin{enumerate}
    \item If $x_i$ are the variables associated with $\varphi \in \sigma$, then $M, \mathfrak{I} \vDash \varphi$ iff $(\mathfrak{I}(x_1), \hdots, \mathfrak{I}(x_n)) \in \varphi^M$, and $M, \mathfrak{I} \not\vDash \varphi$ iff $(\mathfrak{I}(x_1), \hdots, \mathfrak{I}(x_n)) \in \varphi^M$
    \item $M, \mathfrak{I} \vDash \neg \varphi$ iff $M, \mathfrak{I} \not\vDash \varphi$.
    \item $M, \mathfrak{I} \not\vDash \neg \varphi \to \psi$ iff $M, \mathfrak{I} \vDash \varphi$, and $M, \mathfrak{I} \vDash \psi$.
    \item $M, \mathfrak{I} \vDash \varphi[x, y := z]$ if $M, \mathfrak{I} \circ \mathcal{S}^{x, y}_z \vDash \varphi$, where $\mathcal{S}^{x, y}_z : \mathbf{Var} \to \mathbf{Var}$ is the variable reassignment
    \begin{align*}
        \mathcal{S}^{x, y}_z (x) & = \mathcal{S}^{x, y}_z (y) = z
        \\
        \mathcal{S}^{x, y}_z (w) & = w \mbox{ for all } w \notin \{ x, y \}
    \end{align*}
    \item $M, \mathfrak{I} \vDash \forall x (\varphi)$ if for any $x$-variant $\mathfrak{K}$ (i.e. $\mathfrak{I}(y) = \mathfrak{K}(y)$ for any $y \neq x$) including $\mathfrak{I}$, we have $M, \mathfrak{K} \vDash \varphi$
\end{enumerate}
The semantic rules for logical connectives are justified based upon the previous categorical result.
\\
\\
If $M, \mathfrak{I} \vDash \varphi$ for any $\mathfrak{I} \in M^{\mathbf{Var}}$, then we say $M \vDash \varphi$.
\begin{theorem}[Universal Instantiation \& Generalization] \ 
Let $\varphi$ be a wff of arity $n > 0$, then $M \vDash \varphi(\vec{x})$ iff $M \vDash \forall \vec{x} (\varphi(\vec{x}))$.
\end{theorem}
\begin{proof}
Suppose $M \vDash \varphi(\vec{x})$, then for any $\mathfrak{I} \in M^{\mathbf{Var}}$ and $\vec{x}$-variant $\mathfrak{H}$, we should still have $M, \mathfrak{H} \vDash \varphi(\vec{x})$ by definition. However, this is just another way of saying that $M, \mathfrak{I} \vDash \forall \vec{x} (\varphi(\vec{x}))$. Thus, $M \vDash \forall \vec{x} (\varphi(\vec{x}))$.
\\
\\
Next, suppose $M \vDash \forall \vec{x} (\varphi(\vec{x}))$. Let $\mathfrak{L}$ be a variable assignment in $M$. Then $M, \mathfrak{L} \vDash \forall \vec{x} (\varphi(\vec{x}))$, so $M, \mathfrak{I} \vDash \varphi(\vec{x})$ for any $\vec{x}$-variant $\mathfrak{I}$ of $\mathfrak{L}$. Now note that $\mathfrak{L}$ is actually $\vec{x}$-variant of itself, so $M, \mathfrak{L} \vDash \varphi(\vec{x})$. As $\mathfrak{L}$ is arbitrary, we conclude $M \vDash \varphi(\vec{x})$
\end{proof}

\newpage
\newpage

\chapter{Descriptive Set Theory}
\section{Cantor-Bendixson Rank}
Given a set $A$ in a topological space, we can define a transfinite sequence as follows:
\begin{enumerate}
    \item $\operatorname{lp}_0(A) = A$
    \item $\operatorname{lp}_{\alpha + 1}(A) = \operatorname{lp}(\operatorname{lp}_\alpha(A))$
    \item $\operatorname{lp}_\gamma (A) = \bigcap_{\beta < \gamma} \operatorname{lp}_\beta (A)$ for a limit ordinal $\gamma$.
\end{enumerate}
\begin{theorem}[Cantor-Bendixson Rank] \ 
\begin{enumerate}
    \item For arbitrary set $A$, the above sequence is eventually periodic, with the period at most $\omega$.
    \item However, for a closed set $C$, we have a stronger result: the above sequence stabilizes, and the smallest ordinal $\rho$ such that $\operatorname{lp}_\rho (C) = \operatorname{lp}_{\rho + 1} (C)$ is called the \emph{Cantor-Bendixson rank} of $C$.
\end{enumerate}
\end{theorem}
\begin{proof}
\underline{Part 1:} note that $A \supseteq \operatorname{lp}_\omega (A) \supseteq \operatorname{lp}_{\omega \cdot 2} (A) \supseteq \cdots$, so the sequence $\operatorname{lp}_\gamma(A)$ with $\gamma$ a limit ordinal is decreasing. Let $\Gamma_A = \bigcap_{\alpha} \operatorname{lp}_\alpha (A) \subseteq A$. For each $x \in A \setminus \Gamma_A = \bigcup_\alpha A \setminus \operatorname{lp}_\alpha(A)$, there must be some ordinal $\sigma_x$ such that $x \notin \operatorname{lp}_{\sigma_x}(A)$. Let $\sigma_x$ be the least such ordinal. By replacement, $\{ \sigma_x : x \in A \setminus \Gamma_A \}$ is a set (of ordinals), so let $\mu$ be a \textit{limit} ordinal that bounds this set above. By construction, $\operatorname{lp}_\mu(A) \subseteq \operatorname{lp}_{\sigma_x}(A)$, so $x \notin \operatorname{lp}_\mu(A)$ for all $x \in A \setminus \Gamma_A$. Equivalently, $A \setminus \Gamma_A \subseteq A \setminus \operatorname{lp}_\mu(A)$, or $\Gamma_A \supseteq \operatorname{lp}_\mu(A)$. On the other hand, $\Gamma_A$ is the intersection of all $\operatorname{lp}_\alpha(A)$, so we must get $\Gamma_A = \operatorname{lp}_\mu(A)$. Since $\mu$ is a limit ordinal, $\mu + \omega \cdot \alpha$ is also a limit ordinal (for any ordinal $\alpha$). Hence, $\Gamma_A = \operatorname{lp}_\mu(A) \supseteq \operatorname{lp}_{\mu + \omega \cdot \alpha} (A)$, which again shows that $\Gamma_A = \operatorname{lp}_{\mu}(A) = \operatorname{lp}_{\mu + \omega}(A) = \operatorname{lp}_{\mu + \omega \cdot 2}(A) = \cdots$. We conclude that the sequence is eventually periodic with period at most $\omega$.
\\
\\
\underline{Part 2:} if $A = C$ is closed, then $\operatorname{lp}(C) \subseteq C$, and we can prove by induction that
\begin{enumerate}
    \item $\operatorname{lp}_\alpha (C)$ is closed.
    \item $\operatorname{lp}_\alpha (C)$ is decreasing on $\alpha$.
\end{enumerate}
Based on this, we can show analogously (as with part 1) that $\Gamma_C = \operatorname{lp}_{\mu}(C) = \operatorname{lp}_{\mu + 1}(C) = \operatorname{lp}_{\mu + 2}(C) = \cdots$, i.e. the sequence stabilizes. Because of that, $\Gamma_C$ is also closed.
\end{proof}
\begin{remark}
Let $X$ be an indiscrete space with more than 2 elements, then $\operatorname{lp}(S) = X$ for any subset $S$ of $X$. Hence, $\operatorname{lp}_n (S) = X$ for any $n \geq 1$. Yet, $\operatorname{lp}_\omega(S) = S$ (since $\operatorname{lp}_0 (S) = S$), so the sequence is periodic with the period exactly $\omega$.
\end{remark}

\newpage
\newpage

\chapter{General Topology II}
\section{Kuratowski Monoid}
{[Reference: \href{https://www.mathtransit.com/cornucopia/2008_gj_a.php}{The Kuratowski Closure-Complement Theorem}]}
\begin{theorem}[Kuratowski 14 sets]
Let $X$ be a topological space and $E \subseteq X$. Then, at most 14 distinct subsets of $X$ can be obtained from $E$ by taking closure and complement
\end{theorem}
\section{Convergence spaces}
A convergence space is a pair ($X$, $\to$) where $X$ is a set, and $\to$ is a relation from the collection $\operatorname{Filter}(X)$ of filters on $X$, to $X$, such that
\begin{enumerate}
    \item The principal filter $\mathcal{F}_x = \{ A \subseteq X : x \in A \}$ at $x$ converges to $x$ (i.e. $\mathcal{F}_x \to x$).
    \item If $\mathcal{F} \subseteq \mathcal{G}$ and $\mathcal{F} \to x$, then $\mathcal{G} \to x$.
    \item If $\mathcal{F}, \mathcal{G} \to x$, then there exists some filter $\mathcal{H} \subseteq \mathcal{F} \cap \mathcal{G}$ such that $\mathcal{H} \to x$.
\end{enumerate}

\subsection{Neighborhood system}
A function $\mathcal{N}: X \to \mathrm{Filter}(X)$ from $X$ to the collection of filters on $X$ is called a \emph{neighborhood system} if $p \in N$ for any $N \in \mathcal{N}_p := \mathcal{N}(p)$. A \emph{pretopological space} is a pair $(X, \mathcal{N})$ where $\mathcal{N}$ is a neighborhood system on $X$. If $N \in \mathcal{N}_p$, we say that $N$ is a neighborhood of $p$.
\\
\\
A continuous function $f: (X, \mathcal{N}) \to (Y, \mathcal{M})$ between these spaces consists of a function $f: X \to Y$ such that $f^{-1}(V) \in \mathcal{N}_p$ whenever $V \in \mathcal{M}_{f(p)}$. Most of the time, we just use the same letters $\mathcal{N}$ for both neighborhood systems on $X$ and $Y$ for convenience. 
\begin{remark}
An equivalent definition of morphism is: for each neighborhood $V$ of $f(p)$, there exists a neighborhood $U$ of $p$ such that $f(U) \subseteq V$.
\end{remark}
\begin{proof}
Suppose $f: X \to Y$ is continuous in the first sense, then for any $V \in \mathcal{N}_{f(p)}$, we can take $U = f^{-1}(V) \in \mathcal{N}_p$ so that $f(U) = f(f^{-1}(V)) \subseteq V$. Vice versa, suppose $f: X \to Y$ is continuous in the second sense, then for any $V \in \mathcal{N}_{f(p)}$, there exists $U \in \mathcal{N}_p$ such that $f(U) \subseteq V$. This means that $U \subseteq f^{-1}(V)$. Since $\mathcal{N}_p$ is a filter, we have $f^{-1}(V) \in \mathcal{N}_p$.
\end{proof}
\begin{proposition}
The pretopological spaces, along with the continuous functions, form a category, denoted as $\mathbf{PreTop}$.
\end{proposition}
\begin{proof} \ \\
\underline{Identity:} the identity function $\operatorname{id}_X : (X, \mathcal{N}) \to (X, \mathcal{N})$ is continuous. Indeed, for each $V \in \mathcal{N}_{\operatorname{id}_X(p)} = \mathcal{N}_p$, we have $\operatorname{id}_X^{-1}(V) = V \in \mathcal{N}_p$.
\\
\underline{Composition:} given $f: (X, \mathcal{N}^X) \to (Y, \mathcal{N}^Y)$ and $g: (Y, \mathcal{N}^Y) \to (Z, \mathcal{N}^Z)$ continuous, we show that $gf: (X, \mathcal{N}^X) \to (Z, \mathcal{N}^Z)$ is also continuous. Let $W \in \mathcal{N}^Z_{gf(p)}$, then $g^{-1}(W) \in \mathcal{N}^Y_{f(p)}$, and $(gf)^{-1}(W) = f^{-1}(g^{-1}(W)) \in \mathcal{N}^X_p$.
\end{proof}
\ \\
Suppose $X$ is a topological space, let $\mathrm{Nbh}_X(p)$ (or simply $\mathrm{Nbh}(p)$) be the collection of all neighborhoods around $p$.
\begin{theorem}
The forget functor $L: \mathbf{Top} \to \mathbf{PreTop}$ by sending
\begin{enumerate}
    \item $(X, \mathcal{T})$ to $(X, \mathrm{Nbh})$
    \item $f: X \to Y$ to the same underlying function $f$
\end{enumerate}
is well-defined, fully faithful, and has a left adjoint $G$ that is also a left inverse of $L$.
\end{theorem}
\begin{proof} \ \\
\underline{Well-defined:} first we show that $\mathrm{Nbh}$ is a neighborhood system on $X$
\begin{enumerate}
    \item By definition, $p \in N$ for all neighborhood $N$ around $p$.
    \item If $N$ is a neighborhood of $p$, then there exists an open set $U$ such that $p \in U \subseteq N$. Any $M$ containing $N$ will automatically contains $U$, so it should be also a neighborhood of $p$.
    \item If $N_1, N_2$ are neighborhoods of $p$, then there exists open sets $U_1, U_2$ such that $p \in U_k \subseteq N_k$ ($k = 1, 2$). Thus $p \in U_1 \cap U_2 \subseteq N_1 \cap N_2$, which shows that $N_1 \cap N_2$ is neighborhood of $p$.
\end{enumerate}
\underline{Fully faithful:} straight from equivalent definition of continuity (in topological space).
\\
\\
\underline{Adjoint:} the adjoint $G$ is given by the following: for each pretopological space $(X, \mathcal{N})$, construct $\mathcal{T}$ as the collection of $U$ such that it is a neighborhood of itself (i.e. $U \in \mathcal{N}_p$ for all $p \in U$). $G$ then sends $(X, \mathcal{N})$ to $(X, \mathcal{T})$, and $f: X \to Y$ remains the same (just like the functor $L$).
\\
\\
We first verify that $\mathcal{T}$ is a topology on $X$.
\begin{enumerate}
    \item The empty set is trivially in $\mathcal{T}$. $X$ is also in $\mathcal{T}$ since each $\mathcal{N}_p$ is a filter, so $X \in \mathcal{N}_p$.
    \item Given a family $\{ U_i \}_{i \in I}$ of sets in $\mathcal{T}$, let $p$ be a point in $U = \bigcup_{i \in I} U_i$. By definition, there exist some $i_0 \in I$ such that $p \in U_i$. Thus, $U_i \in \mathcal{N}_p$. Since $\mathcal{N}_p$ is a filter, $U \in \mathcal{N}_p$, which implies that $U \in \mathcal{T}$.
    \item Given 2 sets $U$ and $V$ in $\mathcal{T}$, and any $p \in U \cap V$. Then we know that $p \in U, V$, so $U, V \in \mathcal{N}_p$. But $\mathcal{N}_p$, so we get $U \cap V \in \mathcal{N}_p$, and hence, $U \cap V \in \mathcal{T}$.
\end{enumerate}
\ \\
Given $f: (X, \mathcal{N}) \to (Y, \mathcal{M})$ continuous, we next show that $G(f) = f: (X, \mathcal{T}) \to (Y, \mathcal{S})$ is continuous, where $G(X, \mathcal{N}) = (X, \mathcal{T})$ and $G(Y, \mathcal{M}) = (Y, \mathcal{S})$. Let $V \in \mathcal{S}$, and $p \in U = f^{-1}(V)$, then $f(p) \in V$, so $V \in \mathcal{M}_{f(p)}$. By definition, $U \in \mathcal{N}_p$. But $p$ is an arbitrary point in $U$, so by construction of $\mathcal{T}$, we have $U \in \mathcal{T}$.
\\
\\
Next, we show that $GL$ is the identity functor on $\mathbf{Top}$. Denote $(X, \mathcal{N}) = L(X, \mathcal{T})$ and $(X, \mathcal{T}') = G(X, \mathcal{N})$. Let $U \in \mathcal{T}'$, then $U \in \mathcal{N}_p$ for all $p \in U$. By \hyperref[neighborhood-simple-facts]{Remark \ref*{neighborhood-simple-facts}}, $U \in \mathcal{T}$. Therefore, $\mathcal{T}' \subseteq \mathcal{T}$. Vice versa, let $U \in \mathcal{T}$, then $U \in \mathcal{N}_p$ for each $p \in U$ (by definition of a neighborhood). Thus, $U \in \mathcal{T}'$ by definition. We conclude $\mathcal{T} = \mathcal{T}'$.
\\
\\
Finally, we prove $G$ is the left adjoint to $L$.
\\
Note that
\begin{enumerate}
    \item Suppose $f: (X, \mathcal{N}) \to (Y, \mathrm{Nbh})$ is continuous. Let $V \in \mathcal{T}$, we need to show that $f^{-1}(V) \in \mathcal{T}_\mathcal{N}$, or equivalently, $f^{-1}(V) \in \mathcal{N}_p$ for all $p \in f^{-1}(V)$. Let $p \in f^{-1}(V)$, then $f(p) \in V$, so $V \in \mathrm{Nbh}(f(p))$. Thus, $f^{-1}(V) \in \mathcal{N}_p$.
    \item Vice versa, suppose $f: (X, \mathcal{T}_\mathcal{N}) \to (Y, \mathcal{T})$ is continuous. Let $V \in \mathrm{Nbh}(f(p))$, then there exists an open set $V'$ such that $f(p) \in V' \subseteq V$. Thus, $f^{-1}(V')$ is open and $p \in f^{-1}(V') \subseteq f^{-1}(V)$. By definition of $\mathcal{T}_\mathcal{N}$, we have $f^{-1}(V') \in \mathcal{N}_p$ and so $f^{-1}(V) \in \mathcal{N}_p$.
\end{enumerate}
Hence, we have established a bijection $j_{X, Y}$ between $\operatorname{Hom}_{\mathbf{PreTop}}(X, LY)$ and $\operatorname{Hom}_{\mathbf{Top}}(GX, Y)$. This is also natural, intuitively because the function itself remains the same between different categories. Concretely, we'll show that $j$ is a natural isomorphism between
\begin{align*}
    j: \operatorname{Hom}_{\mathbf{PreTop}}(-, L -) \to \operatorname{Hom}_{\mathbf{Top}}(G -, -)
\end{align*}
These functors are of the form $\mathbf{PreTop}^{op} \times \mathbf{Top} \to \mathbf{Set}$. For each morphism $(\varphi, \psi): (X, Y) \to (Z, W)$ in $\mathbf{PreTop}^{op} \times \mathbf{Top}$ (i.e. $\varphi: Z \to X$ is a morphism in $\mathbf{PreTop}$, $\psi: Y \to W$ is a morphism in $\mathbf{Top}$), and $f \in \operatorname{Hom}_{\mathbf{PreTop}}(X, LY)$
\begin{align*}
    j_{Z, W} \circ \operatorname{Hom}_{\mathbf{PreTop}}(\varphi, L\psi) (f) & = \operatorname{Hom}_{\mathbf{PreTop}}(\varphi, L\psi) (f)
    \\
    & = L\psi \circ f \circ \varphi = \psi \circ f \circ G\varphi
    \\
    & = \operatorname{Hom}_{\mathbf{Top}}(G\varphi, \psi) (f)
    \\
    & = \operatorname{Hom}_{\mathbf{Top}}(G\varphi, \psi) \circ j_{X, Y} (f)
\end{align*}
Recall that $L\psi = \psi$ and $G\varphi = \varphi$.
\end{proof}
\begin{theorem}[Topology in terms of neighborhood system] \label{topo-neigh-sys}
The image of the functor $L$ consists exactly of the pretopological spaces $(X, \mathcal{N})$ satisfying the following property: each neighborhood $N$ of $p$ contains a neighborhood $M$ of $p$ such that $N$ is a neighborhood of the whole $M$
\begin{align*}
    \forall p \in X, \forall N \in \mathcal{N}_p, \exists M \in \mathcal{N}_p, \forall x \in M: N \in \mathcal{N}_x
\end{align*}
\end{theorem}
\begin{proof}
Suppose $(\mathcal{N}_p)_{p \in X}$ is a neighborhood system on $X$, and $\mathcal{T}$ is the topology constructed from it. Given $N$ a neighborhood of $p$ (with respect to $\mathcal{T}$, not $\mathcal{N}_p$), there exists some $U \in \mathcal{T}$ such that $p \in U \subseteq N$ by definition. However, by construction, $U \in \mathcal{N}_p$, so $N \in \mathcal{N}_p$. This shows that $\mathrm{Nbh}(p) \subseteq \mathcal{N}_p$.
\\
\\
On the other hand, suppose $(X, \mathcal{N})$ satisfies the condition. Let $N \in \mathcal{N}_p$, and denote $U = \{ x \in N : N \in \mathcal{N}_x \}$. Given $x \in X$, if $N \in \mathcal{N}_x$, then there exists some $M_x \in \mathcal{N}_x$ such that $N \in \mathcal{N}_y$ for all $y \in M_x$. By construction, $M_x \subseteq U$ (note that $x \in N$ whenever $N \in \mathcal{N}_x$). But $\mathcal{N}_x$ is a filter, so $U \in \mathcal{N}_x$. In summary, $N \in \mathcal{N}_x$ implies $U \in \mathcal{N}_x$. In particular,
\begin{enumerate}
    \item $U \in \mathcal{N}_p$. So we get $p \in U \subseteq N$.
    \item For all $x \in U$, $N \in \mathcal{N}_x$, so $U \in \mathcal{N}_x$ also. In other words, $U \in \mathcal{T}$.
\end{enumerate}
Therefore, $N$ is neighborhood of $p$ (with respect to $\mathcal{T}$). This shows that $\mathcal{N}_p \subseteq \mathrm{Nbh}(p)$.
\end{proof}
\begin{remark}
The \hyperref[topo-neigh-sys]{above result} gives us another way to prove the adjunction between $L$ and $G$: note that if $(X, \mathcal{M}) = LG(X, \mathcal{N})$, then $\mathcal{M}_p \subseteq \mathcal{N}_p$ for each $p \in X$. Therefore, the map $\operatorname{id}_X : (X, \mathcal{N}) \to (X, \mathcal{M})$ (note the reversal of direction) is continuous. This provides the unit $\eta: 1_{\mathbf{PreTop}} \to LG$, while the counit $\varepsilon: GL \to 1_{\mathbf{Top}}$ is just the identity transformation
\end{remark}
\begin{example}
Since every set in $\mathcal{N}_p$ has to contain $p$, the filter $\mathcal{N}_p$ is a subset of the principal filter at $p$.
\begin{enumerate}
    \item If, for each $p \in X$, we have $\mathcal{N}_p = \uparrow \{ p \}$, then $G(X, \mathcal{N})$ is the discrete space on $X$.
    \item If, for each $p \in X$, we have $\mathcal{N}_p = \{ X \}$, then $G(X, \mathcal{N})$ is the indiscrete space on $X$.
\end{enumerate}
\end{example}

\subsection{Äech closure operator}
Given a set $X$, a \emph{preclosure operator} (or Äech closure operator) is a function $\operatorname{cl}$ on the power set of $X$ such that
\begin{enumerate}
    \item $\operatorname{cl}(\varnothing) = \varnothing$.
    \item $A \subseteq \operatorname{cl}(A)$.
    \item $\operatorname{cl}(A \cup B) = \operatorname{cl}(A) \cup \operatorname{cl}(B)$
\end{enumerate}
Such pair $(X, \operatorname{cl})$ is then called the \emph{preclosure space}.
\\
\\
A map $f: (X, \operatorname{cl}_X) \to (Y, \operatorname{cl}_Y)$ consists of a function $f: X \to Y$. We say $f$ is continuous if $f(\operatorname{cl}_X(A)) \subseteq \operatorname{cl}_Y(f(A))$ for any $A \subseteq X$.
\begin{proposition}
Preclosure spaces, along with its continuous functions, form a category, denoted as $\mathbf{CloTop}$.
\end{proposition}
\begin{proof} \ \\
\underline{Identity:} the identity $\operatorname{id}_X: X \to X$ is continuous since for each $A \subseteq X$, $\operatorname{id}_X (\operatorname{cl}(A)) = \operatorname{cl}(A) = \operatorname{cl}(\operatorname{id}_X(A))$.
\\
\underline{Composition:} if $f: (X, \operatorname{cl}_X) \to (Y, \operatorname{cl}_Y)$ and $g: (Y, \operatorname{cl}_Y) \to (Z, \operatorname{cl}_Z)$ are continuous, then $gf: (X, \operatorname{cl}_X) \to (Z, \operatorname{cl}_Z)$ is also continuous. Indeed, let $A \subseteq X$, we have
\begin{align*}
    gf(\operatorname{cl}_X(A)) \subseteq g(\operatorname{cl}_Y(f(A))) \subseteq \operatorname{cl}_Z(gf(A))
\end{align*}
\end{proof}
It turns out that this category is actually equivalent with $\mathbf{PreTop}$, so we can interchange different viewpoints regarding pretopological spaces. To do this, we introduce the concept of convergence
\begin{theorem}
From $(X, \operatorname{cl})$, we can define
\end{theorem}
\begin{corollary}[Kuratowski closure axiom]

\end{corollary}
\end{shaded}

\newpage

\begin{shaded}
\chapter{Euclidean Geometry}
\begin{theorem}[Routh Theorem]
Let $\triangle ABC$ be a triangle, and D, E, F are respectively points on the lines BC, CA, AB. Denote $x = \overline{AF}/\overline{FB}, y = \overline{BD}/\overline{DC}, z = \overline{CE}/\overline{EA}$.
\begin{enumerate}
	\item If $P$ is the intersection of $BE$ and $CF$, $Q$ is the intersection of $CF$ and $AD$, and $R$ is the intersection of $AD$ and $BE$, then
	\begin{align*}
	\frac{S_{PQR}}{S_{ABC}} = \frac{(xyz - 1)^2}{(xy + x + 1)(yz + y + 1)(zx + z + 1)}
	\end{align*}
	where $S_{ABC}$ denotes the area of $\triangle ABC$.
	\item
	\begin{align*}
	\frac{S_{DEF}}{S_{ABC}} = \frac{xyz + 1}{(x + 1)(y + 1)(z + 1)}
	\end{align*}
\end{enumerate}
\end{theorem}
\begin{corollary} \ 
\begin{enumerate}
	\item Ceva Theorem: $AD, BE, CF$ are concurrent iff $xyz = 1$.
	\item Menelaus Theorem: $D, E, F$ are collinear iff $xyz = -1$.
\end{enumerate}
\end{corollary}
\begin{proposition}
For a given simplex $S$ in $\mathbb{R}^n$ with its set of vertices $\mathcal{V}$.
\begin{align*}
\sum_{A \in \mathcal{V}} \vec{GA} = 0 \mbox{ iff } G = \frac{\int_S x dV}{\int_S dV} = \frac{\int_S x dV}{\operatorname{vol}(S)}
\end{align*}
\end{proposition}
\begin{theorem}
Let $A, B, C, D, E, F$ be points in Euclidean plane that are not all collinear. Denote $M$ to be the intersection of $AB$ and $DE$, $N$ to be the intersection of $BC$ and $EF$, and $P$ to be the intersection of $CD$ and $FA$. Prove that
\begin{enumerate}
	\item Pascal theorem: if $A, B, C, D, E, F$ lies on a conic, then $M, N, P$ are collinear.
	\item Braikenridge-Maclaurin theorem: if $M, N, P$ are collinear, then $A, B, C, D, E, F$ lies on some conic.
\end{enumerate}
\end{theorem}
\begin{theorem}[Poncelet Porism] \ 
\begin{enumerate}
	\item Given a conic $\mathcal{C}$ inside and conic $\mathcal{I}$ such that there some polygon with $n$ sides (for some fixed $n$) that is inscribed in $\mathcal{I}$, and circumscribed $\mathcal{C}$, then any poiny on $\mathcal{I}$ is a vertex of such polygon (still with $n$ sides).
	\item Cayley existence criteria (see \textit{On Cayley's explicit solution to Poncelet's porism}, by Phillip Griffiths and Joseph Harris)
	\item {[Richelot 1830, Kerawala 1947]} Let $(I, r)$ be a circle (centered at $I$, of radius $r$) inside another circle $(O, R)$. If
	\begin{enumerate}
		\item $d = OI, a = 1/(R+d), b = 1/(R-d), c = 1/r$
		\item $\lambda = 1 + \frac{2c^2 (a^2 - b^2)}{a^2 (b^2 - c^2)}, \omega = \cosh^{-1} \lambda, k^2 = 1 - e^{-2 \omega}$
	\end{enumerate}
	Then there exists an $n$-side polygon that is inscribed in $(O, R)$, and circumscribed $(I, r)$ if and only if
	\begin{align*}
	\operatorname{sc} \left( \frac{K(k)}{n}, k \right) = \frac{c \sqrt{b^2 - a^2} + b \sqrt{c^2 - a^2}}{a(b+c)}
	\end{align*}
	where $\operatorname{sc}(x, y)$ is the Jacobi elliptic function, and $K(z)$ is the complete elliptic integral of the 1st kind. As a result
	\begin{enumerate}
		\item When $n = 3$ (Euler, Chapple): we have the identity $d^2 = R (R - 2r)$ between the radii of inscribed and circumscribed circles of a triangle, and the distance between them.
		\item Similarly, when $n = 4$ (Nicolas Fuss): we have the identity
		\begin{align*}
		\frac{1}{(R - d)^2} + \frac{1}{(R + d)^2} = \frac{1}{r^2}
		\end{align*}
	\end{enumerate}
	\item If a polygon is inscribed and circumscribed by circles, then
	\begin{enumerate}
		\item If the number of sides is even, then the lines, each of which connects the contact points (to the inscribed circle) of 2 opposite sides, are concurrent.
		\item If the number of sides is odd, then the lines, each of which connects a vertex to the contact point of the opposite side, are concurrent.
	\end{enumerate}
	Additionally, the point of concurrency is the limiting point of the 2 circles.
\end{enumerate}
\end{theorem}
\begin{theorem}[Porcupine Theorem]
Given a closed, orientable, smooth (or just $C^1$) manifold $M$ of dimension $n - 1$, possibly with rough corners, such that it is embedded in $\mathbb{R}^n$. We then have
\begin{align*}
\int_{M} \vec{n} d S = \vec{0}
\end{align*}
Where $\vec{n}$ is the normal vector at point $x$.
\end{theorem}
\ \\
\begin{theorem}[Abboud-Viviani invariant]
Given a convex polygon $A_1 A_2 \hdots A_n$ (with $A_{n + 1} = A_1$) which has vertex angles equal to each other (i.e. an equi-angular polygon), and $T$ is a point on the plane. Let
\begin{enumerate}
	\item $S$ be the \emph{total width} of the polygon
	\begin{align*}
	S = \begin{cases}
	\mbox{The sum of distances between opposite sides} & \mbox{ if } 2 \mid n \\
	\mbox{The sum of distances between a vertex and its opposite side} & \mbox{ if } 2 \nmid n
	\end{cases}
	\end{align*}
	\item $D_n$ be the \emph{Abboud-Viviani invariant} of $n$:
	\begin{align*}
	D_n = \begin{cases}
	1 & \mbox{ if } n \mbox{ is even} \\
	\frac{\cos (\pi/n)}{\cos (\pi/n) + 1} & \mbox{ if } n \mbox{ is odd}
	\end{cases}
	\end{align*}
\end{enumerate}
Then
\begin{align*}
\sum_{k = 1}^n \overline{d(T, A_k A_{k + 1})} = D_n S
\end{align*}
where the sign of $\overline{d(T, \ell)}$ is positive if $T$ is on the same side as the polygon with respect to the line $\ell$, and negative otherwise.
\end{theorem}
\begin{theorem}[Viviani conservation principle]
For a convex polygon $A_1 A_2 \hdots A_n$, and $T$ is an arbitrary point inside the polygon, if
\begin{center}
$\sum_{k = 1}^n d(T, A_k A_{k + 1})$ is constant, regardless of the position of $T$
\end{center}
then $\sum_{k = 1}^n \vec{t_k} = 0$, where $\vec{t_k}$ is the projection \emph{unit} vector of $T$ into $A_k A_{k + 1}$ (note that these vectors depends only on the polygon and not $T$). In fact,
\begin{align*}
\sum_{k = 1}^n \overline{d(T, A_k A_{k + 1})} = \mbox{const if and only if } \sum_{k = 1}^n \vec{t_k} = 0
\end{align*}
\end{theorem}
\begin{corollary}
When $n = 3$, then the sum is constant if and only if the triangle is equilateral.
\end{corollary}
\ \\
\begin{theorem}[ErdÅsâMordell inequality]
Let $A_1 A_2 \hdots A_n$ be a convex $n$-gon, $P$ be a point in the polygon. Denote $r_i = PA_i$, $d_{i, j} = d(P, A_i A_j)$, $w_{i, j}$ to be the bisector length of $\angle A_i P A_j$ from $P$ to its intersection with $A_i A_j$.
\begin{enumerate}
	\item {[Lenhard]}
	\begin{align*}
	\sum_{i = 1}^n r_i \geq \sec \frac{\pi}{n} \sum_{i = 1}^n w_{i, i + 1} \geq \sec \frac{\pi}{n} \sum_{i = 1}^n d_{i, i + 1}
	\end{align*}
	Corollary [Barrow]: $r_1 + r_2 + r_3 \geq 2 (w_{1, 2} + w_{2, 3} + w_{3, 1})$, with equality holds only for equilateral triangle, and $P$ is its center.
	\item {[Gueron, Shafrir]} For any $\lambda_i \geq 0$
	\begin{align*}
	\sum_{i = 1}^n \lambda_i r_i \geq \sec \frac{\pi}{n} \sum_{i = 1}^n \sqrt{\lambda_i \lambda_{i + 1}} d_{i, i + 1}
	\end{align*}
	Corollary [Weighted ErdÅsâMordell]: $\lambda_1 r_1 + \lambda_2 r_2 + \lambda_3 r_3 \geq 2 (\sqrt{\lambda_1 \lambda_2} d_{1, 2} + \sqrt{\lambda_2 \lambda_3} d_{2, 3} + \sqrt{\lambda_3 \lambda_1} d_{3, 1})$, with equality holds only for equilateral triangle, $P$ is its center, and $\lambda_1 = \lambda_2 = \lambda_3$.
	\item {[N. Ozeki]}
	\begin{align*}
	\prod_{i = 1}^n r_i \geq \sec^n \frac{\pi}{n} \prod_{i = 1}^n w_{i, i + 1}
	\end{align*}
	\item {[L. Fejes, TÃ³th]}
	\begin{align*}
	\prod_{i = 1}^n r_i \geq \sec^n \frac{\pi}{n} \prod_{i = 1}^n d_{i, i + 1}
	\end{align*}
	\item Conjecture:
	\begin{enumerate}
		\item Generalization of Gueron-Shafrir and Lenhard results:
		\begin{align*}
		\sum_{i = 1}^n \lambda_i r_i \geq \sec \frac{\pi}{n} \sum_{i = 1}^n \sqrt{\lambda_i \lambda_{i + 1}} w_{i, i + 1} \geq \sec \frac{\pi}{n} \sum_{i = 1}^n \sqrt{\lambda_i \lambda_{i + 1}} d_{i, i + 1}
		\end{align*}
		\item Weighted N. Ozeki inequality:
		\begin{align*}
		\prod_{i = 1}^n r_i^{\lambda_i} \geq \sec^n \frac{\pi}{n} \prod_{i = 1}^n w_{i, i + 1}^{\sqrt{\lambda_i \lambda_{i + 1}}}
		\end{align*}		
	\end{enumerate}
\end{enumerate}
\end{theorem}
\begin{theorem}[Kazarinoff]
Let $ABCD$ be a tetrahedron, $P$ be a point inside. Respectively, denote
\begin{enumerate}
	\item $d_A, d_B, d_C, d_D$ to be the distances from $P$ to the plane $BCD, CDA, DAB, ABC$.
	\item $R_A, R_B, R_C, R_D$ to be the length of $PA, PB, PC, PD$.
\end{enumerate}
Then
\begin{align*}
\frac{R_A + R_B + R_C + R_D}{d_A + d_B + d_C + d_D} > 2 \sqrt{2}
\end{align*}
In fact, $2 \sqrt{2}$ is the best (or largest) possible constant.
\end{theorem}
\ \\
\begin{theorem}[Power Summation Theorem] \ 
\begin{enumerate}
	\item Let $A_1 A_2 \hdots A_n$ be a regular $n$-gon inscribed in $(O, R)$ with an arbitrary point $M$ on the circle. Suppose $0 \leq t < n$ is an integer, we have
	\begin{align*}
	\frac{1}{R^{2t}} \sum_{i = 1}^n MA_i^{2t} = n {2t \choose t}
	\end{align*}
	(special thanks to OEIS - On-Line Encyclopedia of Integer Sequences, for the constant ${2t \choose t}$)
	\\
	Conjectures:
	\begin{enumerate}
		\item If $t$ is not an integer, or is an integer but not in between $0$ and $n - 1$ (inclusively), then the sum is not constant (i.e. it depends on the position of $M$). If so, can there be an explicit formula?
		\item What other polygons (beside regular ones) have such property, i.e. the sum is constant for some power $t$.
	\end{enumerate}
	\item Let $A_1 A_2 \hdots A_n$ be a regular $n$-gon inscribed in $(O, R)$ with an arbitrary line $\ell$ going through the center $O$. Suppose $t \geq 0$ is an integer such that $2t < n$ if $n$ is even, and $t < n$ if $n$ is odd, show that
	\begin{align*}
	\frac{1}{R^{2t}} \sum_{i = 1}^n d(A_i, \ell)^{2t} = \frac{n}{4^t} {2t \choose t}
	\end{align*}
	\item Let $A_1 A_2 \hdots A_n$ be a regular $n$-gon inscribed in $(O, R)$ with an arbitrary point $M$ on the circle. Suppose $t$ is an integer such that $0 \leq 2t < n$, we have
	\begin{align*}
	\sum_{i = 1}^n d(M, A_i A_{i + 1})^{2t} = \mbox{const, regardless of } M
	\end{align*}	
\end{enumerate}
\end{theorem}
\ \\
\begin{theorem}[Van Schooten Theorem]
\begin{enumerate}
	\item {[Bui Quang Tuan]} Let $A_1 A_2 \hdots A_n$ be a polygon inscribed in a circle centered at $O$, with $P$ be a point on the circle. Denote $a_i = A_i A_{i + 1}, d_i = d(P, A_i A_{i + 1})$ and $t_i = a_i/d_i$. Prove that among $t_1, t_2, \hdots, t_n$, there is one $t_i$ that sums up the other $t_j$ (for $j \neq i$)
	\item Partial corollary [Van Schooten]: for a triangle $\triangle ABC$, show that
	\begin{center}
		$\triangle ABC$ is an equilateral triangle if and only if one of $PA, PB, PC$ sums up the other 2 for any point $P$ on the circumcircle of $\triangle ABC$.
	\end{center}
\end{enumerate}
\end{theorem}
\ \\
\begin{theorem}[Petr-Douglas-Neumann theorem]
Let $P_0$ be an $n$-gon ($n \geq 3$), and $(k_i)_{i = 0}^{n - 3}$ be a permutation of $\{ 1, 2, \hdots, n - 2 \}$. Construct a sequence of polygon $(P_i)_{i = 0}^{n - 2}$ (with the intital one to be the same as $P_0$) recursively as follows
\begin{enumerate}
	\item Given $P_i$, draw isoceles triangles with apex angle $k_i 2 \pi/n$ on each sides of the polygon $P_i$ such that if the isoceles triangle with base $S_h S_{h + 1}$ is on the same side as the side $S_{h + 1} S_{h + 2}$ with respect to the same base $S_h S_{h + 1}$, then the next isoceles triangle at $S_{h + 1} S_{h + 2}$ has to be on the same side as $S_h S_{h + 1}$ with respect to its base $S_{h + 1} S_{h + 2}$. Such an arrangement consitute an \emph{orientation} of the polygon, and there are exactly 2 distinct orientations for any polygon (even if it is self-intersecting).
	\item The apices of these isoceles triangles form the next polygon $P_{i + 1}$, and the order of vertices follows the same order as the bases of isoceles triangles, i.e. any 2 vertices of $P_{i + 1}$ are adjacent if the repective bases (from the isoceles triangles) are the adjacent sides of $P_i$.
\end{enumerate}
Show that $P_{n - 2}$ is a regular $n$-gon whose centroid coincides with the centroid of the original polygon $P_0$.
\end{theorem}
\begin{corollary} \ 
\begin{enumerate}
	\item Napoleon theorem: the centers of the equilaterals constructing at the sides of some triangle forms another equilateral.
	\item Van Aubel theorem: let $ABCD$ be a quadrilateral. Let $P, Q, R, S$ be the center of the squares constructing on the side $AB, BC, CD, DA$ respectively. Then $PR = QS$ and $PR \perp QS$.
	\item ThÃ©bault problem I: given any parallelogram, the centers of the squares constructed at the 4 sides form another square.
\end{enumerate}
\end{corollary}
\ \\
\begin{theorem} \ 
Let
\begin{align*}
s(x) = \begin{cases}
	\frac{x}{2} & \mbox{ for Euclidean geometry} \\
	\sinh \frac{x}{2} & \mbox{ for hyperbolic geometry} \\
	\sin \frac{x}{2} & \mbox{ for spherical geometry} \\
\end{cases}
\end{align*}
\begin{enumerate}
	\item \underline{Conjecture:} suppose $(C_1, r_1), \hdots, (C_n, r_n)$ ($n \geq 3$) are $n$ circles tangent to some other circle $(O, R)$. Define
	\begin{align*}
	t_{ij} = \begin{cases}
		\mbox{The segment of exterior common tangent of } (C_i) \mbox{ and } (C_j) \\
		\qquad \mbox{ if they are on the same side of } (O) \\
		\mbox{The segment of interior common tangent of } (C_i) \mbox{ and } (C_j) \\
		\qquad \mbox{ if they are on the different sides of } (O)
	\end{cases}
	\end{align*}
	If
	\begin{enumerate}
		\item $E_n$ is the set of polynomials $f$ of $n(n+1)/2$ variables such that $f(|t_{ij}|_e, |r_i|_e) = 0$ when the circles $(C_i)$ varies, where $|AB|_e$ is the Euclidean distance between 2 points.
		\item $H_n$ is the set of polynomials $f$ of $n(n+1)/2$ variables such that $f(\sinh \frac{|t_{ij}|_h}{2}, \frac{1}{2} \sinh |r_i|_h) = 0$ when the circles $(C_i)$ varies, where $|AB|_h$ is the hyperbolic distance between 2 points.
		\item $S_n$ is the set of polynomials $f$ of $n(n+1)/2$ variables such that $f(\sin \frac{|t_{ij}|_s}{2}, \frac{1}{2} \sin |r_i|_s) = 0$ when the circles $(C_i)$ varies, where $|AB|_s$ is the spherical distance between 2 points.
	\end{enumerate}
	Then $E_n = H_n = S_n$, and every polynomial in either of them is homogeneous.
	\item {[Gregorac, Ren Guo, Nilgun Sonmez]} Same as above, but when the circles degenerate into points.
	\item {[Gregorac, Ren Guo, Nilgun Sonmez]} Let $A_0, A_1, \hdots, A_{2n - 1}$ be points on a circle (in one the 3 geometries described above). Denote $l_{ij}$ to be the length of the geodesic segment $A_i A_j$ (for $i \neq j$). Then $\det (a_{ij}) = 0$ where $a_{ij} = (-1)^{\delta_{ij}} [s(l_{2i - 2, 2j - 1}) s(l_{2j - 1, 2i})]^{-1}$ (and $\delta_{ij}$ is the Kronecker delta).
	\item {[Gregorac, Ren Guo, Nilgun Sonmez]} Let $P_0, P_1, \hdots, P_n$ be points on a circle (in one the 3 geometries described above). Denote $l_{ij}$ to be the length of the geodesic segment $P_i P_j$ (for $i \neq j$).
	\begin{enumerate}
		\item For each $|j - i| \geq 2$, there exists some polynomial $F_{ij}$ such that $s(l_{ij}) = F_{ij}(s(l_{12}, l_{23}, \hdots, l_{n1}))$.
		\item If $R$ is the radius of the circle, there exists some polynomial $G$ such that $s(2R) = G(s(l_{12}, l_{23}, \hdots, l_{n1}))$.
	\end{enumerate}
	\item {[Fuhrmann]} Let $(C_1), (C_2), (C_3), (C_4), (C_5), (C_6)$ (in that order, clockwise) be 6 circles tangent to another circles $(O)$. Define $t_{ij}$ as in part (1) previously, but replace with the length of the tangent. Then
	\begin{align*}
	t_{14} t_{25} t_{36} = t_{12} t_{45} t_{36} + t_{23} t_{56} t_{14} + t_{34} t_{16} t_{25} + t_{12} t_{34} t_{56} + t_{16} t_{23} t_{45}
	\end{align*}
	\item Casey theorem: let $\alpha, \beta, \gamma, \delta$ be circles. Let $t_{\alpha \beta}$ be the length of a common tangent (either interior of exterior) of $\alpha$ and $\beta$. Same for $t_{\alpha \gamma}, t_{\alpha \delta}, t_{\beta \gamma}, t_{\beta \delta}, t_{\gamma \delta}$. Show that
	\begin{center}
	There exists a way of choosing tangents and signs so that the equation $\pm t_{\alpha \beta} t_{\gamma \delta} \pm t_{\beta \gamma} t_{\delta \alpha} \pm t_{\gamma \alpha} t_{\beta \delta} = 0$ holds, if and only if all 4 circles $\alpha, \beta, \gamma, \delta$ are tangent to another circle.
	\end{center}
	\item Ptolemy inequality: let $ABCD$ be a quardrilateral, then $AC \cdot BD \leq AB \cdot CD + BC \cdot DA$, with equality happens only if the quadrilateral is cyclic.
	\item {[McDougall]} Let $P_0, P_1, \hdots, P_n$ (with $n$ even) be points on a circle in the counter-clockwise order, and denote $R_k = \prod_{i \neq k} P_k P_i$. Show that
	\begin{align*}
	\sum_{k = 1}^n (-1)^{k - 1} \frac{1}{R_k} = 0
	\end{align*}
	\underline{Conjecture:} does it still hold in hyperbolic/spherical geometry?
\end{enumerate}
\end{theorem}
\end{shaded}

\newpage

\begin{shaded}
\chapter{Abstract Algebra}
\begin{proposition} \ 
\begin{enumerate}
	\item $xyz = x + y + z + 2 \Leftrightarrow \frac{1}{1+x} + \frac{1}{1+y} + \frac{1}{1+z} = 1$
	\item If $x, y, z$ are non-negative, then $x^2 + y^2 + z^2 + 2xyz = 1$ if and only if there exists $\alpha, \beta, \gamma \geq 0$ with $\alpha + \beta + \gamma = \pi$ such that $x = \cos \alpha$, $y = \cos \beta$, and $z = \cos \gamma$.
	\item Suppose $x, y, z > 0$ and $\max \{ x, y, z \} \geq 2$, then $x^2 + y^2 + z^2 = xyz + 4$ if and only if there exists $a, b, c > 0$ such that $x = a + 1/a, y = b + 1/b, z = c + 1/c$.
\end{enumerate}
\end{proposition}
\begin{proposition} [Triangle Trigonometric Identities]
Let $x + y + z = \pi$
\begin{enumerate}
	\item $\cos^2 x + \cos^2 y + \cos^2 z + 2 \cos x \cos y \cos z = 1$
	\item $\tan x \tan y \tan z = \tan x + \tan y + \tan z$
	\item $\tan \frac{x}{2} \tan \frac{y}{2} + \tan \frac{y}{2} \tan \frac{z}{2} + \tan \frac{z}{2} \tan \frac{x}{2} = 1$
\end{enumerate}
\end{proposition}
\begin{theorem}[\href{https://artofproblemsolving.com/community/c6h80127}{S.O.S method}]
Consider $S = S_a (b - c)^2 + S_b (c - a)^2 + S_c (a - b)^2$, where $S_a, S_b, S_c$ are functions of $a, b, c$
\begin{enumerate}
	\item If $S_a, S_b, S_c \geq 0$ then $S \geq 0$.
	\item If $a \geq b \geq c$ and $S_b, S_b + S_c, S_b + S_a \geq 0$ then $S \geq 0$.
	\item If $a \geq b \geq c$ and $S_a, S_c, S_a + 2 S_b, S_c + 2 S_b \geq 0$ then $S \geq 0$.
	\item If $a \geq b \geq c$ and $S_b, S_c, a^2 S_b + b^2 S_a \geq 0$ then $S \geq 0$.
	\item If $S_a + S_b + S_c \geq 0$ and $S_a S_b + S_b S_c + S_c S_a \geq 0$ then $S \geq 0$.
\end{enumerate}
Other reference: \href{https://web.evanchen.cc/handouts/SOS_Dumbass/SOS_Dumbass.pdf}{Supersums of Square-Weights (SOS): A Dumbassâs Perspective}
\end{theorem}
\begin{theorem}[Hilbert 17th problem]
\end{theorem}
\begin{proposition} \ 
\begin{enumerate}
	\item $(a^2 + n b^2) (c^2 + n d^2) = (ac + n bd)^2 + n (ad - bc)^2$
	\item $(a^2 - n b^2) (c^2 - n d^2) = (ac + n bd)^2 - n (ad + bc)^2$
	\item $(n + 1) (a^2 + n b^2) = (a + n b)^2 + n (a - b)^2$
	\item BrahmaguptaâFibonacci two-square identity, Euler four-square identity, Degen eight-square identity, and \href{https://kconrad.math.uconn.edu/blurbs/linmultialg/pfister.pdf}{Pfister theorem}
\end{enumerate}
\end{proposition}

\section{Functional Equation}
\begin{proposition}[Cauchy functional equation] \ 
Consider the functional equation $f(x + y) = f(x) + f(y)$
\begin{enumerate}
	\item If $f: \mathbb{Q} \to \mathbb{C}$, then $f(x) = ax$ for some complex constant $a$.
	\item If $f: \mathbb{R} \to \mathbb{C}$, then $f(x) = ax$ if any of the following condition is satisfied:
	\begin{enumerate}
		\item $f$ is continuous at some point.
		\item $f$ is monotonic on some interval.
		\item $f$ is bounded on some interval.
		\item $f$ is Lebesgue measurable.
	\end{enumerate}
	\item In general, pick a Hamel basis $H$ of $\mathbb{R}$ over the rationals, and $f: H \to \mathbb{C}$ any function, then the linear extension $\overline{f}: \mathbb{R} \to \mathbb{C}$ satisfies the Cauchy functional equation. In fact, the converse also holds, i.e. any function satisfying the equation must be a linear extension of some (complex-valued) map on a Hamel basis.
\end{enumerate}
\end{proposition}
\begin{proposition} \ 
\begin{enumerate}
	\item Quadratic functional equation: $f(x + y) + f(x - y) = 2[f(x) + f(y)]$
	\item Jensen functional equation: $f \left( \frac{x + y}{2} \right) = \frac{f(x) + f(y)}{2}$
	\item d'Alembert functional equation: $f(x + y) + f(x - y) = 2[f(x) f(y)]$
	\item Sinusoidal system of functional equations:
	\begin{align*}
	(S(x))^2 + (C(x))^2 & = 1
	\\
	S(x + y) & = S(x) C(y) + S(y) C(x)
	\\
	C(x + y) & = C(x) C(y) - S(x) S(y)
	\end{align*}
	Reference: \href{https://math.stackexchange.com/questions/3386066/defining-sine-and-cosine-from-functional-equations-sx2cx2-1-cxy}{Defining sine and cosine from functional equations}.
\end{enumerate}
\end{proposition}

\subsection{Polynomial functional equation}
\begin{theorem}[Lagrange interpolation]
Let $(x_i, y_i)_{i = 1}^n$ be points in $\mathbb{R}^2$ such that $x_i$ are pairwise distinct, then there exists a unique polynomial $p(x)$ of degree at most $n$ such that $p(x_i) = y_i$. In fact,
\begin{align*}
	p(x) = \sum_{i = 1}^n y_i \prod_{j \neq i} \frac{x - x_j}{x_i - x_j}
\end{align*}
\end{theorem}

\section{Irreducibility Criteria}
\begin{lemma}[Gauss primitivity lemma]
If $R$ is a unique factorization domain (UFD), then the set of primitive polynomials in $R[x]$ is multiplicatively closed. Moreover, the content of a product is the product of each individual content (for polynomials).
\end{lemma}
\begin{corollary}[Gauss irreducibility lemma]
If $R$ is a unique factorization domain (UFD), and $F$ is its field of fractions then a non-constant polynomial in $R[x]$ is irreducible (in $R[x]$) if and only if it is irreducible in $F[x]$ and primitive in $R[x]$.
\end{corollary}
\begin{theorem}[Content of a polynomial]
Let $R$ be a commutative ring. The content $\operatorname{cont}(f)$ of a polynomial $f$ in $R[x]$ is the ideal (in $R$) generated by the coefficients of $f$. Then
\begin{enumerate}
	\item $\operatorname{cont}(fg) \subseteq \operatorname{cont}(f) \operatorname{cont}(g) \subseteq \sqrt{\operatorname{cont}(fg)}$
	\item If $R$ is a GCD domain, then $\gcd (\operatorname{cont}(fg)) = \gcd (\operatorname{cont}(f)) \gcd (\operatorname{cont}(g))$, where $\gcd(I)$ is the minimal principal ideal containing $I$ (it awalys exists and is unique for finitely generated ideal).
\end{enumerate}
\end{theorem}
\begin{theorem}[Eisenstein criterion]
If $D$ is an integral domain, and $f(x) = \sum_{i = 0}^n a_i x^i$ is a polynomial over $D$. If there is a prime ideal $\mathfrak{p}$ of $D$ such that
\begin{enumerate}
	\item $a_i \in \mathfrak{p}$ for $i \neq n$
	\item $a_n \notin \mathfrak{p}$
	\item $a_0 \notin \mathfrak{p}^2$
\end{enumerate}
then $f(x)$ is not the product of 2 non-constant polynomials in $D[x]$. As a result, if $f(x)$ is also primitive, then it is irreducible in $D[x]$.
\end{theorem}
\begin{theorem}[Cohn criterion]
If a prime number $p \in \mathbb{N}$ is expressed in base $b$ as $p = \sum_{i = 0}^n a_i b^i$, then $f(x) = \sum_{i = 0}^n a_i x^i$ is irreducible in $\mathbb{Z}[x]$.
\end{theorem}
\begin{theorem}[Perrion criterion]
Let $f(x) = \sum_{i = 0}^n a_i x^i$ be a polynomial over $\mathbb{Z}$ such that $a_0 \neq 0, a_n = 1$ (i.e. $f(x)$ is monic) and either one of the following conditions hold
\begin{enumerate}
	\item $|a_{n - 1}| > 1 + |a_{n - 2}| + \cdots + |a_0|$
	\item $|a_{n - 1}| \geq 1 + |a_{n - 2}| + \cdots + |a_0|$ and $f(\pm 1) \neq 0$
\end{enumerate}
Then $f(x)$ is irreducible over $\mathbb{Z}$.
\end{theorem}

\section{Constructible numbers}
Reference
\begin{enumerate}
	\item Rotman, Joseph J. (2006), \textit{A First Course in Abstract Algebra with Applications} (3rd ed.), Prentice Hall, ISBN 978-0-13-186267-8
	\item Kazarinoff, Nicholas D. (2003) [1970], \textit{Ruler and the Round /Classic Problems in Geometric Constructions}, Dover, ISBN 0-486-42515-0
	\item Gleason, Andrew M. (1988), \textit{Angle trisection, the heptagon, and the triskaidecagon}, American Mathematical Monthly, 95 (3): 185â194, doi:10.2307/2323624, MR 0935432. Footnote 8, p. 191. https://web.archive.org/web/20141105205944/http://apollonius.math.nthu.edu.tw/d1/ne01/jyt/linkjstor/regular/7.pdf\#3
	\item Roger C. Alperin; Robert J. Lang (2009). \textit{One-, Two-, and Multi-Fold Origami Axioms} (PDF). 4OSME. A K Peters.
\end{enumerate}

\subsection{Galois construction}
We say that an (geometric) operation is Galois if, whenever $\alpha$ is constructible from that operation (along with some basic construction), then any of its conjugates must also be constructible.
\begin{example}
	\item Straightedge
	\item Compass
	\item Trisector
\end{example}

\subsection{Straightedge and compass}
\subsection{Ruler and bisector}
\subsection{p-sector}
\subsection{Lang Origami}

\chapter{Calculus}
Reference
\begin{enumerate}
	\item Tran Phuong. \textit{Diamonds in Mathematical inequalities}. Viet Publishing.
\end{enumerate}

\begin{theorem}[Bertrand paradox]
The probability of choosing a chord on a unit circle so that its length is at least the length of a side of an inscribed equilateral triangle (which is $\sqrt{3}/2$) is $1/3$.
\end{theorem}
\begin{proof}
The probability is the ratio $\lambda (C_g)/ \lambda(A_g)$ where $C_g = \{ (x, y, z, w) : x^2 + y^2 = z^2 + w^2 = 1, (x - z)^2 + (y - w)^2 \geq 3/4 \}$, and $A_g = \{ (x, y, z, w) : x^2 + y^2 = z^2 + w^2 = 1 \}$.
\\
Let $g(\theta, \varphi) = (\cos \theta, \sin \theta, \cos \varphi, \sin \varphi)$ ($\theta, \varphi \in [0, 2\pi]$) be a parametrization of $A_g$. Then $C_g = \{ g(\theta, \varphi) : |\theta - \varphi| \in [2 \pi / 3, 4 \pi / 3] \}$ (by presenting $(\cos \theta, \sin \theta)$ and $(\cos \varphi, \sin \varphi)$ as 2 points on a unit circle, and find the distance between them).
\\
As $g_\theta = (-\sin \theta, \cos \theta, 0, 0)$ and $g_\varphi = (0, 0, -\sin \varphi, \cos \varphi)$, we get
\begin{align*}
\lambda(A_g) & = \int_0^{2 \pi} \int_0^{2 \pi} \sqrt{\det \begin{bmatrix}
g_\theta \cdot g_\theta & g_\theta \cdot g_\varphi \\
g_\varphi \cdot g_\theta & g_\varphi \cdot g_\varphi
\end{bmatrix}} d \theta d \varphi = \int_0^{2 \pi} \int_0^{2 \pi} d \theta d \varphi = 4\pi^2
\\
\lambda(C_g) & = \int_{\{(\theta, \varphi) : |\theta - \varphi| \in [2 \pi/3, 4 \pi/3] \}} d \theta d \varphi = 2 \int_{\{(\theta, \varphi) : \theta - \varphi \in [2 \pi/3, 4 \pi/3] \}} d \theta d \varphi
\\
& = 2 \cdot \frac{3}{18} \cdot 4 \pi^2 = \frac{4}{3} \pi^2
\end{align*}
So the probability is $1/3$.
\end{proof}
\begin{theorem}[Inequalities] \ 
\begin{enumerate}
	\item Bernoulli inequality:
	\begin{enumerate}
		\item $(1 + x)^r \geq 1 + rx$ for every integer $r \geq 0$ and real number $x \geq -1$. It is strict if $r \geq 2$ and $x \neq 0$.
		\item $(1 + x)^r \geq 1 + rx$ for every even integer $r \geq 0$ and real number $x$.
		\item $(1 + x)^r \geq 1 + rx$ for every real number $r \geq 1$ and $x \geq -1$. It is strict if $r \notin \{ 0, 1 \}$ and $x \neq 0$.
		\item $(1 + x)^r \leq 1 + rx$ for every real number $0 \leq r \leq 1$ and $x \geq -1$.
	\end{enumerate}
	\item Cauchy-Schwarz inequality (also called CauchyâBunyakovsky-Schwarz inequality): in an inner product space
	\begin{align*}
	|\langle u, v \rangle|^2 & \leq \langle u, u \rangle \cdot \langle v, v \rangle \mbox{ or}
	\\
	|\langle u, v \rangle| & \leq \| u \| \cdot \| v \|
	\end{align*}
	Special cases:
	\begin{enumerate}
		\item Sedrakyan lemma / Engel form / T2 lemma / Titu lemma: for $u_i, v_i > 0$
		\begin{align*}
		\sum_{i = 1}^n \frac{u_i^2}{v_i} \geq \frac{\left( \sum_{i = 1}^n u_i \right)^2}{\sum_{i = 1}^n v_i}
		\end{align*}
		\item In $\mathbb{R}^n$
		\begin{align*}
		\left( \sum_{i = 1}^n u_i v_i \right)^2 \leq \left( \sum_{i = 1}^n u_i^2 \right) \left( \sum_{i = 1}^n v_i^2 \right)
		\end{align*}
	\end{enumerate}
	\item Chebyshev inequality (also called the BienaymÃ©âChebyshev inequality): let
	\begin{enumerate}
		\item $t > 0$, and $0 < p < \infty$.
		\item $(X, \Sigma, \mu)$ be a measure space.
		\item $f: X \to [-\infty, \infty]$ is an extended real-valued measurable function on $X$.
		\item $g: (0, \infty) \to [0, \infty]$ is an extended real-valued measurable function and nondecreasing, with $g(t) \neq 0$
	\end{enumerate}
	then
	\begin{align*}
	\mu \{ x \in X : f(x) \geq t \} \leq \frac{1}{g(t)} \int_X g \circ f d \mu
	\end{align*}
	Special cases:
	\begin{enumerate}
		\item When $g(x) = |x|^p$ for $x \geq t$ and $0$ for $0 < x < t$
		\begin{align*}
		\mu \{ x \in X : |f(x)| \geq t \} \leq \frac{1}{t^p} \int_X |f|^p d \mu
		\end{align*}
		\item Probabilistic version: let $X$ (integrable) be a random variable with finite expected value $\mu$ and finite non-zero variance $\sigma^2$
		\begin{align*}
		\operatorname{Pr}(|X - \mu| \geq k \sigma) \leq \frac{1}{k^2}
		\end{align*}
		\item Discrete version: let $(a_i)_{i = 1}^n$ and $(b_i)_{i = 1}^n$ be monotonic sequences
		\begin{enumerate}
			\item If they are either all increasing, or all decreasing:
			\begin{align*}
			\frac{1}{n} \sum_{i = 1}^n a_i b_i \geq \left( \frac{1}{n} \sum_{i = 1}^n a_i \right) \left( \frac{1}{n} \sum_{i = 1}^n b_i \right)
			\end{align*}
			\item If one is increasing, and the other is decreasing:
			\begin{align*}
			\frac{1}{n} \sum_{i = 1}^n a_i b_i \leq \left( \frac{1}{n} \sum_{i = 1}^n a_i \right) \left( \frac{1}{n} \sum_{i = 1}^n b_i \right)
			\end{align*}
		\end{enumerate}
		There are also the continuous version: let $f, g : [a, b] \to \mathbb{R}$ be integrable functions
		\begin{enumerate}
			\item If they are either all increasing, or all decreasing:
			\begin{align*}
			\frac{1}{b - a} \int_a^b f(x) g(x) dx \geq \left( \frac{1}{b - a} \int_a^b f(x) dx \right) \left( \frac{1}{b - a} \int_a^b g(x) dx \right)
			\end{align*}
			\item If one is increasing, and the other is decreasing:
			\begin{align*}
			\frac{1}{b - a} \int_a^b f(x) g(x) dx \leq \left( \frac{1}{b - a} \int_a^b f(x) dx \right) \left( \frac{1}{b - a} \int_a^b g(x) dx \right)
			\end{align*}
		\end{enumerate}
	\end{enumerate}
	\item HÃ¶lder inequality: let $(S, \Sigma, \mu)$ be a measure space, and $p, q \in [1, \infty]$ be such that $1/p + 1/q = 1$ (i.e. they are HÃ¶lder conjugate). Then for all $f \in L^p (S)$ and $g \in L^q (S)$, we have $fg \in L^1 (S)$ and
	\begin{align*}
	\| fg \|_1 \leq \| f \|_p \cdot \| g \|_q
	\end{align*}
	Equality occurs if and only if $|f|^p$ and $|g|^q$ are linearly dependent in $L^1 (S)$ (i.e. $\alpha |f|^p = \beta |g|^q$ $\mu$-a.e. for some $\alpha^2 + \beta^2 \neq 0$).
	\\
	\\
	Special cases: in $\mathbb{R}^n$ or $\mathbb{C}^n$
	\begin{align*}
	\sum_{i = 1}^n |x_i y_i| \leq \left( \sum_{i = 1}^n |x_i|^p \right)^{1/p} \left( \sum_{i = 1}^n |y_i|^q \right)^{1/q}
	\end{align*}
	\item Karamata inequality / Majorization inequality: let $I$ be an interval and $f: I \to \mathbb{R}$ be a convex function. Suppose $x_k, y_k \in I$ such that $(x_1, \hdots, x_n)$ majorizes $(y_1, \hdots, y_n)$, i.e.
	\begin{enumerate}
		\item $x_1 \geq x_2 \geq \cdots \geq x_n$ and $y_1 \geq y_2 \geq \cdots \geq y_n$
		\item $x_1 + \cdots + x_k \geq y_1 + \cdots + y_k$ for $1 \leq k < n$.
		\item $x_1 + \cdots + x_n = y_1 + \cdots + y_n$
	\end{enumerate}
	then $f(x_1) + \cdots + f(x_n) \geq f(y_1) + \cdots + f(y_n)$. If $f$ is strictly convex, then equality holds iff $x_k = y_k$ for all $1 \leq k \leq n$.
	\item Jensen inequality: suppose $(\Omega, \mathcal{A}, \mu)$ is a measure space with finite measure (i.e. $\mu(\Omega) < \infty$). If $g: \Omega \to \mathbb{R}$ is integrable, and $\varphi: \mathbb{R} \to \mathbb{R}$ is convex (or at least on the image of $\Omega$ under $g$), then
	\begin{align*}
	\varphi \left( \frac{1}{\mu(\Omega)} \int_\Omega g d \mu \right) \leq \frac{1}{\mu(\Omega)} \int_\Omega \varphi \circ g d \mu
	\end{align*}
	Special cases: if $\lambda_i \geq 0$ such that $\sum_{i = 1}^n \lambda_i = 1$, then
	\begin{align*}
	\varphi \left( \sum_{i = 1}^n \lambda_i x_i \right) \leq \sum_{i = 1}^n \lambda_i \varphi(x_i)
	\end{align*}
	\item Minkowski inequality (or simply, the triangle inequality in $L^p$ space): if $f, g \in L^p (S, \Sigma, \mu)$ (with $1 \leq p \leq \infty$)
	\begin{align*}
	\| f + g \|_p \leq \| f \|_p + \| g \|_p
	\end{align*}
	Equality happens exactly when $f, g$ are linearly dependent in $L^p$.
	\\
	\\
	Special cases: for $x_i, y_i \in \mathbb{C}$
	\begin{align*}
	\left( \sum_{i = 1}^n |x_i + y_i|^p \right)^{1/p} \leq \left( \sum_{i = 1}^n |x_i|^p \right)^{1/p} + \left( \sum_{i = 1}^n |y_i|^p \right)^{1/p}
	\end{align*}
	\item Newton inequality: if $a_1, a_2, \hdots, a_n \in \mathbb{R}$, and $e_k(a_1, a_2, \hdots, a_n)$ denotes the $k$-th elementary symmetric polynomial (i.e. $e_k(a_1, a_2, \hdots, a_n) = \sum_{1 \leq j_1 < j_2 < \cdots < j_k \leq n} a_{j_1} a_{j_2} \cdots a_{j_k}$), then
	\begin{align*}
	S_{k - 1} S_{k + 1} \leq S_k^2
	\end{align*}
	where $S_k = e_k / {n \choose k}$. If all $a_i$ are non-zero, then equality holds iff all $a_i$ are equal.
	\item Maclaurin inequality: with the same $S_k$ as above, with all $a_i$ positive, then
	\begin{align*}
	S_1 \geq S_2^{1/2} \geq \cdots \geq S_n^{1/n}
	\end{align*}
	with equality if and only if all $a_i$ are equal.
	\item Young inequality: if $a, b \geq 0$, and $p, q > 1$ are HÃ¶lder conjugate, then
	\begin{align*}
	ab \leq \frac{a^p}{p} + \frac{b^q}{q}
	\end{align*}
	Equality occurs exactly when $a^p = b^q$.
	\item Muirhead inequality: given $a = (a_i)_{i = 1}^n, x = (x_i)_{i = 1}^n \in \mathbb{R}^n$ with $x_i > 0$, define
	\begin{align*}
		[a] = \frac{1}{n!} \sum_{\sigma} \prod_{i = 1}^n x_{\sigma_i}^{a_i}
	\end{align*}
	where the sum is over all permutation of $\{1, 2, \hdots, n \}$.
	\\
	\\
	Then, $[a] \leq [b]$ for all $x_i > 0$ if and only if there exists some doubly stochastic matrix $P$ such that $a = Pb$. Equality happens iff $a = b$ or all $x_i$ are equal to each other.
	\\
	\\
	The condition $a = Pb$ can be stated alternatively as follows: re-labeling indices in $a$ and $b$ so that $a_1 \geq a_2 \geq \cdots a_n$ and $b_1 \geq b_2 \geq \cdots b_n$, then $a = Pb$ for some doubly stochastic matrix $P$ if and only if $b$ majorizes $a$.
	\item Generalized mean inequality: let $-\infty \leq p \leq \infty$, we define the weighted $p$-mean of $x_i > 0$ with weight $w_i > 0$ as (for $\sum_{i = 1}^n w_i = 1$)
	\begin{enumerate}
		\item $M_{-\infty} (\vec{x}; \vec{w}) = \min_{i = 1}^n w_i x_i$
		\item $M_{\infty} (\vec{x}; \vec{w}) = \max_{i = 1}^n w_i x_i$
		\item $M_0 (\vec{x}; \vec{w}) = \prod_{i = 1}^n x_i^{w_i}$
		\item $M_p (\vec{x}; \vec{w}) = \left( \sum_{i = 1}^n w_i x_i^p \right)^{1/p}$ for $p \notin \{ 0, \pm \infty \}$.
	\end{enumerate}
	Then for $-\infty \leq p < q \leq \infty$, we have $M_p (\vec{x}; \vec{w}) \leq M_q (\vec{x}; \vec{w})$, with equality if and only if all $x_i$ where $w_i > 0$ are equal. Furthermore, $M_p (\vec{x}; \vec{w})$ is continuous in $p \in [-\infty, \infty]$. 
	\item Schur inequality: for all non-negative $x, y, z, t$
	\begin{align*}
		x^t (x - y)(x - z) + y^t (y - z)(y - x) + z^t (z - x)(z - y) \geq 0
	\end{align*}
	with equality if and only if $x = y = z$, or 2 of them are equal and the other is $0$. The inequality is also true if $t$ is an even positive integer, and $x, y, z$ are any real numbers.
	\item Rearrangement inequality: suppose $x_1 \leq x_2 \leq \cdots \leq x_n$ and $y_1 \leq y_2 \leq \cdots \leq y_n$, then for any permutation $\sigma$ of $\{ 1, 2, \hdots, n \}$
	\begin{align*}
	x_n y_1 + \cdots + x_1 y_n \leq x_{\sigma(1)} y_1 + \cdots + x_{\sigma(n)} y_n \leq x_1 y_1 + \cdots + x_n y_n
	\end{align*}
\end{enumerate}
\end{theorem}
\begin{theorem}[Abstract Concreteness Method] \ 
\begin{enumerate}
	\item Suppose $f(x, y, z)$ is a function that is either monotonic, convex, or concave in variable $x$ on $\mathbb{R}$, then $f(abc, ab + bc + ca, a + b + c)$ achieves extremum (with $ab + bc + ca$ and $a + b + c$ fixed) when 2 of 3 variables $a, b, c$ are equal.
	\item Suppose $f(x, y, z)$ is a function that is either monotonic, convex, or concave in variable $x$ on $[0, \infty)$, then $f(abc, ab + bc + ca, a + b + c)$ achieves extremum (with $ab + bc + ca$ and $a + b + c$ fixed) when 2 of 3 variables $a, b, c$ are equal, or one of them is $0$.
\end{enumerate}
\end{theorem}

\newpage

\chapter{Complex Analysis}
\begin{theorem}[RouchÃ© theorem]
\end{theorem}

\chapter{Abstract Vector Space}
Reference
\begin{enumerate}
	\item Paul Richard Halmos. \textit{Finite-Dimensional Vector Spaces}. Undergraduate Texts in Mathematics. Springer, 1974. ISBN: 0387900934.
	\item Walter Rudin. \textit{Real and Complex Analysis}. New York City, NY: McGraw Hill Education India, 2015. ISBN: 0070542341.
	\item Barry Simon. \textit{Notes on infinite determinants of Hilbert space operators}. In: Advances in Mathematics 24.3 (1977), pp. 244â273. ISSN: 0001-8708. DOI: https://doi.org/10.1016/0001-8708(77) 90057-3. URL: http://www.sciencedirect.com/science/article/pii/0001870877900573.
	\item Sergei Winitzki. \textit{Linear Algebra via Exterior Products}. 2010. ISBN: 140929496X.
	\item \href{https://math.stackexchange.com/questions/21614/is-there-a-definition-of-determinants-that-does-not-rely-on-how-they-are-calcula}{Is there a definition of determinants that does not rely on how they are calculated?}.
\end{enumerate}

\section{Algebraic Trace and Determinant}
\subsection{Inner product}
An \emph{involution}, or \emph{conjugation}, $\sigma: F \to F$ on a field $F$ is a field automorphism of order at most 2 (i.e. $\sigma^2 = 1_F$). Associated with an involution, is the modular valuation $N: F \to F, a \to a \sigma(a)$ which satisfies
\begin{enumerate}
	\item $N(0) = 0$ and $N(1) = N(-1) = 1$.
	\item Multiplicative: $N(ab) = N(a) N(b)$.
	\item Invariant under involution: $N(a) = N(\sigma(a)) = \sigma(N(a))$.
\end{enumerate}
A $\sigma$-inner product on a vector space $V$ over $F$ is a map $\langle \cdot, \cdot \rangle : V \times V \to F$ such that
\begin{enumerate}
	\item $\sigma$-symmetry: for all $x, y \in V$,
	$$\langle x, y \rangle = \sigma (\langle y, x \rangle)$$
	\item Linearity in 1st argument: for all $x, y, z \in V$ and $a \in F$
	$$\langle x + ay, z \rangle = \langle x, z \rangle + a \langle y, z \rangle$$
	\item Modular definitness:
	\begin{enumerate}
		\item For each $x \in V$, there exists some $a \in F$ such that $\langle x, x \rangle = N(a)$.
		\item If $\langle x, x \rangle = 0$, then $x = 0$.
	\end{enumerate}
\end{enumerate}
A vector space with such inner product is called a $\sigma$-inner product space (or just inner product space given the context)
\begin{proposition} \ 
\begin{enumerate}
	\item The orthogonality relation is symmetric: $\langle x, y \rangle = 0$ iff $\langle y, x \rangle = 0$.
	\item Non-degeneracy: if $\langle x, y \rangle = 0$ for all $y \in V$ then $x = 0$. Similarly, if $\langle x, y \rangle = 0$ for all $x \in V$ then $y = 0$.
	\item $\sigma$-linearity in 2nd argument: for all $x, y, z \in V$ and $a \in F$
	$$\langle x, y + az \rangle = \langle x, y \rangle + \sigma(a) \langle x, z \rangle$$
\end{enumerate}
\end{proposition}
\begin{example} \ 
\begin{enumerate}
	\item The standard Euclidean inner is the inner product when $\sigma$ is the identity on $\mathbb{R}$. In fact, it is the only field automorphism on $\mathbb{R}$.
	\item The Hermitian inner product is the inner product when $\sigma(z) = \overline{z}$. Along with the identity map, these 2 involutions comprise all field automorphisms on $\mathbb{C}$ such that $\mathbb{R}$ is fixed.
\end{enumerate}
\end{example}
\begin{theorem}[Riesz representation theorem]
Given $V$ a finite-dimensional $\sigma$-inner product space, and $V^*$ its (algebraic) dual, then for each functional $f$ in $V^*$, there exists a unique $\alpha$ in $V$ such that $f(v) = \langle v, \alpha \rangle$ for all $v \in V$.
\end{theorem}
\begin{proof}
Denote $\Phi_\alpha (v) = \langle v, \alpha \rangle$, then by non-degeneracy
\begin{align*}
\Phi_\alpha = \Phi_\beta \leftrightarrow \langle v, \alpha - \beta \rangle = 0, \forall v \in V \leftrightarrow \alpha = \beta
\end{align*}
Thus, the right-multiplication map $\Phi: V \to V^*$ is injective, which is also bijective since $V$ is finite-dimensional. Note that $\Phi$ is also $\sigma$-linear, that is
$$\Phi_{x + cy} = \Phi_x + \sigma(c) \Phi_y$$
\end{proof}

\subsection{Trace}
Let $\mathcal{L}(V, W)$ be the space of all linear maps from $V$ to $W$, and $V^* = \mathcal{L} (V, F)$ be the dual space of $V$.
\begin{theorem}
The map $\eta : V^* \otimes W \to \mathcal{L}(V, W)$, where $\eta(\alpha \otimes w)(v) = \alpha(v) w$ (and extends linearly), is a canonical embedding.
\end{theorem}
The image $\eta$, sometimes identified with $V^* \otimes W$, is called \emph{space of trace class maps} (from $V$ to $W$), and denoted as $\operatorname{Tr}(V, W) = \eta(V^* \otimes W)$. When $V = W$, and $T = \eta \left( \sum_i c_i \alpha_i \otimes v_i \right)$ then the \emph{trace} of $T$ is defined as
$$\operatorname{tr}(T) = \sum_i c_i \alpha_i(v_i)$$
Clearly the trace is a linear map from $\operatorname{Tr}(V) = \operatorname{Tr}(V, V)$ to $F$.
\begin{proposition}[Properties of trace] \ 
\begin{enumerate}
	\item Linearity: if $T, S$ are trace-class and $c \in F$, then $T + cS$ is also trace-class. Additionally, when $V = W$, we have
	$$\operatorname{tr}(T + cS) = \operatorname{tr}(T) + c \operatorname{tr}(S)$$
	\item Closed under composition: if $T: V \to W$ and $S : U \to V$ are trace-class, then $T \circ S : U \to W$ is also trace-class. Hence, $\operatorname{Tr}(V)$ is a rng (a ring without multiplicative identity).
	\item Invariant under cyclic composition, if $T: V \to W$ and $S: W \to V$ are trace-class, then
	$$\operatorname{tr}(TS) = \operatorname{tr}(ST)$$
	\item Identity as trace-class: the identity is a trace-class operator iff $V$ is finite-dimensional. Therefore, the vector spaces (including infinite-dimensional ones) with trace-class maps as morphisms will not form a category.
	\item Transpose: the dual $T^*$ is trace-class if and only if $T$ is trace-class. If so, we also get $\operatorname{tr}(T) = \operatorname{tr}(T^*)$.
	\item Adjoint [???]
	\item Direct sum: the direct sum of trace-class maps is again trace-class, and $\operatorname{tr}(T \oplus S) = \operatorname{tr}(T) + \operatorname{tr}(S)$
	\item Tensor product: the tensor product of trace-class maps is also trace-class, and $\operatorname{tr}(T \otimes S) = \operatorname{tr}(T) \operatorname{tr}(S)$
\end{enumerate}
\end{proposition}
\begin{theorem}[Characteriztion of Trace Class Operators]
An operator $T: V \to W$ is trace class if and only if it has finite rank, i.e. its image is finite-dimensional.
\end{theorem}
\begin{corollary}
All linear maps $V \to W$ are trace class if and only if either $V$ or $W$ has finite dimension.
\end{corollary}
\begin{corollary}[Computation of trace]
Let $T: V \to V$ be a linear operator with finite rank, and suppose $\beta = \{ v_1, v_2, \hdots, v_n \}$ is a basis of $T(V)$ with $\beta^*$ is an extension of $\beta$ to a basis of the whole $V$. If $f_i$ is the coefficient of $v_i$ in $T(v_i)$ then
$$\operatorname{tr}(T) = \sum_{i = 1}^n f_i$$
\end{corollary}

\subsection{Determinant}
Let $V^I$ be the vector space of all functions $f: I \to V$. A map $\phi: V^I \to F$ is called
\begin{enumerate}
	\item Multilinear if for all $k \in I$ and $(\alpha_i)_{i \in I}, (\beta_i)_{i \in I} \in V^I$ and $c \in F$ such that $\alpha_i = \beta_i$ for all $i \neq k$, we have $\phi(\gamma) = \phi(\alpha) + c \phi(\beta)$ where $\gamma_i = \alpha_i$ for $i \neq k$ but $\gamma_k = \alpha_k + c \beta_k$.
	\item Alternating if for any $(\alpha_i)_{i \in I} \in V^I$ such that $\alpha_n = \alpha_m$ for some $n \neq m \in I$, then $\phi(\alpha) = 0$.
	\item Symmetric if for any transpose map $\tau: I \to J$, $\phi(\alpha) = \phi(\alpha \circ \tau)$
	\item Anti-symmetric if for any transpose map $\tau: I \to J$, $\phi(\alpha) = -\phi(\alpha \circ \tau)$
\end{enumerate}
The space of all alternating multilinear maps (of arity $I$) is denoted as $\Lambda^I V$.
\begin{proposition}
If $(\alpha_i)_{i \in I}$ are dependent vectors in $V$, then $\phi(\alpha) = 0$ for all alternating multilinear map. As a result, $\Lambda^I V = 0$ if the cardinality of $I$ is strictly greater than the dimension of $V$.
\end{proposition}
\begin{proposition}[Independent of indices]
If $I$ is equinumerous to $J$, then $\Lambda^I V$ is isomorphic to $\Lambda^J V$.
\end{proposition}
\begin{theorem}
If $\dim V = |I|$, then $\Lambda^I V$ is one-dimensional.
\end{theorem}
\begin{theorem} \ 
\begin{enumerate}
	\item Transpose: $T$ is determinant-class iff its dual is determinant-class, and $\det T = \det T^*$.
	\item Adjoint: $T$ is determinant-class iff its adjoint is determinant-class, and $\det T = \det T^\sigma$.
	\item Direct sum
	\item Tensor product
	\item Fredholm property: if $T: V \to V$ is trace-class, then $1_V + T$ is determinant-class.
\end{enumerate}
\end{theorem}
\begin{proposition} \ 
\begin{enumerate}
	\item Trace-class operators are stable under conjugation
	\begin{enumerate}
		\item Given $T: V \to W$ trace-class and $U: V \to W$ an isomorphism, $UTU^{-1}$ is also trace-class
		\item $\det (1_V + T) = \det (1_W + UTU^{-1})$
	\end{enumerate}
	\item Sylvester determinant theorem: if $T: V \to W$ and $S: W \to V$ are trace-class, then
	$$\det (1_W + ST) = \det(1_V + ST)$$
\end{enumerate}
\end{proposition}

\section{Volumetric space}
\subsection{Simplicial volume on a vector space}
A map $d_n: V^{n + 1} \to \mathbb{R}$ is an $n$-volume of a vector space $V$ if
\begin{enumerate}
	\item Non-negative: $d_n(x_0, x_1, \hdots, x_n) \geq 0$ for all $x_i \in V$.
	\item Symmetry: $d_n (x_{\sigma(0)}, x_{\sigma(1)}, \hdots, x_{\sigma(n)}) = d_n(x_0, x_1, \hdots, x_n)$ for any permutation $\sigma \in S_{n + 1}$.
	\item Triangle inequality: if $\Delta$ denotes the collection of all subsets of $\{ 0, 1, 2, \hdots, n + 1 \}$ of size $n + 1$, and $P \in \Delta$, then
	$$\sum_{I \neq P, I \in \Delta} d_n (x_i)_{i \in I} \geq d_n (x_i)_{i \in P}$$
	\item Translational invariance: $d_n (x_0 + v, x_1 + v, \hdots, x_n + v) = d_n(x_0, x_1, \hdots, x_n)$ for all $x_i, v \in V$.
	\item Homogeneity: $d_n (0, \alpha x_1, x_2, \hdots, x_n) = |\alpha| d_n(0, x_1, x_2, \hdots, x_n)$ for all $x_i \in V$ and $\alpha \in F$.
\end{enumerate}
A family of $n$-volumes (for $m \geq n \geq 1$) on $V$ is geometrically compatible if
\begin{enumerate}
	\item $d_1 (x, y) = 0$ if and only if $x = y$.
	\item $d_n (x_0, x_1, \hdots, x_n) = 0$ if and only if for some $P \in \Delta$, $\sum_{I \neq P} d_{n - 1} (x_i)_{i \in I} = d_{n - 1} (x_i)_{i \in P}$.
\end{enumerate}
\begin{proposition}
If $x_0, x_1, \hdots, x_n$ are linearly dependent, then $d_n (x_0, x_1, \hdots, x_n) = 0$.
\end{proposition}

\subsection{Gramian volume}
Given $V$ a Hilbert space, the Gramian volume of $x_1, \hdots, x_n$ is
$$\frac{1}{n!} \sqrt{\det \begin{bmatrix}
\langle x_1, x_1 \rangle & \langle x_1, x_2 \rangle & \cdots & \langle x_1, x_n \rangle \\
\langle x_2, x_1 \rangle & \langle x_2, x_2 \rangle & \cdots & \langle x_2, x_n \rangle \\
\vdots & \vdots & \ddots & \vdots \\
\langle x_n, x_1 \rangle & \langle x_n, x_2 \rangle & \cdots & \langle x_n, x_n \rangle
\end{bmatrix}}$$

\subsection{Cayley-Menger volume}
In a metric space $M$, let $d_{ij} = d(x_i, x_j)$, then the Cayley-Menger volume is
$$\sqrt{\frac{1}{(n!)^2 2^n} \det \begin{bmatrix}
2 d_{01}^2 & d_{01}^2 + d_{02}^2 - d_{12}^2 & \cdots & d_{01}^2 + d_{0n}^2 - d_{1n}^2 \\
d_{01}^2 + d_{02}^2 - d_{12}^2 & 2 d_{02}^2 & \cdots & d_{02}^2 + d_{0n}^2 - d_{2n}^2 \\
\vdots & \vdots & \ddots & \vdots \\
d_{01}^2 + d_{0n}^2 - d_{1n}^2 & d_{02}^2 + d_{0n}^2 - d_{2n}^2 & \cdots &  2 d_{0n}^2
\end{bmatrix}}$$
$$= \sqrt{\frac{(-1)^{n + 1}}{(n!)^2 2^n} \det \begin{bmatrix}
0 & d_{01}^2 & d_{02}^2 & \cdots & d_{0n}^2 & 1 \\
d_{01}^2 & 0 & d_{12}^2 & \cdots & d_{1n}^2 & 1 \\
d_{02}^2 & d_{12}^2 & 0 & \cdots & d_{2n}^2 & 1 \\
\vdots & \vdots & \ddots & \vdots \\
d_{0n}^2 & d_{1n}^2 & d_{2n}^2 & \cdots & 0 & 1 \\
1 & 1 & 1 & \cdots & 1 & 0
\end{bmatrix}}$$
\end{shaded}

\begin{shaded}
\chapter{Algebraic Number Theory}
\begin{theorem}[Pell equation]
Let $x^2 - n y^2 = 1$ be a Pell equation (with $n$ fixed and square-free)
\begin{enumerate}
	\item If $[a_0; a_1, a_2, \cdots]$ is the continued fraction of $\sqrt{n}$, then some convergent $x_1/y_1$ will satisfy the equation. The smallest $(x_1, y_1)$ with respect to the first coordinate is called the fundamental solution.
	\item All remaning solution can be found by taking the power of the fundamental solution: if $x_k + y_k \sqrt{n} = (x_1 + y_1 \sqrt{n})^k$, then $(x_k, y_k)$ is a solution. Vice versa, if $(a, b)$ is a solution, then $a + b \sqrt{n} = (x_1 + y_1 \sqrt{n})^k$ for some positive integer $k$. A recurrence relation for $x_k$ and $y_k$ is described below
\begin{align*}
x_{k + 1} & = x_1 x_k + n y_1 y_k \\
y_{k + 1} & = x_1 y_k + y_1 x_k
\end{align*}
\end{enumerate}
\end{theorem}
\begin{lemma}[BÃ©zout identity]
If $\gcd(a, b) = d$ then $\{ ax + by : x, y \in \mathbb{Z} \} = d \mathbb{Z}$.
\end{lemma}
\begin{lemma}[Hensel lemma]
Let $\mathfrak{m}$ be a maximal ideal of a commutative ring $R$, $h(x) = a_0 x^n + \cdots + a_{n - 1} x + a_n$ be a polynomial over $R$ such that the leading coefficient $a_0$ is not in $\mathfrak{m}$. Then every factorization of $h(x)$ modulo $\mathfrak{m}$ (note that $(R/\mathfrak{m})[x]$ is a PID) can be lifted uniquely into a factorization modulo $\mathfrak{m}^k$ for each $k \geq 1$.
\\
\\
More precisely, if $h(x) \equiv a_0 f(x) g(x) \pmod{\mathfrak{m}}$ where $f, g$ are monic and coprime modulo $\mathfrak{m}$, then there exists unique monic polynomials $f_k, g_k$ (modulo $\mathfrak{m}^k$) for each $k \geq 1$ such that
\begin{align*}
h(x) & \equiv a_0 f_k (x) g_k(x) \pmod{\mathfrak{m}^k} \\
f_k(x) & \equiv f(x) \pmod{\mathfrak{m}} \\
g_k(x) & \equiv g(x) \pmod{\mathfrak{m}}
\end{align*}
\end{lemma}
\begin{lemma}[Lifting the exponent - LTE]
Let $x, y$ be integers, $n, p$ be positive integers, where $p$ is a prime such that it does not divide $x$ and $y$. Then
\begin{enumerate}
	\item If $p$ is odd:
	\begin{enumerate}
		\item If $p \mid x - y$: $\nu_p (x^n - y^n) = \nu_p (x - y) + \nu_p(n)$
		\item If $n$ is odd and $p \mid x + y$: $\nu_p (x^n + y^n) = \nu_p(x + y) + \nu_p(n)$
	\end{enumerate}
	\item If $p = 2$:
	\begin{enumerate}
		\item If $4 \mid x - y$: $\nu_2 (x^n - y^n) = \nu_2 (x - y) + \nu_2 (n)$
		\item If $2 \mid x - y$ and $n$ is even: $\nu_2 (x^n - y^n) = \nu_2 (x - y) + \nu_2 (x + y) + \nu_2 (n) - 1$
	\end{enumerate}
\end{enumerate}
\end{lemma}
\begin{theorem}[Chinese Remainder Theorem]
If $I_1, I_2, \hdots, I_n$ are pairwise coprime ideals of a commutative ring $R$ (i.e. the sum of ideals is equal to $R$), then
\begin{align*}
R/\bigcap_{k = 1}^n I_k \cong \prod_{k = 1}^n R/I_k
\end{align*}
\end{theorem}
\begin{theorem}[Sylvester Coinage Theorem]
Let $a, b$ be relatively prime positive integers, then
\begin{enumerate}
	\item $(a - 1)(b - 1) - 1$ is largest number that is not a sum of nonnegative multiplies of $a$ and $b$.
	\item There are $(a - 1)(b - 1)/2$ of such numbers.
\end{enumerate}
\end{theorem}
\begin{theorem}[Wilson Theorem]
$n$ is prime if and only if $(n - 1)! \equiv -1 \pmod{n}$.
\end{theorem}
\begin{theorem}[Fermat 2-square theorem]
An odd prime $p$ is a sum of 2 squares if and only if $p \equiv 1 \pmod{4}$. In the language of algebra, all prime $p \equiv 1 \pmod{4}$ is not prime as Gaussian integers $\mathbb{Z}[i]$.
\end{theorem}
\begin{proof}
If $p = x^2 + y^2$, then we can check the cases of $x$ and $y$ modulo $4$ to show that $p \equiv 1 \pmod{4}$. As for the converse, we first have $(p - 1)! \equiv -1 \pmod{p}$ by Wilson theorem, or
\begin{align*}
\left[ \left( \frac{p - 1}{2} \right)! \right]^2 (-1)^{(p - 1)/2} \equiv -1 \pmod{p}
\end{align*}
Since $p \equiv 1 \pmod{4}$, $\left[ \left( \frac{p - 1}{2} \right)! \right]^2 \equiv -1 \pmod{p}$. In other words, there exists some $m$ such that $m^2 + 1$ is divisible by $p$. Consider the set $\{ am + b : 0 \leq a, b \leq \lceil \sqrt{p} \rceil - 1 \}$: it has $\lceil \sqrt{p} \rceil > p$ elements, so by pigeonhole principle, there exists some $a_1, a_2, b_1, b_2 \in [0, \lceil \sqrt{p} \rceil - 1]$ such that
\begin{align*}
a_1 m + b_1 & \equiv a_2 m + b_2 \pmod{p}, \mbox{ or} \\
(a_1 - a_2)^2 m^2 & \equiv (b_1 - b_2)^2 \pmod{p}
\end{align*}
Since $m^2 \equiv -1 \pmod{p}$, we get $(a_1 - a_2)^2 + (b_1 - b_2)^2 \equiv 0 \pmod{p}$. On the other hand, $(a_1 - a_2)^2 + (b_1 - b_2)^2 \leq 2 ( \lceil \sqrt{p} \rceil - 1)^2 < 2p$, so the only possible values for the expression $(a_1 - a_2)^2 + (b_1 - b_2)^2$ is $p$ (as it is divisible by $p$).
\end{proof}
\end{shaded}

\section{Euler totient theorem}
In March 2015, when the author was in preparation for 2015 Vietnam Team Selection Test (TST) in April, one of his coaches and teachers (Tran Nam Dung) gave this problem as an exercise: let $(f_n)_{n \in \mathbb{N}}$ be a sequence defined recursively as
\begin{enumerate}
	\item $f_1 = a, f_2 = a^2 - 2b$ where $a, b$ are non-negative integers.
	\item $f_{n + 2} = a f_{n + 1} - b f_n$
\end{enumerate}
Show that
\begin{enumerate}
	\item For any prime $p$ and any non-negative integer $m$, $f_{p^{m + 1}} \equiv f_{p^m} \pmod{p^{m + 1}}$
	\item Does $f_{n + \varphi(n)} \equiv f_n \pmod{n + \varphi(n)}$ for all $n$?
\end{enumerate}
2nd part is fairly easy, just choose $n = 4$ with specific $a$ and $b$ as a counterexample. Even if one change the modulus $n + \varphi(n)$ to $n$, $n = 4$ can still provide a counterexample. Even still, the correct form $f_{n - \varphi(n)} \equiv f_n \pmod{n - \varphi(n)}$ has $n = 6$ as a counterexample for some $a$ and $b$.
\\
\\
We will show an even stronger statement
\begin{theorem} \label{sum-eul-totient}
Let $K$ be an (algebraic) number field (i.e. finite extension of $\mathbb{Q}$) and $\mathcal{O}_K$ be its ring of integers. If $\alpha_1, \alpha_2, \hdots, \alpha_k$ are roots (multiplicity counted) of the polynomial equation
$$x^k = c_1 x^{k - 1} + c_2 x^{k - 2} + \cdots + c_{k - 1} x + c_k$$
over $K$ (i.e. $c_i \in K$). Let $f_n = \sum_{i = 1}^k \alpha_i^n$, then
\begin{enumerate}
	\item  $f_n \in K$ for all $n \in \mathbb{N}$.
	\item Recall the norm $N(I)$ of an ideal is the cardinality of its residue $\mathcal{O}_K / I$. Show that for a prime ideal $\mathfrak{p}$ and $t \geq 0$ such that $v_\mathfrak{p} (c_i) \geq 0$ (for $1 \leq i \leq k$), we get
	$$f_{N(\mathfrak{p})^{t + 1}} \equiv f_{N(\mathfrak{p})^t} \pmod{\mathfrak{p}^{t + 1}}$$
\end{enumerate}
\end{theorem}
To prove, we introduce the following lemmas
\begin{lemma}[Newton identities on symmetric polynomial] \label{newt-id-sym-poly}
Define
\begin{enumerate}
	\item The elementary polynomials $e_k (x_1, x_2, \hdots, x_n)$
	\begin{align*}
	e_k (x_1, x_2, \hdots, x_n) & = \begin{cases}
		0 & \mbox{ if } k < 0 \\
		1 & \mbox{ if } k = 0 \\
		\sum_{1 \leq i_1 < i_2 < \cdots i_k \leq n} x_{i_1} x_{i_2} \cdots x_{i_k} & \mbox{ if } 1 \leq k \leq n \\
		0 & \mbox{ if } k > n
	\end{cases}
	\end{align*}
	\item The power sum polynomials $p_m (x_1, x_2, \hdots, x_n) = \sum_{i = 1}^n x_i^m$.
\end{enumerate}
Then for integer $m \geq 1$
\begin{align*}	
p_m & = m \sum_{\substack{r_1 + 2r_2 + \cdots + n r_n = m \\ r_1, r_2, \hdots, r_n \geq 0}} (-1)^m \frac{(r_1 + r_2 + \cdots + r_n - 1)!}{r_1! r_2! \cdots r_n!} \prod_{i = 1}^n (-e_i)^{r_i}
\end{align*}
\end{lemma}
\begin{proof}
It could be proven using induction, but we will use the generating function method (Example 11, chapter 8, pp.169-172 in [Titu Andreescu and Gabriel Dospinescu. Problems from the book. Plano, TX: XYZ Press, 2008. ISBN: 978-0-9799269-0-7]).
\\
\\
Fix $x_i$ and write $e_i = e_i (x_1, x_2, \hdots, x_n), p_m = p_m (x_1, x_2, \hdots, x_n)$. By ViÃ¨te formula
\begin{align*}
P(z) & = \frac{1}{\sum_{i = 0}^n (-1)^i e_i z^i} = \prod_{i = 1}^n \frac{1}{1 - x_i z}
\end{align*}
We then compute its logarithm in 2 different ways. Firstly,
\begin{align*}
\ln P(z) & = - \sum_{i = 1}^n \ln (1 - x_i z) \\
& = \sum_{i = 1}^n \sum_{k = 1}^\infty \frac{(x_i z)^k}{k} \\
& = \sum_{k = 1}^\infty \frac{z^k}{k} \sum_{i = 1}^n x_i^k \\
& = \sum_{k = 1}^\infty \frac{p_k}{k} z^k
\end{align*}
On the other hand, by the multinomial formula
\begin{align*}
\ln P(z) & = - \ln \sum_{i = 0}^n (-1)^i e_i z^i \\
& = - \ln \left( 1 - \sum_{i = 1}^n (-1)^{i + 1} e_i z^i \right) \\
& = \sum_{m = 1}^\infty \frac{1}{m} \left( \sum_{i = 1}^n (-1)^{i + 1} e_i z^i \right)^m \\
& = \sum_{m = 1}^\infty \frac{1}{m} \sum_{\substack{r_1 + r_2 + \cdots + r_n = m \\ r_1, r_2, \hdots, r_n \geq 0}} {m \choose r_1, r_2, \hdots, r_n} \prod_{i = 1}^n \left[ (-1)^{i + 1}  e_i z^i\right]^{r_i} \\
& = \sum_{m = 1}^\infty \sum_{\substack{r_1 + r_2 + \cdots + r_n = m \\ r_1, r_2, \hdots, r_n \geq 0}} \frac{(m - 1)!}{r_1! r_2! \cdots r_n!} \prod_{i = 1}^n (-1)^{i r_i} (-e_i)^{r_i} z^{i r_i} \\
& = \sum_{r_1, r_2, \hdots, r_n \geq 0} \frac{(r_1 + r_2 + \cdots + r_n - 1)!}{r_1! r_2! \cdots r_n!} \prod_{i = 1}^n (-1)^{i r_i} (-e_i)^{r_i} z^{i r_i} \\
\end{align*}
Comparing the coefficient of $z^k$, we get
\begin{align*}
\frac{p_k}{k} & = \sum_{\substack{r_1 + 2r_2 + \cdots + n r_n = m \\ r_1, r_2, \hdots, r_n \geq 0}} \frac{(r_1 + r_2 + \cdots + r_n - 1)!}{r_1! r_2! \cdots r_n!} \prod_{i = 1}^n (-1)^{i r_i} (-e_i)^{r_i} \\
& = \sum_{\substack{r_1 + 2r_2 + \cdots + n r_n = m \\ r_1, r_2, \hdots, r_n \geq 0}} (-1)^m \frac{(r_1 + r_2 + \cdots + r_n - 1)!}{r_1! r_2! \cdots r_n!} \prod_{i = 1}^n (-e_i)^{r_i} \\
\end{align*}
\end{proof}
\begin{lemma}[Euler totient theorem] \label{eul-totient-thm}
For any $\omega \in K, t \in \mathbb{N}$ and prime ideal $\mathfrak{p}$ of $\mathcal{O}_K$ such that $v_\mathfrak{p}(\omega) \geq 0$, we have
$$\omega^{N(\mathfrak{p})^{t + 1}} \equiv \omega^{N(\mathfrak{p})^t} \pmod{\mathfrak{p}^{t + 1}}$$
\end{lemma}
\begin{proof}
We first show for $\omega \in \mathcal{O}_K \setminus \mathfrak{p}$, then $\omega \in \mathcal{O}_K$, and finally $\omega \in K$.
\\
\\
*Assuming $\omega \in \mathcal{O}_K \setminus \mathfrak{p}$, we consider the multiplication map by $\omega$ on the multiplicative group of $\mathcal{O}_K / \mathfrak{p}^{t + 1}$
$$f (x + \mathfrak{p}^{t + 1}) = \omega x + \mathfrak{p}^{t + 1}$$
\begin{enumerate}
	\item Well-defined: we prove that $\omega + \mathfrak{p}^{t + 1}$ is also a unit of $\mathcal{O}_K / \mathfrak{p}^{t + 1}$ (and so for). Since $\omega \notin \mathfrak{p}$, $\omega + \mathfrak{p}$ is non-zero in $\mathcal{O}_K / \mathfrak{p}$. But $\mathfrak{p}$ is maximal (as $\mathcal{O}_K$ is a Dedekind domain), so $\mathcal{O}_K / \mathfrak{p}$ is a field, meaning that $\omega + \mathfrak{p}$ is invertible in $\mathcal{O}_K / \mathfrak{p}$.
	\\
	\\
	Let $\gamma + \mathfrak{p}$ be its (multiplicative) inverse, i.e. $\omega \gamma + \pi  = 1$ for some $\pi \in \mathfrak{p}$. Now define the following sequences
	\begin{align*}
	\begin{cases}
		y_1 = \gamma, & p_1 = \pi \\
		y_n = \pi y_{n - 1} + \gamma, & p_n = \pi p_{n - 1}
	\end{cases}
	\end{align*}
	Using induction, we have $p_n = \pi^n$ and
	$$\omega y_n  + p_n = \omega (\pi y_{n - 1} + \gamma) + \pi p_{n - 1} = \omega \gamma + \pi (\omega y_{n - 1} + p_{n - 1}) = \omega \gamma + \pi = 1$$
	In other words, $\omega y_n + \pi^n = 1$, so $\omega + \mathfrak{p}^n$ is invertible in $\mathcal{O}_K / \mathfrak{p}^n$ for each $n \in \mathbb{N}$.
	\item Bijective: since $\omega + \mathfrak{p}^{t + 1}$ is invertible in $\mathcal{O}_K / \mathfrak{p}^{t + 1}$, there exists some $\gamma \in \mathcal{O}_K$ such that $\omega \gamma \equiv 1 \pmod{\mathfrak{p}^{t + 1}}$. Then the inverse of $f$ is given by
	$$f^{-1} (x + \mathfrak{p}^{t + 1}) = \gamma x + \mathfrak{p}^{t + 1}$$
	Indeed, $f \circ f^{-1} (x + \mathfrak{p}^{t + 1}) = \omega (\gamma x) + \mathfrak{p}^{t + 1} = x + \mathfrak{p}^{t + 1}$ and similarly, $f^{-1} \circ f  (x + \mathfrak{p}^{t + 1}) = \gamma (\omega x) + \mathfrak{p}^{t + 1} = x + \mathfrak{p}^{t + 1}$.
\end{enumerate}
On the other hand, $\mathcal{O}_K / I$ is finite for any ideal $I$, so $(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times$ is also finite, and since $f: (\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times \to (\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times$ is bijective, we get
\begin{align*}
\prod_{x + \mathfrak{p}^{t + 1} \in (\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times} x + \mathfrak{p}^{t + 1} & = \prod_{x + \mathfrak{p}^{t + 1} \in (\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times} \omega x + \mathfrak{p}^{t + 1} \\
\omega^{|(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times|} r & \equiv r \pmod{\mathfrak{p}^{t + 1}} \\
\omega^{|(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times|} & \equiv 1 \pmod{\mathfrak{p}^{t + 1}}
\end{align*}
where $r$ is some number in $\mathcal{O}_K$ such that $r + \mathfrak{p}^{t + 1} = \prod_{x + \mathfrak{p}^{t + 1} \in (\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times} x + \mathfrak{p}^{t + 1} \in (\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times$ (since the multiplicative group ... is a group).
\\
\\
To conclude the case, we need to compute the cardinality of $(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times$.
\begin{enumerate}
	\item If $\theta + \mathfrak{p}^{t + 1}$ is not an invertible element of $\mathcal{O}_K / \mathfrak{p}^{t + 1}$, then $\theta$ must be in $\mathfrak{p}$. Otherwise, just as we have shown above for $\omega$, $\theta + \mathfrak{p}^{t + 1}$ is also an invertible element, a contradiction. Thus, $\theta + \mathfrak{p}^{t + 1}$ must belong to $\mathfrak{p} / \mathfrak{p}^{t + 1}$.
	\item Vice versa, $\theta + \mathfrak{p}^{t + 1} \in \mathfrak{p} / \mathfrak{p}^{t + 1}$, then $\theta \in \mathfrak{p}$ by definition. But then $\theta^{t + 1} \in \mathfrak{p}^{t + 1}$, i.e. $\theta + \mathfrak{p}^{t + 1}$ is a nilpotent element of $\mathcal{O}_K / \mathfrak{p}^{t + 1}$. In particular, it cannot be in $(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times$.
	\item Hence, $\mathcal{O}_K / \mathfrak{p}^{t + 1}$ is a disjoint union of its multiplicative group, and $\mathfrak{p} / \mathfrak{p}^{t + 1}$.
	$$N(\mathfrak{p})^{t + 1} = |\mathcal{O}_K / \mathfrak{p}^{t + 1}| = |(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times| + |\mathfrak{p} / \mathfrak{p}^{t + 1}|$$
	On the other hand, by the 3rd isomorphism theorem for ring $(\mathcal{O}_K / \mathfrak{p}^{t + 1})/(\mathfrak{p} / \mathfrak{p}^{t + 1}) \cong \mathcal{O}_K / \mathfrak{p}$, so
	$$|\mathfrak{p} / \mathfrak{p}^{t + 1}| = \frac{|(\mathcal{O}_K / \mathfrak{p}^{t + 1})|}{|(\mathcal{O}_K / \mathfrak{p})|} = N(\mathfrak{p})^t$$
	and
	$$|(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times| = N(\mathfrak{p})^{t + 1} - N(\mathfrak{p})^t$$
\end{enumerate}
Rewriting the previous congruence, we obtain the following
\begin{align*}
\omega^{N(\mathfrak{p})^{t + 1} - N(\mathfrak{p})^t} & \equiv 1 \pmod{\mathfrak{p}^{t + 1}} \\
\omega^{N(\mathfrak{p})^{t + 1}} & \equiv \omega^{N(\mathfrak{p})^t} \pmod{\mathfrak{p}^{t + 1}}
\end{align*}
\\
*For the next case, $\omega \in \mathcal{O}_K$, since we already show the identity for $\omega \in \mathcal{O}_K \setminus \mathfrak{p}$, we only need to show the same holds for $\omega \in \mathfrak{p}$, but this is straightforward: we already have $\omega^n \equiv 0 \pmod{\mathfrak{p}^{t + 1}}$ for any $n \geq t + 1$. On the other hand, $N(\mathfrak{p}) \geq 2$ (since it is the cardinality of a finite field), so $N(\mathfrak{p})^t \geq 2^t \geq t + 1$ ($t \geq 0$). In other words,
$$\omega^{N(\mathfrak{p})^{t + 1}} \equiv \omega^{N(\mathfrak{p})^t} \equiv 0 \pmod{\mathfrak{p}^{t + 1}}$$
\\
*For the final case, $\omega \in K$, since $K$ coincides with $\mathcal{O}_K$'s field of fractions, we can write $\omega = \eta / \delta$ for some number $\eta, \delta$ in $\mathcal{O}_K$ (possibly have some common factor). If $v_\mathfrak{p} (\omega) \geq 1$, then $v_\mathfrak{p} (\omega^{N(\mathfrak{p})^t}) = N(\mathfrak{p})^t \geq 2^t \geq t + 1$, so
$$\omega^{N(\mathfrak{p})^{t + 1}} \equiv \omega^{N(\mathfrak{p})^t} \equiv 0 \pmod{\mathfrak{p}^{t + 1}}$$
Otherwise, suppose $v_\mathfrak{p} (\eta) = v_\mathfrak{p} (\delta) = s$ for some non-negative integer $s$. Just like the case $\omega \in \mathcal{O}_K \setminus \mathfrak{p}$, we will show that
$$\omega^{N(\mathfrak{p})^{t + 1} - N(\mathfrak{p})^t} \equiv 1 \pmod{\mathfrak{p}^{t + 1}}$$
which will lead to Q.E.D.
\\
\\
Denote $\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1}) = N(\mathfrak{p})^{t + 1} - N(\mathfrak{p})^t = |(\mathcal{O}_K / \mathfrak{p}^{t + 1})^\times|$. By assumption, we can factorize the principal ideals $\eta \mathcal{O}_K$ and $\delta \mathcal{O}_K$ into
\begin{align*}
\eta \mathcal{O}_K & = \mathfrak{p}^s \mathfrak{n} \\
\delta \mathcal{O}_K & = \mathfrak{p}^s \mathfrak{d}
\end{align*}
such that $\mathfrak{n}, \mathfrak{d}$ are not divisible by $\mathfrak{p}$ (in particular, $\mathfrak{n} \cap \mathfrak{p} = \mathfrak{d} \cap \mathfrak{p} = \{ 0 \}$). Since these are also set equalities, if we fix some $\rho \in \mathfrak{p} \setminus \mathfrak{p}^2, \lambda \in \mathfrak{n}, \kappa \in \mathfrak{d}$ (all non-zero), then there exists some $r_\eta, r_\delta \in \mathcal{O}_K$ (also non-zero) such that
\begin{align*}
\eta r_\eta & = \rho^s \lambda \\
\delta r_\delta & = \rho^s \kappa
\end{align*}
Taking valuation at $\mathfrak{p}$, we notice that $r_\eta, r_\delta \notin \mathfrak{p}$. Now consider
\begin{align*}
v_p \left( (\eta r_\eta)^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} - (\delta r_\delta)^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} \right) & = v_p \left( \rho^{s \varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} \left[ \lambda^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} - \kappa^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} \right] \right) \\
& = s \varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1}) + v_p \left( \lambda^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} - \kappa^{\varphi_{\mathcal{O}_K}(\mathfrak{p}^{t + 1}) (\mathfrak{p}^{t + 1})} \right) \\
& \geq s \varphi_{\mathcal{O}_K}(\mathfrak{p}^{t + 1}) + (t + 1)
\end{align*}
The last inequality is due to $\lambda^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} \equiv \kappa^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} \equiv 1 \pmod{\mathfrak{p}^{t + 1}}$ ($\lambda, \kappa$ are non-zero, so they do not belong to $\mathfrak{p}$). Rewriting the above inequality as the following congruence
\begin{align*}
(\eta r_\eta)^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} & \equiv (\delta r_\delta)^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} & \pmod{\mathfrak{p}^{s \varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1}) + (t + 1)}} \\
\omega^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} r_\eta^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} & \equiv r_\delta^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} & \pmod{\mathfrak{p}^{t + 1}} \\
\omega^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} & \equiv 1 & \pmod{\mathfrak{p}^{t + 1}}
\end{align*}
The second congruence is due to $v_\mathfrak{p} (\delta^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})}) = v_\mathfrak{p}(\delta) \varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1}) = s \varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})$, while the last congruence is due to $r_\eta^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} \equiv r_\delta^{\varphi_{\mathcal{O}_K} (\mathfrak{p}^{t + 1})} \equiv 1 \pmod{\mathfrak{p}^{t + 1}}$ (since $r_\eta, r_\delta \notin \mathfrak{p}$).
\end{proof}
\begin{corollary}
Let $\omega$ be some number in $K$ and $I$ be some (integral) ideal of $\mathcal{O}_K$ such that $v_\mathfrak{p} (\omega) = 0$ whenever $v_\mathfrak{p} (I) > 0$ for a given prime ideal $\mathfrak{p}$. Prove that
$$\omega^{\varphi_{\mathcal{O}_K} (I)} \equiv 1 \pmod{I}$$
Recall that $\varphi_{\mathcal{O}_K} (I)$ is the cardinality of the multiplicative group of $\mathcal{O}_K / I$.
\end{corollary}
\begin{proof}
Since $\mathcal{O}_K$ is a Dedekind domain, we can factorize $I$ into product of power of prime ideals $I = \prod_{k = 1}^n \mathfrak{p}_k^{t_k}$. If $\mathfrak{m}$ is the sum of $\mathfrak{p}_i^{t_i}$ and $\mathfrak{p}_j^{t_j}$ (for $i \neq j$), then it contains $\mathfrak{p}_i^{t_i}$ and $\mathfrak{p}_j^{t_j}$. Since $\mathfrak{p}_i, \mathfrak{p}_j$ are prime, $\mathfrak{m}$ contains the prime ideals themselves. But a prime ideal in Dedekind domain is always maximal, so $\mathfrak{m}$ is the whole ring $\mathcal{O}_K$. Thus, we can apply the Chinese remainder theorem to get
\begin{align*}
\mathcal{O}_K / I & \cong \prod_{k = 1}^n \mathcal{O}_K / \mathfrak{p}_k^{t_k} \\
(\mathcal{O}_K / I)^\times & \cong \left( \prod_{k = 1}^n \mathcal{O}_K / \mathfrak{p}_k^{t_k} \right)^\times = \prod_{k = 1}^n (\mathcal{O}_K / \mathfrak{p}_k^{t_k})^\times \\
\varphi_{\mathcal{O}_K} (I) & = \prod_{k = 1}^n \varphi_{\mathcal{O}_K} (\mathfrak{p}_k^{t_k})
\end{align*}
By the hypothesis, $v_{\mathfrak{p}_k} (\omega) = 0$ ($k = \overline{1, n}$), so from the previous theorem, we have
\begin{align*}
\omega^{\varphi_{\mathcal{O}_K} (\mathfrak{p}_k^{t_k})} & \equiv 1 & \pmod{\mathfrak{p}_k^{t_k}} \\
\omega^{\varphi_{\mathcal{O}_K} (I)} & \equiv 1^{\varphi_{\mathcal{O}_K} (I) / \varphi_{\mathcal{O}_K} (\mathfrak{p}_k^{t_k})} \equiv 1 & \pmod{\mathfrak{p}_k^{t_k}}
\end{align*}
But $\mathcal{O}_K / I \cong \prod_{k = 1}^n \mathcal{O}_K / \mathfrak{p}_k^{t_k}$, so we finally get
$$\omega^{\varphi_{\mathcal{O}_K} (I)} \equiv 1 \pmod{I}$$
\end{proof}
\begin{proposition}[Legendre formula]
For a prime $p$ and a positive integer $n$
$$v_p (n!) = \sum_{i = 1}^\infty \left\lfloor \frac{n}{p^i} \right\rfloor = \frac{n - s_p(n)}{p - 1}$$
where $s_p(n)$ is the sum of digits of $n$ in base $p$.
\end{proposition}
\begin{proof}
From $1$ to $n$, by pigeonhole principle, there are exactly $\lfloor n/p^i \rfloor$ numbers divisible by $p^i$, so
\begin{align*}
v_p (n!) & = \sum_{m = 1}^n v_p (m) = \sum_{i = 1}^\infty i \left( \left\lfloor \frac{n}{p^i} \right\rfloor - \left\lfloor \frac{n}{p^{i + 1}} \right\rfloor \right) \\
& = \sum_{i = 1}^\infty i \left\lfloor \frac{n}{p^i} \right\rfloor - \sum_{i = 2}^\infty (i - 1) \left\lfloor \frac{n}{p^i} \right\rfloor = \sum_{i = 1}^\infty \left\lfloor \frac{n}{p^i} \right\rfloor
\end{align*}
For the second equality, if $\overline{n_l n_{l - 1} \hdots n_1 n_0}_p$ is the representation of $n$ in base $p$, then for $p^i \leq n$
\begin{align*}
\left\lfloor \frac{n}{p^i} \right\rfloor = \left\lfloor \frac{n_l p^l + n_{l - 1} p^{l - 1} + \cdots + n_1 p + n_0}{p^i} \right\rfloor = n_l p^{l - i} + n_{l - 1} p^{l - 1 - i} + \cdots + n_{i + 1} p + n_i
\end{align*}
Therefore,
\begin{align*}
\sum_{i = 1}^\infty \left\lfloor \frac{n}{p^i} \right\rfloor & = \sum_{i = 1}^l n_l p^{l - i} + n_{l - 1} p^{l - 1 - i} + \cdots + n_{i + 1} p + n_i \\
& = n_l p^{l - 1} + n_{l - 1} p^{l - 2} + \cdots + n_2 p + n_1 \\
& + n_l p^{l - 2} + n_{l - 1} p^{l - 3} + \cdots + n_2 \\
& + \cdots \\
& + n_l \\
& = \sum_{i = 1}^l n_i (p^{i - 1} + p^{i - 2} + \cdots + p + 1) \\
& = \sum_{i = 1}^l n_i \frac{p^i - 1}{p - 1} = \sum_{i = 0}^l n_i \frac{p^i - 1}{p - 1} \\
& = \frac{\sum_{i = 0}^l n_i p^i - \sum_{i = 0}^l n_i}{p - 1} = \frac{n - s_p (n)}{p - 1}
\end{align*}
\end{proof}
\begin{corollary} \label{multi-val-sum-digit}
If $r_i \in \mathbb{N}$ and $p$ is a prime
$$v_p \left( {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) = \frac{\sum_{i = 1}^k s_p(r_i) - s_p \left( \sum_{i = 1}^k r_i \right)}{p - 1}$$
\end{corollary}
\begin{proof}
By the Legendre formula
\begin{align*}
v_p \left( {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) & = v_p \left( \frac{\left( \sum_{i = 1}^k r_i \right)!}{\prod_{i = 1}^k r_i!} \right) \\
& = \frac{\left[ \sum_{i = 1}^k r_i - s_p \left( \sum_{i = 1}^k r_i \right) \right] - \sum_{i = 1}^k [r_i - s_p (r_i)]}{p - 1} \\
& = \frac{\sum_{i = 1}^k s_p(r_i) - s_p \left( \sum_{i = 1}^k r_i \right)}{p - 1}
\end{align*}
\end{proof}
\begin{corollary} \label{p-adic-reduct} \ 
$$v_p \left( {p(r_1 + r_2 + \cdots + r_k) \choose p r_1, p r_2, \hdots, p r_k} \right) = v_p \left( {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right)$$
\end{corollary}
\begin{proof}
Note that $s_p$ is invariant under padding zero, i.e. $s_p (pn) = s_p (n)$, so
\begin{align*}
v_p \left( {p(r_1 + r_2 + \cdots + r_k) \choose p r_1, p r_2, \hdots, p r_k} \right) & = \frac{\sum_{i = 1}^k s_p(pr_i) - s_p \left( p \sum_{i = 1}^k r_i \right)}{p - 1} \\
& = \frac{\sum_{i = 1}^k s_p(r_i) - s_p \left( \sum_{i = 1}^k r_i \right)}{p - 1} \\
& = v_p \left( {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right)
\end{align*}
\end{proof}
\begin{proposition}[Kummer theorem] \label{p-adic-high-school-addition}
Let $r_1, r_2, \hdots, r_k$ be non-negative integers, and $p$ be a prime. Let $\tau$ be a number such that $\tau + 1$ is the maximum number of digits of $r_i$ in base $p$. Then write $r_i$ in base $p$ and add them up as follows
\begin{enumerate}
	\item $r_a = \overline{d_{a, \tau} d_{a, \tau - 1} \hdots d_{a, 0}}_p$ ($a = \overline{1, k}$). Note that $d_{a, \tau}$ can be $0$.
	\item $x_0$ is the quotient and $y_0$ is the remainder of $\sum_{i = 1}^k d_{i, 0}$ after dividing by $p$, i.e.
	$$\sum_{i = 1}^k d_{i, 0} = x_0 p + y_0$$ 
	\item Similarly, for each $j = \overline{1, \tau}$, let $x_j$ be the quotient and $y_j$ be the remainder of $\sum_{i = 1}^k d_{i, j} + x_{j - 1}$ after dividing by $p$
	$$\sum_{i = 1}^k d_{i, j} + x_{j - 1} = x_j p + y_j$$
\end{enumerate}
Prove that
\begin{align*}
\sum_{i = 1}^k r_i & = \overline{x_\tau y_\tau y_{\tau - 1} \cdots y_0}_p \\
\sum_{j = 1}^\tau x_j & = v_p \left( {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right)
\end{align*}
\end{proposition}
\begin{proof}
The first formula is just addition in base $p$
\begin{align*}
\sum_{i = 1}^k r_i & = \sum_{i = 1}^k \sum_{j = 0}^\tau p^j d_{i, j} = \sum_{j = 0}^\tau p^j \sum_{i = 1}^k d_{i, j} \\
& = y_0 + x_0 p + \sum_{j = 1}^\tau p^j (-x_{j - 1} + y_j + x_j p) \\
& = y_0 + x_0 p - x_0 p + y_1 p + x_1 p^2 - \cdots - x_{\tau - 1} p^\tau + y_\tau p^\tau + x_\tau p^{\tau + 1} \\
& = y_0 + y_1 p + \cdots + y_\tau p^\tau + x_\tau p^{\tau + 1} = \overline{x_\tau y_\tau y_{\tau - 1} \cdots y_0}_p
\end{align*}
For the second formula, according to the previous corollary
\begin{align*}
(p - 1) v_p \left( {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) & = \sum_{i = 1}^k s_p (r_i) - s_p \left( \sum_{i = 1}^k r_i \right) \\
& = \sum_{i = 1}^k \sum_{j = 0}^\tau d_{i, j} - s_p (\overline{x_\tau y_\tau y_{\tau - 1} \cdots y_0}_p) \\
& = \sum_{j = 0}^\tau \sum_{i = 1}^k d_{i, j} - x_\tau - \sum_{j = 0}^\tau y_j \\
& = \sum_{j = 0}^\tau (x_j p + y_j) - \sum_{j = 1}^\tau x_{j - 1} - x_\tau - \sum_{j = 0}^\tau y_j \\
& = (p - 1) \sum_{j = 0}^\tau x_j
\end{align*}
\end{proof}
\begin{lemma} \label{reduced-multi-pos-val}
Let $p$ be a prime and $r_1, r_2, \hdots, r_k \in \mathbb{N}$ such that $r_i$ are not simultaneously divisible by $p$ (in other words, $v_p (\gcd(r_1, r_2, \hdots, r_k)) = 0$), then
$$v_p \left( \frac{1}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) \geq 0$$
\end{lemma}
\begin{proof}
According to the previous proposition
$$v_p \left( \frac{1}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) = \sum_{j = 0}^\tau x_j - v_p(\overline{x_\tau y_\tau y_{\tau - 1} \cdots y_0}_p)$$
If $v_p(\overline{x_\tau y_\tau y_{\tau - 1} \cdots y_0}_p) = 0$, then we get Q.E.D since $x_j$ is a quotient, which always non-negative (as long as the dividend is non-negative). Otherwise, suppose $v_p(\overline{x_\tau y_\tau y_{\tau - 1} \cdots y_0}_p) = c + 1$ for some $c \geq 0$. Equivalently, $y_c = y_{c - 1} = \cdots = y_0 = 0$ but $y_{c + 1} \neq 0$. On the other hand, $r_i$ are not simultaneously divisible by $p$, so at least one of $r_i$'s last digit (in base $p$) $d_{i, 0}$ must be non-zero, which makes $x_0 p = x_0 p + y_0 = \sum_{i = 1}^k d_{i, 0} \neq 0$. In other words, $x_0 \neq 0$ or equivalently, $x_0 \geq 1$. For each $1 \leq j \leq c$, we deduce by induction that
$$x_j p = x_j p + y_j = x_{j - 1} + \sum_{i = 1}^k d_{i, j} \geq x_{j - 1} \geq 1$$
Thus, $x_j \geq 1$ for all $0 \leq j \leq c$. We then observe
\begin{align*}
v_p \left( \frac{1}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) & = \sum_{j = 0}^\tau x_j - v_p(\overline{x_\tau y_\tau y_{\tau - 1} \cdots y_0}_p) \\
& = \sum_{j = 0}^\tau x_j - (c + 1) \geq \sum_{j = 0}^c x_j - (c + 1) \geq 0
\end{align*}
\end{proof}
\begin{corollary} \label{reduce-multi-geq-gcd}
$$v_p \left( \frac{1}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) \geq -v_p (\gcd(r_1, r_2, \hdots, r_k))$$
\end{corollary}
\begin{proof}
Let $s = v_p(\gcd(r_1, r_2, \hdots, r_k))$ and $r_i = p^s z_i$, then $v_p(\gcd(z_1, z_2, \hdots, z_k)) = 0$. By \hyperref[p-adic-reduct]{corollary \ref*{p-adic-reduct}} and \hyperref[reduced-multi-pos-val]{lemma \ref*{reduced-multi-pos-val}}
\begin{align*}
& v_p \left( \frac{1}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) \\
& \qquad = v_p \left( \frac{1}{p^s (z_1 + z_2 + \cdots + z_k)} {p^s (z_1 + z_2 + \cdots + z_k) \choose p^s z_1, p^s z_2, \hdots, p^s z_k} \right) \\
& \qquad = -s + v_p \left( \frac{1}{z_1 + z_2 + \cdots + z_k} {z_1 + z_2 + \cdots + z_k \choose z_1, z_2, \hdots, z_k} \right) \\
& \qquad \geq -s = - v_p(\gcd(r_1, r_2, \hdots, r_k))
\end{align*}
\end{proof}
\begin{corollary} \label{reduce-multi-int}
Suppose $m = v_1 r_1 + v_2 r_2 + \cdots + v_k r_k$ where $v_i$ are integers (but not all zero), $r_i$ are non-negative integers, and $m$ is a positive integer, then
$$\frac{m}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \in \mathbb{N}$$
\underline{Note:} the denominator is non-zero since $r_i$ cannot all be zero (which will also make $m = 0$, contradicting the assumption).
\end{corollary}
\begin{proof}
For each prime $p$, if $s = v_p (\gcd(r_1, r_2, \hdots, r_k))$, then $p^s \mid r_i$ and so $p^s \mid \sum_{i = 1}^k v_i r_i = m$. Hence,
\begin{align*}
v_p \left( \frac{m}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) \geq v_p (m) - s = s - s = 0
\end{align*}
But $p$ is arbitrary, so the only possibility is that the expression must be an integer.
\end{proof}
\begin{lemma} \label{p-adic-multi-cong}
For every $r_1, r_2, \hdots, r_k \in \mathbb{N}$, not all simultaneously 0, $t \in \mathbb{N}$ and prime $p$
$${p(r_1 + r_2 + \cdots + r_k) \choose p r_1, p r_2, \hdots, p r_k} \equiv {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \pmod{p^{1 + v_p \left( \sum_{i = 1}^k r_i \right)}}$$
\end{lemma}
\begin{proof}
Let $s = v_p (\gcd(r_1, r_2, \hdots, r_k))$ and $r_i = p^s z_i$ (so that $z_i$ are not simultaneously divisible by $p$). The following is a series of equivalence
\begin{align*}
{p(r_1 + r_2 + \cdots + r_k) \choose p r_1, p r_2, \hdots, p r_k} & \equiv {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \pmod{p^{1 + v_p \left( \sum_{i = 1}^k r_i \right)}}
\\
\frac{\left( p \sum_{i = 1}^k r_i \right)!}{\prod_{i = 1}^k (pr_i)!} & \equiv \frac{\left( \sum_{i = 1}^k r_i \right)!}{\prod_{i = 1}^k r_i!} \pmod{p^{1 + v_p \left( \sum_{i = 1}^k r_i \right)}}
\\
\frac{\left( p \sum_{i = 1}^k r_i \right)!}{\left( \sum_{i = 1}^k r_i \right)!} & \equiv \frac{\prod_{i = 1}^k (pr_i)!}{\prod_{i = 1}^k r_i!} \equiv \prod_{i = 1}^k \frac{(pr_i)!}{r_i!} \pmod{p^{w_p^{[1]}}}
\end{align*}
where $w_p^{[1]} = 1 + v_p \left( \sum_{i = 1}^k r_i \right) - v_p \left( \left( \sum_{i = 1}^k r_i \right) ! \right) + v_p \left( \prod_{i = 1}^k (pr_i)! \right)$
\begin{align*}
p^{\sum_{i = 1}^k r_i} \prod_{\substack{t = 0 \\ p \nmid t}}^{p \sum_{i = 1}^k r_i - 1} \left( p \sum_{i = 1}^k r_i - t \right) & \equiv p^{\sum_{i = 1}^k r_i} \prod_{i = 1}^k \prod_{\substack{t = 0 \\ p \nmid t}}^{p r_i - 1} (p r_i - t) \pmod{p^{w_p^{[1]}}}
\end{align*}
since for each factor $\gamma$ in the denominator, there is always $p \gamma$ appeared in the numerator. Vice versa, if $1 \leq \lambda \leq p \sum_{i = 1}^k r_i$ is divisible by $p$, then $1 \leq \lambda/p \leq \sum_{i = 1}^k r_i$, so $\lambda/p$ should appear in the denominator. After each pair of corresponding factors cancels, we are left with $\sum_{i = 1}^k r_i$ factors of $p$, and other factors which are not divisible by $p$. If we write each factor that is not divisible by $p$ as $p \sum_{i = 1}^k r_i - t$ for $0 \leq t \leq p \sum_{i = 1}^k r_i - 1$ (or $pr_i - t$ for RHS), then $p$ cannot divide $t$. Vice versa, if $p$ does not divide $t$, then $p$ neither divide $p \sum_{i = 1}^k r_i - t$.
\begin{align*}
\prod_{\substack{t = 0 \\ p \nmid t}}^{p \sum_{i = 1}^k r_i - 1} \left( p \sum_{i = 1}^k r_i - t \right) & \equiv \prod_{i = 1}^k \prod_{\substack{t = 0 \\ p \nmid t}}^{p r_i - 1} (p r_i - t) \pmod{p^{w_p^{[2]}}}
\end{align*}
where $w_p^{[2]} = w_p^{[1]} - \sum_{i = 1}^k r_i$
\begin{align*}
\prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} \sum_{i = 1}^k z_i - 1} \left( p^{s + 1} \sum_{i = 1}^k z_i - t \right) & \equiv \prod_{i = 1}^k \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_i - 1} (p^{s + 1} z_i - t) \pmod{p^{w_p^{[2]}}}
\end{align*}
We then try to prove this congruence instead. But first, let's simplify $w_p^{[2]}$
\begin{align*}
w_p^{[2]} & = 1 + v_p \left( \sum_{i = 1}^k r_i \right) - v_p \left( \left( \sum_{i = 1}^k r_i \right) ! \right) + v_p \left( \prod_{i = 1}^k (pr_i)! \right) - \sum_{i = 1}^k r_i \\
& = 1 + v_p \left( \sum_{i = 1}^k r_i \right) - v_p \left( \left( \sum_{i = 1}^k r_i \right) ! \right) + \sum_{i = 1}^k v_p \left( (pr_i)! \right) - \sum_{i = 1}^k r_i \\
& = 1 + v_p \left( \sum_{i = 1}^k r_i \right) + \frac{- \left[ \sum_{i = 1}^k r_i - s_p \left( \sum_{i = 1}^k r_i \right) \right] + \left[ \sum_{i = 1}^k pr_i - s_p (pr_i) \right]}{p - 1} - \sum_{i = 1}^k r_i \\
& = 1 + v_p \left( \sum_{i = 1}^k r_i \right) + \sum_{i = 1}^k r_i - \frac{\sum_{i = 1}^k s_p(r_i) - s_p \left( \sum_{i = 1}^k r_i \right)}{p - 1} - \sum_{i = 1}^k r_i \\
& = 1 + v_p \left( \sum_{i = 1}^k r_i \right) - v_p \left( {r_1 + r_2 + \cdots r_k \choose r_1, r_2, \hdots, r_k} \right) \\
& = 1 - v_p \left( \frac{1}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots r_k \choose r_1, r_2, \hdots, r_k} \right) \\
& \leq 1 + v_p (\gcd(r_1, r_2, \hdots, r_k)) = 1 + s
\end{align*}
From here, if we can show the following stronger congruence (same one we need to prove, but with larger exponent in the modulus), then we have Q.E.D.
\begin{align*}
\prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} \sum_{i = 1}^k z_i - 1} \left( p^{s + 1} \sum_{i = 1}^k z_i - t \right) & \equiv \prod_{i = 1}^k \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_i - 1} (p^{s + 1} z_i - t) \pmod{p^{s + 1}}
\end{align*}
Simplifying each side, we get
\begin{align*}
\mbox{LHS} & = \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} \sum_{i = 1}^k z_i - 1} \left( p^{s + 1} \sum_{i = 1}^k z_i - t \right) \equiv \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} \sum_{i = 1}^k z_i - 1} (-t) \pmod{p^{s + 1}} \\
\mbox{RHS} & = \prod_{i = 1}^k \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_i - 1} (p^{s + 1} z_i - t) \equiv \prod_{i = 1}^k \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_i - 1} (-t) \pmod{p^{s + 1}}
\end{align*}
However, on the other hand
\begin{align*}
\mbox{LHS} & \equiv \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_1 - 1} (-t) \prod_{\substack{t = p^{s + 1} z_1 \\ p \nmid t}}^{p^{s + 1} \sum_{i = 1}^k z_i - 1} (-t)
\\
& = \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_1 - 1} (-t) \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} \sum_{i = 2}^k z_i - 1} [-(t + p^{s + 1} z_1)]
\\
& \equiv \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_1 - 1} (-t) \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} \sum_{i = 2}^k z_i - 1} (-t) \equiv \cdots
\\
& \equiv \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_1 - 1} (-t) \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_2 - 1} (-t) \cdots \prod_{\substack{t = 0 \\ p \nmid t}}^{p^{s + 1} z_k - 1} (-t) \equiv \mbox{RHS} \pmod{p^{s + 1}}
\end{align*}
\end{proof}
\ \\
\begin{proof}[Proof of theorem \ref*{sum-eul-totient}] \ \\
\underline{Part 1:} by \hyperref[newt-id-sym-poly]{lemma \ref*{newt-id-sym-poly}}, we have $f_n \in K$ for all $n \in \mathbb{N}$. In fact, $f_n \in \mathcal{O}_K$ if $c_i \in \mathcal{O}_K$, but this is irrelevant to the current discussion.
\\
\underline{Part 2:} since $\mathcal{O}_K \setminus \mathfrak{p}$ is a finite field, let $N(\mathfrak{p}) = p^\tau$ where $p$ is the characteristic of $\mathcal{O}_K \setminus \mathfrak{p}$ (and so $p \in \mathfrak{p}$) and $\tau \geq 1$. By \hyperref[newt-id-sym-poly]{Newton identities on symmetric polynomials}
\begin{align*}
f_{N(\mathfrak{p})^{t + 1}} & = f_{p^{\tau (t + 1)}} = \sum_{\substack{s_1 + 2s_2 + \cdots + k s_k = p^{\tau (t + 1)} \\ s_1, s_2, \hdots, s_k \geq 0}} \frac{p^{\tau (t + 1)}}{s_1 + s_2 + \cdots + s_k} {s_1 + s_2 + \cdots + s_k \choose s_1, s_2, \hdots, s_k} \prod_{i = 1}^k c_i^{s_i}
\end{align*}
For tuples $(s_1, s_2, \hdots, s_k)$ such that $v_p (\gcd(s_1, s_2, \hdots, s_k)) \leq \tau - 1$ (i.e. $s_i$ are not simultaneously divisible by $p^\tau$), then by \hyperref[reduce-multi-geq-gcd]{corollary \ref*{reduce-multi-geq-gcd}}
$$v_p \left( \frac{1}{s_1 + s_2 + \cdots + s_k} {s_1 + s_2 + \cdots + s_k \choose s_1, s_2, \hdots, s_k} \right) \geq - v_p (\gcd(s_1, s_2, \hdots, s_k)) \geq - \tau + 1$$
So
$$\frac{p^{\tau(t + 1)}}{s_1 + s_2 + \cdots + s_k} {s_1 + s_2 + \cdots + s_k \choose s_1, s_2, \hdots, s_k} \in p^{\tau (t + 1) - \tau + 1} \mathcal{O}_K = p^{\tau t + 1} \mathcal{O}_K \subseteq \mathfrak{p}^{\tau t + 1} \subseteq \mathfrak{p}^{t + 1}$$
since $p \in \mathfrak{p}$ (as $p = 0$ in $\mathcal{O}_K / \mathfrak{p}$). Under modulo $\mathfrak{p}^{t + 1}$, such term (i.e. $v_p(\gcd(s_1, s_2, \hdots, s_k)) \leq \tau - 1$) in $f_{N(\mathfrak{p})^{t + 1}}$ will be zero, leaving us other terms such that $s_i$ are simultaneously divisible by $p^\tau$.
\\
\\
For each remaining such term, let $s_i = p^\tau r_i$
\begin{align*}
f_{N(\mathfrak{p})^{t + 1}} & \equiv \sum_{\substack{s_1 + 2s_2 + \cdots + k s_k = p^{\tau (t + 1)} \\ p^\tau \mid s_1, s_2, \hdots, s_k}} \frac{p^{\tau (t + 1)}}{s_1 + s_2 + \cdots + s_k} {s_1 + s_2 + \cdots + s_k \choose s_1, s_2, \hdots, s_k} \prod_{i = 1}^k c_i^{s_i} \\
& = \sum_{\substack{r_1 + 2r_2 + \cdots + k r_k = p^{\tau t} \\ r_1, r_2, \hdots, r_k \geq 0}} \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {p^\tau (r_1 + r_2 + \cdots + r_k) \choose p^\tau r_1, p^\tau r_2, \hdots, p^\tau r_k} \prod_{i = 1}^k c_i^{p^\tau r_i} \pmod{\mathfrak{p}^{t + 1}} \\
\end{align*}
This is similar to $f_{N(\mathfrak{p})^t}$, using the same Newton identity
\begin{align*}
f_{N(\mathfrak{p})^t} & = \sum_{\substack{r_1 + 2r_2 + \cdots + k r_k = p^{\tau t} \\ r_1, r_2, \hdots, r_k \geq 0}} \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \prod_{i = 1}^k c_i^{r_i}
\end{align*}
Comparing the corresponding terms, we conjecture that the following congruence holds (for $r_1 + 2r_2 + \cdots + k r_k = p^{\tau t}$ and $r_1, r_2, \hdots, r_n \geq 0$)
\begin{align*}
& \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {p^\tau (r_1 + r_2 + \cdots + r_k) \choose p^\tau r_1, p^\tau r_2, \hdots, p^\tau r_k} \prod_{i = 1}^k c_i^{p^\tau r_i} \nonumber
\\
& \qquad \equiv \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \prod_{i = 1}^k c_i^{r_i} \pmod{\mathfrak{p}^{t + 1}}
\end{align*}
If so, then it is straightforward to see that $f_{N(\mathfrak{p})^{t + 1}} \equiv f_{N(\mathfrak{p})^t} \pmod{\mathfrak{p}^{t + 1}}$.
\\
\\
Let $\omega$ be the quotient and $\gamma$ be the remainder of $v_p (\gcd(r_1, r_2, \hdots, r_k))$ after dividing $\tau$, and set $r_i = (p^\tau)^\omega z_i, z_i = p^\gamma x_i$. From \hyperref[reduce-multi-geq-gcd]{corollary \ref*{reduce-multi-geq-gcd}} and \hyperref[reduce-multi-int]{corollary \ref*{reduce-multi-int}}
\begin{align*}
\frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} & \in \mathbb{N}
\\
v_p \left( \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \right) & \geq \tau t - (\tau \omega + \gamma) = \tau(t - \omega) - \gamma
\end{align*}
Note that $r_1 + 2r_2 + \cdots + k r_k = p^{\tau t}$, so $x_1 + 2x_2 + \cdots + k x_k = p^{\tau t - (\tau \omega + \gamma)} = p^{\tau (t - \omega) - \gamma}$. In particular, $\tau (t - \omega) - \gamma$ must be non-negative.
\begin{enumerate}
	\item If $\gamma = 0$, then $\tau (t - \omega) - \gamma = \tau (t - \omega) \geq (t - \omega)$.
	\item Otherwise, $1 \leq \gamma \leq \tau - 1$ (since $\gamma$ is the remainder). $\tau (t - \omega) - \gamma$ is non-negative, so $\tau (t - \omega) \geq \gamma \geq 1$. In particular, $t - \omega \geq 1$. We can then show that
	$$\tau (t - \omega) - \gamma \geq \tau (t - \omega) - (\tau - 1) = (\tau - 1)(t - \omega - 1) + (t - \omega) \geq t - \omega$$
\end{enumerate}
In any case, we always have $\tau (t - \omega) - \gamma \geq t - \omega$, so 
$$\frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \in p^{\tau (t - \omega) - \gamma} \subseteq p^{t - \omega} \subseteq \mathfrak{p}^{t - \omega}$$
On the other hand, note that $v_\mathfrak{p}(c_i) \geq 0$, so by the \hyperref[eul-totient-thm]{Euler totient theorem}
\begin{align*}
c_i^{p^\tau r_i} = (c_i^{z_i})^{p^{\tau(\omega + 1)}} = (c_i^{z_i})^{N(\mathfrak{p})^{\omega + 1}} & \equiv (c_i^{z_i})^{N(\mathfrak{p})^\omega} = c_i^{r_i} \pmod{\mathfrak{p}^{\omega + 1}} \\
\prod_{i = 1}^k c_i^{p^\tau r_i} & \equiv \prod_{i = 1}^k c_i^{r_i} \pmod{\mathfrak{p}^{\omega + 1}} \\
\end{align*}
Multiplying both side by $\frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \in \mathfrak{p}^{t - \omega}$, we get
\begin{align} \label{1st-term-cong}
& \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \prod_{i = 1}^k c_i^{p^\tau r_i} \nonumber
\\
& \qquad \equiv \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \prod_{i = 1}^k c_i^{r_i} \pmod{\mathfrak{p}^{t + 1}}
\end{align}
\\
On the other hand, by \hyperref[p-adic-multi-cong]{lemma \ref*{p-adic-multi-cong}}
\begin{align*}
{p^{\tau + 1}(r_1 + r_2 + \cdots + r_k) \choose p^{\tau + 1} r_1, p^{\tau + 1} r_2, \hdots, p^{\tau + 1} r_k} & \equiv {p^\tau(r_1 + r_2 + \cdots + r_k) \choose p^\tau r_1, p^\tau r_2, \hdots, p^\tau r_k} \pmod{p^{1 + v_p \left( p^\tau \sum_{i = 1}^k r_i \right)}}
\end{align*}
Note that $1 + v_p \left( p^\tau \sum_{i = 1}^k r_i \right) = 1 + \tau + v_p \left( \sum_{i = 1}^k r_i \right) \geq 1 + v_p \left( \sum_{i = 1}^k r_i \right)$, so
\begin{align*}
{p^{\tau + 1}(r_1 + r_2 + \cdots + r_k) \choose p^{\tau + 1} r_1, p^{\tau + 1} r_2, \hdots, p^{\tau + 1} r_k} & \equiv {p^\tau(r_1 + r_2 + \cdots + r_k) \choose p^\tau r_1, p^\tau r_2, \hdots, p^\tau r_k}
\\
& \equiv {p^{\tau - 1}(r_1 + r_2 + \cdots + r_k) \choose p^{\tau - 1} r_1, p^{\tau - 1} r_2, \hdots, p^{\tau - 1} r_k}
\\
& \equiv \cdots \equiv {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \pmod{p^{1 + v_p \left( \sum_{i = 1}^k r_i \right)}}
\end{align*}
Multiplying $p^{\tau t} / (r_1 + r_2 + \cdots + r_k)$ (which increase the exponent of $p$ in the modulus by $\tau t - v_p(r_1 + r_2 + \cdots + r_k)$) on both sides, we get
\begin{align*}
& \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {p^{\tau + 1}(r_1 + r_2 + \cdots + r_k) \choose p^{\tau + 1} r_1, p^{\tau + 1} r_2, \hdots, p^{\tau + 1} r_k}
\\
& \qquad \equiv \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \pmod{p^{\tau t + 1}}
\end{align*}
Yet $p^{\tau t + 1} \mathcal{O}_K \subseteq p^{t + 1} \mathcal{O}_K \subseteq \mathfrak{p}^{t + 1}$,
\begin{align} \label{2nd-cof-cong}
& \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {p^{\tau + 1}(r_1 + r_2 + \cdots + r_k) \choose p^{\tau + 1} r_1, p^{\tau + 1} r_2, \hdots, p^{\tau + 1} r_k} \nonumber
\\
& \qquad \equiv \frac{p^{\tau t}}{r_1 + r_2 + \cdots + r_k} {r_1 + r_2 + \cdots + r_k \choose r_1, r_2, \hdots, r_k} \pmod{\mathfrak{p}^{t + 1}}
\end{align}
Finally, by combining \hyperref[1st-term-cong]{(\ref*{1st-term-cong})} and \hyperref[2nd-cof-cong]{(\ref*{2nd-cof-cong})}, we get Q.E.D.
\end{proof}

\section{Structure of multiplicative group of a residue ring for a number field}
We call a prime $p$ \emph{ramified} in some prime ideal $\mathfrak{p}$ if $v_\mathfrak{p} (p \mathcal{O}_K)$ is strictly greater than 1. If the exponent is exactly 1, then we call such prime \emph{unramified} in $\mathfrak{p}$. To uncover the structure of $(\mathcal{O}_K / \mathfrak{p}^t)^\times$, we introduce the following lemmas.
\begin{lemma} \label{val-rami-prime}
If $N(\mathfrak{p}) = p^m$, then
\begin{enumerate}
	\item $p \in \mathfrak{p}$, and $q \notin \mathfrak{p}$ for all prime $q \neq p$.
	\item If $\mu = v_\mathfrak{p} (p)$ (which is at least 1), then
	$$v_\mathfrak{p} (x) = \mu v_p (x) \mbox{ for all } x \in \mathbb{Z}$$
\end{enumerate}
\end{lemma}
\begin{proof}
*Since $N(\mathfrak{p}) = p^m = |\mathcal{O}_K/\mathfrak{p}|$, $\mathcal{O}_K/\mathfrak{p}$ must be a finite field of characteristic $p$, so $p (1 + \mathfrak{p}) = p + \mathfrak{p} = \mathfrak{p}$. In other words, $p \in \mathfrak{p}$. If $q$ is another prime in $\mathfrak{p}$, then recall the BÃ©zout lemma, $px + qy = 1$ for some integers $x, y$. But $\mathbb{Z}$ is a subring of $\mathcal{O}_K$, so $1 \in \mathfrak{p}$, contradicting the primeness of $\mathfrak{p}$.
\\
\\
*As a result, $v_\mathfrak{p}(q) = 0$ for prime $q \neq p$, so for any integer $x$, only the prime power of $p$ matters
$$v_\mathfrak{p} (x) = v_\mathfrak{p} (p^{v_p(x)}) = v_\mathfrak{p} (p) v_p (x) = \mu v_p (x)$$
\end{proof}
\begin{lemma}[Odd prime] \label{odd-val-ineq}
For any odd prime $p$ and integer $k \geq 2$, we have $k \geq v_p (k) + 2$. Equality happens exactly when either $k = 2$, or $k = p = 3$.
\end{lemma}
\begin{proof}
If $v_p (k) = 0$, then $k \geq 2 = 2 + v_p (k)$. Otherwise, suppose $v_p(k) \geq 1$. Consider the function $f(x) = p^x - x - 2$ for $x \geq 0$: its derivative $f'(x) = \ln p \cdot p^x - 1 \geq \ln 3 \cdot p^0 - 1 > 0$ is always positive, so $f$ is \emph{strictly} increasing on $[0, \infty)$. In particular, $f(v_p(k)) \geq f(1) = p - 3 \geq 0$, so $v_p (k) + 2 \leq p^{v_p(k)} \leq k$.
\\
\\
In the case $v_p (k) = 0$, if equality occurs then $k = 2$, which indeed makes $v_p(k) = 0$ regardless of (odd prime) $p$. In the other case, $v_p(k) \geq 1$, since $f$ is strictly increasing, if equality occurs then $v_p (k) = 0$ (since $f(v_p(k)) = f(1)$) and $p = 3$. But that also means, $k = 3^{v_p(k)} = v_p(k) + 2 = 3$.
\end{proof}
\begin{lemma}[Even prime] \label{even-val-ineq} \ 
\begin{enumerate}
	\item For all integer $k \geq 3$, we have $k \geq v_2 (k) + 2$. Equality happens exactly when $k = 4$.
	\item For all integer $k \geq 5$, $k \geq v_2(k) + 5$. Equality happens exactly when $k = 5, 6$ or $8$.
\end{enumerate}
\end{lemma}
\begin{proof}
*For the first inequality: we divide into 2 cases base on $2$-adic value
\begin{enumerate}
	\item If $v_2 (k) \leq 1$: then $2 + v_2 (k) \leq 3 \leq k$.
	\item If $v_2 (k) \geq 2$: let $f(x) = 2^x - x - 2$, where its derivative $f'(x) = \ln 2 \cdot 2^x - 1 \geq \ln 2 \cdot 2^2 - 1 > 0$ is positive for all $x \geq 2$, so $f$ is strictly increasing on $[2, \infty)$. We then have $f(v_2(k)) \geq f(2) = 0$, so $v_2 (k) + 2 \leq 2^{v_2 (k)} \leq k$.
\end{enumerate}
If equality occurs, then either $v_2 (k) = 1$ and $k = 3 = v_2(k) + 2$ (which is impossible), or $v_2 (k) = 2$ and $k = 2^{v_2(k)} = v_2 (k) + 2 = 4$ (which is indeed true).
\\
\\
*For the second inequality: we divide into the following cases (still base on $2$-adic value)
\begin{enumerate}
	\item If $v_2 (k) = 0$: then $5 + v_2 (k) = 5 \leq k$.
	\item If $v_2 (k) = 1$: then $k \geq 6 = v_2 (k) + 1$ (the least even number over $5$) .
	\item If $v_2 (k) = 2$: then $k \geq 8 > v_2 (k) + 5$ (the least number over $5$ that is divisble by $4$).
	\item If $v_2 (k) \geq 3$: by induction (or calculus like the above), one can show that $2^n \geq n + 5$ for all $n \geq 3$ (with equality exactly at $n = 3$). Hence, $k \geq 2^{v_2 (k)} \geq v_2 (k) + 5$.
\end{enumerate}
If equality occurs, then either $v_2 (k) = 0$ and $k = 5 = 5 + v_2(k)$ (which is true), or $v_2 (k) = 1$ and $k = 6 = v_2 (k) + 5$ (which is also true), or $v_2 (k) = 3$ and $k = 2^{v_2 (k)} = v_2 (k) + 5 = 8$ (which is indeed true). Note the inequality is strict in the case $v_2 (k) = 2$.
\end{proof}
\begin{lemma} \label{val-bino-prime-pow-ineq}
For all integers $n, w \geq 1$, prime $p$, and $1 \leq k \leq p^n$
$$v_p \left( {p^n w \choose k} \right) \geq n - v_p (k)$$
\end{lemma}
\begin{proof}
Based on \hyperref[p-adic-high-school-addition]{proposition \ref*{p-adic-high-school-addition}}, we write $k$ and $p^n - k$ in base $p$ as
\begin{align*}
k & = \overline{\cdots a_{n - 1} \hdots a_0} \\
p^n w - k & = \overline{\cdots b_{n - 1} \hdots b_0}
\end{align*}
with $x_j$ be the quotient, $0 \leq y_j \leq p - 1$ be the remainder of $x_{j - 1} + a_j + b_j$ after dividing by $p$
\begin{align*}
a_0 + b_0 & = p x_0 + y_0 \\
a_j + b_j + x_{j - 1} & = p x_j + y_j \mbox{ for } j \geq 1
\end{align*}
We only pay attention to the last $n$ digits of $k$ and $p^n w - k$
\begin{enumerate}
	\item Since $p^n w = k + (p^n w - k) = \overline{\cdots y_{n - 1} \cdots y_0}$, we know that $y_0 = y_1 = \cdots = y_{n - 1} = 0$. Also, since $0 \leq a_j, b_j \leq p - 1$, we also have $0 \leq x_j \leq 1$. Indeed, under induction
	\begin{enumerate}
		\item Base case $j = 0$: since $p x_0 \leq p x_0 + y_0 = a_0 + b_0 \leq 2(p - 1)$, so $x_0 \leq 2 - 2/p$, or $x_0 \leq 1$ since $x_0$ is an integer.
		\item Induction case: suppose $x_{j - 1} \leq 1$, then $p x_j \leq p x_j + y_j = a_0 + b_0 + x_{j - 1} \leq 2p -1$. In other words, $x_j \leq 2 - 1/p$, or $x_j \leq 1$.
	\end{enumerate}
	\item To show $v_p \left( {p^n w \choose k} \right) \geq n - v_p (k)$ for $k \geq 1$, consider two separate cases
	\begin{enumerate}
		\item If $x_j = 0$ for all $0 \leq j < n$, then $a_0 + b_0 = p x_0 + y_0 = 0$ and $a_j + b_j = a_j + b_j + x_{j - 1} = p x_j + y_j = 0$ for each $1 \leq j < n$. Therefore, $a_j = b_j = 0$ for all $0 \leq j < n$. Since $k \geq 1$ (i.e. $k$ is non-zero), $v_p (k) \geq n$, so
		$$v_p \left( {p^n w \choose k} \right) = \sum_j x_j \geq \sum_{j = 0}^{n - 1} x_j = 0 \geq n - v_p (k)$$
		\item There exists some $0 \leq j < n$ such that $x_j \neq 0$, or $x_j = 1$. Pick $j_0$ to be the smallest such. We divide into 2 cases
		\begin{enumerate}
			\item If $j_0 = 0$, then $a_0 + b_0 = p x_0 + y_0 = p$. But $a_0, b_0 \leq p - 1$, so $a_0$ and $b_0$ cannot be zero (otherwise, the other is equal to $p$). Hence, $v_p (k) = 0 = j_0$.
			\item If $1 \leq j_0 < n$, then by definition, $x_j = 0$ for all $j < j_0$. However, $a_0 + b_0 = p x_0 + y_0 = 0$ and $a_j + b_j + x_{j - 1} = p x_j + y_j = 0$ for all $1 \leq j < j_0 < n$, so $a_j = b_j = 0$ for all $0 \leq j < j_0$. This shows that $p^{j_0}$ must divide $k$, or simply $j_0 \leq v_p (k)$. On the other hand, $a_{j_0} + b_{j_0} = a_{j_0} + b_{j_0} + x_{j_0 - 1} = p x_{j_0} + y_{j_0} = p$, while $a_{j_0}, b_{j_0} \leq p - 1$, so both $a_{j_0}$ and $b_{j_0}$ cannot be $0$. Therefore, $v_p (k) \leq j_0$, or just $v_p(k) = j_0$ since we have already shown $j_0 \leq v_p (k)$.
		\end{enumerate}
		In any case, we have $v_p (k) = j_0$. Additionally, for $n > j > j_0 \geq 0$ (so $j \geq 1$), we have $a_j + b_j + x_{j - 1} = p x_j + y_j = p x_j$. By induction, if $x_{j - 1} = 1$, then $p x_j \geq 1$, and so $x_j = 1$ necessarily (as $0 \leq x_j \leq 1$). Therefore, $x_j = 1$ for all $j_0 \leq j < n$. In a sense, $x_j$ represents the carries of the addition between $\overline{1 \hdots 1} \times p^{j_0}$ and $\overline{1} \times p^{j_0}$. Finally, by \hyperref[p-adic-high-school-addition]{proposition \ref*{p-adic-high-school-addition}}, we get
		$$v_p \left( {p^n w \choose k} \right) = \sum_j x_j \geq \sum_{j = 0}^{n - 1} x_j = \sum_{j = j_0}^{n - 1} x_j = n - 1 - j_0 + 1 = n - v_p (k)$$
	\end{enumerate}
\end{enumerate}
\end{proof}
As a result from the proof above, equality happens when $w = 1$.
\begin{proposition} \label{val-bino-prime-pow-eq}
For all integer $n \geq 1$, prime $p$, and $1 \leq k \leq p^n$
$$v_p \left( {p^n \choose k} \right) = n - v_p (k)$$
\end{proposition}
\begin{lemma} \label{2-3-LTE} \ 
\begin{enumerate}
	\item If $k \geq 1$, then $v_2 \left( 3^{2^k} - 1 \right) = k + 2$.
	\item $v_2 (3^k + 1) \leq 2$ for all nonnegative integer $k$. Equality happens exactly when $k$ is odd (i.e. $v_2 (3^k + 1) = 1$ whenever $k$ is even).
\end{enumerate}
\end{lemma}
\begin{proof}
By the binomial theorem
$$3^{2^k} = (1 + 2)^{2^k} = \sum_{i = 0}^{2^k} {2^k \choose i} 2^i$$
Furthermore, by \hyperref[even-val-ineq]{lemma \ref*{even-val-ineq}} and \hyperref[val-bino-prime-pow-eq]{proposition \ref*{val-bino-prime-pow-eq}}
\begin{align*}
v_2 \left( {2^k \choose i} 2^i \right) & = k - v_2 (i) + i \geq k + 2 \mbox{ for } i \geq 3
\\
3^{2^k} & = 1 + 2^k \cdot 2 + \frac{2^k (2^k - 1)}{2} \cdot 2^2 + \sum_{i = 3}^{2^k} {2^k \choose i} 2^i
\\
& = 1 + 2^{2k + 1} + \sum_{i = 3}^{2^k} {2^k \choose i} 2^i \equiv 1 \pmod{2^{k + 2}}
\end{align*}
Note that $k \geq 1$, which means that $2^k \geq 2$ (that's why we can extract the first 3 terms of the sum) and $2k + 1 \geq k + 2$ (for the last congruence). On the other hand,
\begin{enumerate}
	\item If $k = 1$, then $v_2 (3^{2^k} - 1) = 3 = k + 2$
	\item If $k \geq 2$, then $2^k \geq 4$ and $2k + 1 \geq k + 3$, so
	\begin{align*}
	v_2 \left( {2^k \choose i} 2^i \right) & = k - v_2 (i) + i \geq k + 5 \mbox{ for } i \geq 5
	\\
	3^{2^k} & = \sum_{i = 0}^{4} {2^k \choose i} 2^i + \sum_{i = 5}^{2^k} {2^k \choose i} 2^i
	\\
	& \equiv 1 + 2^{2k + 1} + 2^{k + 3} \frac{(2^k - 1)(2^{k - 1} - 1)}{3}
	\\
	& \qquad + 2^{k + 2} \frac{(2^k - 1) (2^{k - 1} - 1) (2^k - 3)}{3}
	\\
	& \equiv 1 + 2^{k + 2} \frac{(2^k - 1) (2^{k - 1} - 1) (2^k - 3)}{3} \not\equiv 1 \pmod{2^{k + 3}}
	\end{align*}
	In other words, $v_2 (3^{2^k} - 1) < k + 3$, which, when combines with the previous lower bound (i.e. $3^{2^k} \equiv 1 \pmod{2^{k + 2}}$), gives us $v_2 (3^{2^k} - 1) = k + 2$.
\end{enumerate}
\ 
\\
*For the second part
\begin{enumerate}
	\item If $n$ is even (i.e. $n = 2k$), then $3^n + 1 = 9^k + 1 \equiv 2 \pmod{8}$, thus $v_2 (3^n + 1) = 1$.
	\item If $n$ is odd (i.e. $n = 2k + 1$), then $3^n + 1 = 9^k \cdot 3 + 1 \equiv 4 \pmod{8}$, thus $v_2 (3^n + 1) = 2$.
\end{enumerate}
\end{proof}

\subsection{$p$ is odd and unramified in $\mathfrak{p}$}
\begin{theorem}
If $N(\mathfrak{p}) = p^m$ and $p$ is unframified in $\mathfrak{p}$, then
$$(\mathcal{O}_K / \mathfrak{p}^t)^\times \cong (C_{p^{t - 1}})^m \times C_{N(\mathfrak{p}) - 1}$$
where $C_n$ is the cyclic group of order $n$.
\end{theorem}
\begin{proof}
When $t = 1$, the isomorphism becomes $(\mathcal{O}_K / \mathfrak{p})^\times \cong C_{N(\mathfrak{p}) - 1}$, which is true since the multiplicative group of a field is cyclic (and $N(\mathfrak{p}) = p^m$ is the cardinality of $\mathcal{O}_K / \mathfrak{p}$). For $t \geq 2$, let
\begin{enumerate}
	\item $\mathfrak{g} = g_0 + \mathfrak{p}$ be a generator of $(\mathcal{O}_K / \mathfrak{p})^\times$.
	\item $\beta = \{ \mathfrak{h}_1, \mathfrak{h}_2, \hdots, \mathfrak{h}_m \}$ be a basis of $\mathcal{O}_K / \mathfrak{p}$ over $\mathbb{F}_p$ (note that $\mathcal{O}_K / \mathfrak{p} \cong \mathbb{F}_{p^m}$). Also, let $h_i$ be some number in $\mathcal{O}_K$ such that $\mathfrak{h}_i = h_i + \mathfrak{p}$. If $h_i \in \mathfrak{p}$, then $h_i + \mathfrak{p} = \mathfrak{p}$, contradicting the fact that $\beta$ is a basis of $\mathcal{O}_K / \mathfrak{p}$. Thus, $h_i \notin \mathfrak{p}$, meaning $v_\mathfrak{p} (h_i) = 0$.
\end{enumerate}
\ \\
*We prove that $1 + p h_i$ is of order $p^{t - 1}$ modulo $\mathfrak{p}^t$. By \hyperref[val-rami-prime]{lemma \ref*{val-rami-prime}}, \hyperref[odd-val-ineq]{lemma \ref*{odd-val-ineq}}, and \hyperref[val-bino-prime-pow-ineq]{lemma \ref*{val-bino-prime-pow-ineq}}
\begin{align*}
v_\mathfrak{p} \left( {p^{t - 1} \choose k} p^k h_i^k \right) & = v_\mathfrak{p}(p) v_p \left( {p^{t - 1} \choose k} p^k \right) + v_\mathfrak{p} (h_i^k) \geq t - 1 - v_p (k) + k \geq t + 1 \\
& \mbox{whenever } k \geq 2 \\
(1 + p h_i)^{p^{t - 1}} & = \sum_{k = 0}^{p^{t - 1}} {p^{t - 1} \choose k} p^k h_i^k = 1 + p^{t - 1} \cdot p h_i + \sum_{k = 2}^{p^{t - 1}} {p^{t - 1} \choose k} p^k h_i^k \\
& \equiv 1 + p^t h_i \equiv 1 \pmod{\mathfrak{p}^t}
\end{align*}
We can split the sum since $p^{t - 1} \geq 3^{2 - 1} = 3$. On the other hand, since $p^{t - 2} \geq 3^{2 - 2} = 1$, we have
\begin{align*}
v_\mathfrak{p} \left( {p^{t - 2} \choose k} p^k h_i^k \right) & = v_\mathfrak{p}(p) v_p \left( {p^{t - 2} \choose k} p^k \right) + v_\mathfrak{p} (h_i^k) \geq t - 2 - v_p (k) + k \geq t \\
& \mbox{whenever } k \geq 2 \\
(1 + p h_i)^{p^{t - 2}} & = \sum_{k = 0}^{p^{t - 2}} {p^{t - 2} \choose k} p^k h_i^k = 1 + p^{t - 2} \cdot p h_i + \sum_{k = 2}^{p^{t - 2}} {p^{t - 2} \choose k} p^k h_i^k \\
& \equiv 1 + p^{t - 1} h_i \not\equiv 1 \pmod{\mathfrak{p}^t}
\end{align*}
(note that $h_i \notin \mathfrak{p}$ so $v_\mathfrak{p}(p^{t - 1} h_i) = t - 1 < t$). Let $H_i$ be the subgroup of $\mathcal{O}_K / \mathfrak{p}^t$ generated by $1 + p h_i + \mathfrak{p}^t$. By the result above, we know that $H_i$ is a cyclic group of order $p^{t - 1}$.
\\
\\
*Next, let $s$ be the order of $g_0$ modulo $\mathfrak{p}^t$ (it can be different based on the choice of $g_0$, but it always have order $N(\mathfrak{p}) - 1$ modulo $\mathfrak{p}$). Since $\mathfrak{p}^t \subseteq \mathfrak{p}$, we also have $g^s \equiv 1 \pmod{\mathfrak{p}}$, so $s$ must be a multiple of $N(\mathfrak{p}) - 1$ by Lagrange theorem. Let $s = r [N(\mathfrak{p}) - 1]$, then $g_0^r$ will have order $N(\mathfrak{p}) - 1$ modulo $\mathfrak{p}^t$. If $G$ is the subgroup generated by $g_0^r + \mathfrak{p}^t$, then it should be a cyclic group of order $N(\mathfrak{p}) - 1$.
\\
\\
*Since $|G| \prod_{i = 1}^m |H_i| = [N(\mathfrak{p}) - 1] \cdot \left( p^{t - 1} \right)^m = N(\mathfrak{p})^{t - 1} [N(\mathfrak{p}) - 1]$, and $|(\mathcal{O}_K / \mathfrak{p}^t)^\times| = \varphi_{\mathcal{O}_K} (\mathfrak{p}^t) = N(\mathfrak{p})^t - N(\mathfrak{p})^{t - 1}$ (according to the \hyperref[eul-totient-thm]{Euler totient theorem}), the order of $G \times \prod_{i = 1}^m H_i$ and $(\mathcal{O}_K / \mathfrak{p}^t)^\times$ are the same. We conjecture that they are actually isomorphic.
\\
\\
Since $H_i$ are cyclic subgroups of $(\mathcal{O}_K / \mathfrak{p}^t)^\times$ (of order $p^{t - 1}$), the kernel the multiplication map $\sigma: \prod_{i = 1}^m H_i \to (\mathcal{O}_K / \mathfrak{p}^t)^\times$ (sending $(b_1, b_2, \hdots, b_m) \mapsto b_1 b_2 \cdots b_m \pmod{\mathfrak{p}^t}$) consists of elements of the form
$$\prod_{i = 1}^m (1 + p h_i)^{x_i} \equiv 1 \pmod{\mathfrak{p}^t}$$
for some $0 \leq x_1, x_2, \hdots, x_m < p^{t - 1}$. Suppose at least one $x_i$ is not zero, then $w = v_p(\gcd(x_1, x_2, \hdots, x_m))$ is non-negative (not $-\infty$), and $x_i = p^w y_i$ such that $y_i$ are not simultaneously divisible by $p$. We also have $w < t - 1$ (since $x_i < p^{t - 1}$), so the congruence above works for smaller modulus $\mathfrak{p}^{w + 2}$.
\begin{align*}
\prod_{i = 1}^m (1 + p h_i)^{x_i} & \equiv 1 \pmod{\mathfrak{p}^{w + 2}} \\
\prod_{i = 1}^m (1 + p h_i)^{p^w y_i} & \equiv 1 \pmod{\mathfrak{p}^{w + 2}} \\
\prod_{i = 1}^m \sum_{k = 1}^{p^w y_i} {p^w y_i \choose k} p^k h_i^k & \equiv 1 \pmod{\mathfrak{p}^{w + 2}}
\end{align*}
By \hyperref[odd-val-ineq]{lemma \ref*{odd-val-ineq}} and \hyperref[val-bino-prime-pow-ineq]{lemma \ref*{val-bino-prime-pow-ineq}}, for $k \geq 2$, we have
$$v_\mathfrak{p} \left( {p^w y_i \choose k} p^k h_i^k \right) = v_p \left( {p^w y_i \choose k} \right) + k \geq w - v_p(k) + k \geq w + 2$$
Consider
\begin{enumerate}
	\item If $x_i = p^w y_i \geq 1$, then we can split the sum as
	\begin{align*}
	\sum_{k = 1}^{p^w y_i} {p^w y_i \choose k} p^k h_i^k & = 1 + p^w y_i \cdot p h_i + \sum_{k = 2}^{p^w y_i} {p^w y_i \choose k} p^k h_i^k \\
	& \equiv 1 + p^{w + 1} y_i h_i \pmod{\mathfrak{p}^{w + 2}}
	\end{align*}
	\item If $x_i = p^w y_i = 0$, then $y_i = 0$, and the sum turns into
	\begin{align*}
	\sum_{k = 1}^{p^w y_i} {p^w y_i \choose k} p^k h_i^k & = 1 = 1 + p^{w + 1} y_i h_i
	\end{align*}
\end{enumerate}
In either case, the previous congruence turns into
$$\prod_{i = 1}^m \sum_{k = 1}^{p^w y_i} {p^w y_i \choose k} p^k h_i^k \equiv \prod_{i = 1}^m \left( 1 + p^{w + 1} y_i h_i \right) \equiv 1 \pmod{\mathfrak{p}^{w + 2}}$$
If we distribute the above product (in the middle), every term that multiplies at least 2 different factors of the form $p^{w + 1} y_i h_i$, then such term has to be divisible by $p^{2w + 2}$. But $v_\mathfrak{p} (p^{2w + 2}) = 2w + 2 \geq w + 2$, so those terms can be cancelled modulo $\mathfrak{p}^{w + 2}$. That leaves us with $1$ and $p^{w + 1} y_i h_i$
\begin{align*}
1 + \sum_{i = 1}^m p^{w + 1} y_i h_i & \equiv 1 \pmod{\mathfrak{p}^{w + 2}} \\
p^{w + 1} \sum_{i = 1}^m y_i h_i & \equiv 0 \pmod{\mathfrak{p}^{w + 2}}
\end{align*}
Since $v_\mathfrak{p}(p^{w + 1}) = w + 1$,
$$v_\mathfrak{p} \left( \sum_{i = 1}^m y_i h_i \right) = v_\mathfrak{p} \left( p^{w + 1} \sum_{i = 1}^m y_i h_i \right) - (w + 1) \geq (w + 2) - (w + 1) = 1$$
i.e.
\begin{align*}
\sum_{i = 1}^m y_i h_i & \in \mathfrak{p} \\
\sum_{i = 1}^m y_i (h_i + \mathfrak{p}) & = \mathfrak{p} \\
\sum_{i = 1}^m y_i \mathfrak{h}_i & = \mathfrak{p}
\end{align*}
Yet $\beta = \{ \mathfrak{h}_i : 1 \leq i \leq m \}$ is a basis of $\mathcal{O}_K / \mathfrak{p}$ over $\mathbb{F}_p$, so the coefficients $y_i$ must be zero modulo $p$, contradicting the fact that they are not simultaneously divisible by $p$. Thus, the intial assumption is false, which means that all $x_i$ has to be zero. The kernel is then trivial, or equivalently, the multiplication map $\sigma: \prod_{i = 1}^m H_i \to (\mathcal{O}_K/\mathfrak{p}^t)^\times$ is an embedding, with the image be just $H_1 H_2 \cdots H_m$.
\\
\\
*Finally, consider another multiplication map $\sigma: G \times \prod_{i = 1}^m H_i \to (\mathcal{O}_K/\mathfrak{p}^t)^\times$: since the order of $G$ (which is $N(\mathfrak{p}) = p^m - 1$) and $\prod_{i = 1}^m H_i$ (which is $p^{m(t - 1)}$) is relatively prime, the kernel is trivial. Indeed, 
\begin{enumerate}
	\item Given $\mathfrak{a} \in G$ and $\mathfrak{b}_i \in H_i$ such that $\mathfrak{a} \prod_{i = 1}^m \mathfrak{b}_i = 1 + \mathfrak{p}$ (the identity in $(\mathcal{O}_K/\mathfrak{p}^t)^\times$), then $\mathfrak{a}^{p^{m(t - 1)}} = \left( \prod_{i = 1}^m \mathfrak{b}_i \right)^{-p^{m(t - 1)}} = 1 + \mathfrak{p}$.
	\item But $p^m - 1$ and $p^{m(t - 1)}$ are relative prime, so by BÃ©zout lemma, there exists some integer $x, y$ such that $(p^m - 1)x + p^{m(t - 1)} y = 1$. Hence, $\mathfrak{a} = \mathfrak{a}^{(p^m - 1) x + p^{m(t - 1)} y} = \left( \mathfrak{a}^{p^m - 1} \right)^x \cdot \left( \mathfrak{a}^{p^{m (t - 1)}} \right)^y = 1 + \mathfrak{p}$.
	\item It also means that $\prod_{i = 1}^m \mathfrak{b}_i = \mathfrak{a}^{-1} = 1 + \mathfrak{p}$, but from the previous result, we must have $\mathfrak{b}_i = 1 + \mathfrak{p}$.
\end{enumerate}
Thus, $G \times \prod_{i = 1}^m H_i$ embeds into $(\mathcal{O}_K/\mathfrak{p}^t)^\times$. But we already observe that these 2 groups have the same (finite) order, so the embedding is actually an isomorphism. We conclude that
$$(\mathcal{O}_K/\mathfrak{p}^t)^\times \cong G \times \prod_{i = 1}^m H_i \cong C_{N(\mathfrak{p}) - 1} \times \left( C_{p^{t - 1}}\right)^m$$
\end{proof}
\begin{corollary}
For each $t \geq 1$
$$(\mathbb{Z}/p^t \mathbb{Z})^\times \cong C_{p - 1} \times C_{p^{t - 1}}$$
\end{corollary}

\begin{shaded}
\subsection{$p$ is odd and ramified in $\mathfrak{p}$}
\begin{theorem}
If $N(\mathfrak{p}) = p^m$ and $v_\mathfrak{p}(p) = \mu$, then for $t \geq \mu$, we get
$$(\mathcal{O}_K / \mathfrak{p}^t)^\times \cong \left( \prod_{j = 0}^{\mu - 1} C_{p^{\lceil (t - j)/\mu \rceil - 1}} \times C_{\mu - 1} \right)^m \times C_{N(\mathfrak{p}) - 1}$$
\end{theorem}
\begin{proof}
Let
\begin{enumerate}
	\item $g_0$ be a generator modulo $\mathfrak{p}$ (i.e. a primitive root) of $(\mathcal{O}_K / \mathfrak{p})^\times$. In particular, $g_0^{N(\mathfrak{p}) - 1} \equiv 1 \pmod{\mathfrak{p}}$.
	\item $\{ h_1, h_2, \hdots, h_m \}$ be a basis modulo $\mathfrak{p}$ of $\mathcal{O}_K / \mathfrak{p}$ over $\mathbb{F}_p$. In particular, $h_i$ is not in $\mathfrak{p}$, and whenever $z_1 h_1 + z_2 h_2 + \cdots + z_m h_m \equiv 0 \pmod{\mathfrak{p}}$ (with $z_i \in \mathbb{Z}$), $z_i$ are simultaneously divisible by $p$.
	\item $\omega \in \mathfrak{p} \setminus \mathfrak{p}^2$ (i.e. $v_\mathfrak{p}(\omega) = 1$) so that $p \mid \omega^\mu$ (note that, by definition of $\mu$, $p \mathcal{O}_K = \mathfrak{p}^\mu \mathfrak{q}$ where $v_\mathfrak{p}(\mathfrak{q}) = 0$)
\end{enumerate}
\ \\
*We show that the order of $1 + p \omega^j h_i$ modulo $\mathfrak{p}^t$ is $p^{s_j}$ where $s_j = \lceil (t - j)/\mu \rceil - 1$ (for $0 \leq j < \mu$). Indeed, by \hyperref[val-rami-prime]{lemma \ref*{val-rami-prime}}, \hyperref[odd-val-ineq]{lemma \ref*{odd-val-ineq}}, and \hyperref[val-bino-prime-pow-ineq]{lemma \ref*{val-bino-prime-pow-ineq}}
\begin{align*}
v_\mathfrak{p} \left( {p^{s_j} \choose k} p^k \omega^{jk} h_i^k \right) & = \mu (s_j - v_p(k)) + (\mu + j)k \geq \mu \left( \frac{t - j}{\mu} - 1 - v_p(k) + k \right) + jk \\
& \geq t + \mu + j (k - 1) \geq t + \mu + j > t \\
& \mbox{whenever } k \geq 2, j \geq 0 \\
(1 + p \omega^j h_i)^{p^{s_j}} & = \sum_{k = 0}^{p^{s_j}} {p^{s_j} \choose k} p^k \omega^{jk} h_i^k = 1 + p^{s_j + 1} \omega^j h_i + \sum_{k = 2}^{p^{s_j}} {p^{s_j} \choose k} p^k \omega^{jk} h_i^k \\
& \equiv 1 + p^{\lceil (t - j)/\mu \rceil} \omega^j h_i \equiv 1 \pmod{\mathfrak{p}^t}
\end{align*}
The last congruence holds because $v_\mathfrak{p} \left( p^{\lceil (t - j)/\mu \rceil} \omega^j h_i \right) = \mu \lceil (t - j)/\mu \rceil + j \geq t$. On the other hand,
\begin{align*}
v_\mathfrak{p} \left( {p^{s_j - 1} \choose k} p^k \omega^{jk} h_i^k \right) & = \mu (s_j - 1 - v_p(k)) + (\mu + j)k \geq \mu \left( \frac{t - j}{\mu} - 2 - v_p(k) + k \right) + jk \\
& \geq t + j (k - 1) \geq t \\
& \mbox{whenever } k \geq 2, j \geq 0 \\
(1 + p \omega^j h_i)^{p^{s_j - 1}} & = \sum_{k = 0}^{p^{s_j - 1}} {p^{s_j - 1} \choose k} p^k \omega^{jk} h_i^k = 1 + p^{s_j} \omega^j h_i + \sum_{k = 2}^{p^{s_j - 1}} {p^{s_j - 1} \choose k} p^k \omega^{jk} h_i^k \\
& \equiv 1 + p^{\lceil (t - j)/\mu \rceil - 1} \omega^j h_i \not\equiv 1 \pmod{\mathfrak{p}^t}
\end{align*}
since $v_\mathfrak{p} \left( p^{\lceil (t - j)/\mu \rceil - 1} \omega^j h_i \right) < \mu \cdot (t - j)/\mu + j = t$.
\\
\\
*Note that the order of $1+\omega^j h_i$ (modulo $\mathfrak{p}^t$) is a \textit{non-trivial} power of $p$ for $1 \leq j \leq \mu - 1$, so let $r_{ij}$ be such that $(1 + \omega^j h_i)^{r_{ij}}$ has order $p$. Let $W_{ij}$ be the subgroup (of $\left( \mathcal{O}_K/\mathfrak{p}^t \right)^\times$) generated by $1 + p \omega^j h_i$, and $M_{ij}$ be the subgroup generated by $(1 + \omega^j h_i)^{p^{r_{ij}}}$. Note that $|W_{ij}| = p^{s_j}$, $|M_{ij}| = p$, and
\begin{align*}
\prod_{i = 1}^m \prod_{j = 0}^{\mu - 1} p^{s_j} \cdot \prod_{i = 1}^m \prod_{j = 1}^{\mu - 1} p = p^{m(t - 1)}
\end{align*}
which the order of the $p$-torsion subgroup of $\left( \mathcal{O}_K/\mathfrak{p}^t \right)^\times$, so we will prove that the product of these groups embedded into $\left( \mathcal{O}_K/\mathfrak{p}^t \right)^\times$ (through multiplication map). Let $0 \leq \lambda_{ij} < s_j$ and $0 \leq \kappa_{ij} < p$ be such that
\begin{align*}
\prod_{j = 0}^{\mu-1} \prod_{i = 1}^m (1 + p \omega^j h_i)^{\lambda_{ij}} \cdot \prod_{j = 1}^{\mu-1} \prod_{i = 1}^m (1 + \omega^j h_i)^{p^{r_{ij}} \kappa_{ij}} & \equiv 1 \pmod{\mathfrak{p}^t}
\end{align*}
Under modulus $\mathfrak{p}^\mu$, this congruence turns into
\begin{align*}
\prod_{j = 1}^{\mu-1} \prod_{i = 1}^m (1 + \omega^j h_i)^{p^{r_{ij}} \kappa_{ij}} & \equiv 1 \pmod{\mathfrak{p}^\mu}
\end{align*}

\end{proof}

\subsection{2 is unramified in $\mathfrak{p}$}
\begin{theorem}
Suppose $N(\mathfrak{p}) = 2^m$ ($m \geq 1$) and $2$ is unramified in $\mathfrak{p}$. Then
\begin{enumerate}
	\item For $t = 1$: $(\mathcal{O}_K / \mathfrak{p})^\times \cong C_{N(\mathfrak{p}) - 1}$
	\item For $t = 2$: $(\mathcal{O}_K / \mathfrak{p}^2)^\times \cong (C_2)^m \times C_{N(\mathfrak{p}) - 1}$
	\item For $t \geq 3$
	$$(\mathcal{O}_K / \mathfrak{p}^t)^\times \cong (C_2 \times C_{2^{t - 2}}) \times (C_{2^{t - 1}})^{m - 1} \times C_{N(\mathfrak{p}) - 1}$$
\end{enumerate}
\end{theorem}
\begin{proof}
The case $t = 1$ proceeds just the same as the previous theorem (by noting that the multiplicative group of a finite field is cyclic). For the case $t = 2$, let
\begin{enumerate}
	\item $\mathfrak{g} = g_0 + \mathfrak{p}$ be a generator of the (cyclic) group $(\mathcal{O}_K / \mathfrak{p})^\times$.
	\item $\beta = \{ \mathfrak{h}_1, \mathfrak{h}_2, \hdots, \mathfrak{h}_m \} = \{ h_i + \mathfrak{p} : 1 \leq i \leq m \}$ be a basis of $\mathcal{O}_K/\mathfrak{p}$ over $\mathbb{F}_2$.
\end{enumerate}
Like the above proof for odd prime, we first show the order of $1 + 2 h_i$ is $2$ modulo $\mathfrak{p}^2$. Indeed, note that $h_i \notin \mathfrak{p}$ (otherwise $\beta$ is not a basis), so $2 h_i \not\equiv 0 \pmod{\mathfrak{p}^2}$ and hence, $1 + 2h_i \not\equiv 1 \pmod{\mathfrak{p}^2}$. On the other hand, since $v_\mathfrak{p}(2) = 1$ (2 is unramified in $\mathfrak{p}$), we get $(1 + 2h_i)^2 = 1 + 4 h_i + 4 h_i^2 \equiv 1 \pmod{\mathfrak{p}^2}$.
\\
\\
Let $H_i$ be the (cyclic) subgroup of $(\mathcal{O}_K / \mathfrak{p}^2)^\times$ generated by $1 + 2h_i + \mathfrak{p}^2$. Consider an element in the kernel of the multiplication map $\sigma: \prod_{i = 1}^m H_i \to (\mathcal{O}_K / \mathfrak{p}^2)^\times$ (sending $(b_1, b_2, \hdots, b_m) \mapsto b_1 b_2 \cdots b_m$)
\begin{align*}
\prod_{i = 1}^m (1 + 2h_i)^{u_i} \equiv 1 \pmod{\mathfrak{p}^2}
\end{align*}
where $0 \leq u_i \leq 1$. In simple term, it is just a product of $1 + 2h_i$ (but not necessarily all $i$ from $1$ to $m$). Therefore, since $v_\mathfrak{p} (4) = 2$, we have
\begin{align*}
1 + 2 \sum_{i = 1}^m u_i h_i & \equiv 1 \pmod{\mathfrak{p}^2} \\
2 \sum_{i = 1}^m u_i h_i & \equiv 0 \pmod{\mathfrak{p}^2}
\end{align*}
It is then necessary that $\sum_{i = 1}^m u_i h_i \in \mathfrak{p}$. But since $\mathfrak{h}_i = h_i + \mathfrak{p}$ are linearly independent over $\mathbb{F}_2$, $u_i = 0 \pmod{2}$, or just simply $u_i = 0$ since $0 \leq u_i \leq 1$. Hence, the kernel of the multiplication map is trivial, i.e. $\prod_{i = 1}^m H_i$ embeds into $(\mathcal{O}_K / \mathfrak{p}^2)^\times$.
\\
\\
Next, let $s$ be the order of $g_0$ modulo $\mathfrak{p}^2$, so in particular, we have $g_0^s \equiv 1 \pmod{\mathfrak{p}}$. Since $g_0$ is of order $N(\mathfrak{p}) - 1$ modulo $\mathfrak{p}$, $s$ must be a multiple of $N(\mathfrak{p}) - 1$, i.e. $s = [N(\mathfrak{p}) - 1] r$ for some $r \geq 1$. It is then true that $g_0^r$ is of order $N(\mathfrak{p}) - 1$ modulo $\mathfrak{p}^2$, so let $G$ be the subgroup of $(\mathcal{O}_K / \mathfrak{p}^2)^\times$ generated by $g_0^r + \mathfrak{p}^2$. Since the order of $G$ is $N(\mathfrak{p}) - 1 = 2^m - 1$, which is relatively prime to the order of $H_i$ ($|H_i| = 2$), we can argue similarly (like the above proof for odd prime) that $G \times \prod_{i = 1}^m H_i$ embeds into $(\mathcal{O}_K / \mathfrak{p}^2)^\times$ through the multiplication map. But $\left| G \times \prod_{i = 1}^m H_i \right| = |G| \prod_{i = 1}^m |H_i| = 2^m [N(\mathfrak{p}) - 1] = N(\mathfrak{p})^2 - N(\mathfrak{p}) = |(\mathcal{O}_K / \mathfrak{p}^2)^\times|$, so the 2 are isomorphic
$$(\mathcal{O}_K / \mathfrak{p}^2)^\times \cong G \times \prod_{i = 1}^m H_i \cong C_{N(\mathfrak{p}) - 1} \times (C_2)^m$$
\\
\\
*For $t \geq 3$
\begin{enumerate}
	\item $N(\mathfrak{p}) = 2$: 
	\begin{enumerate}
		\item $\varphi_{\mathcal{O}_K}(\mathfrak{p}^t) = 2^t - 2^{t - 1} = 2^{t - 1}$
		\item $(\mathcal{O}_K / \mathfrak{p}^t)^\times \cong \langle -1 + \mathfrak{p}^t \rangle \times \langle 3 + \mathfrak{p}^t \rangle \cong C_2 \times C_{2^{t - 2}}$
	\end{enumerate}
	\item $N(\mathfrak{p}) = 4, t = 3$:
	\begin{enumerate}
		\item $\varphi_{\mathcal{O}_K}(\mathfrak{p}^3) = 2^4 \cdot 3$
		\item $\mathcal{O}_K / \mathfrak{p} = \operatorname{span}_{\mathbb{F}_2} \{ 1 + \mathfrak{p}, h + \mathfrak{p} \}$
		\item $h^2 \equiv h + 1 \pmod{\mathfrak{p}}$
		\item
		\begin{align*}
		\langle -1 \rangle & = \{ -1, 1 \} \\
		\langle 1 + 4h \rangle & = \{ 1, 1 + 4h \} \\
		\langle 1 + 2h \rangle & = \{ 1, 1 + 2h, 5, -3 + 2h \} \\
		(\mathcal{O}_K / \mathfrak{p}^3)^\times & = \langle -1 \rangle \cdot \langle 1 + 4h \rangle \cdot \langle 1 + 2h \rangle \cdot \langle h \rangle \cong (C_2)^2 \times C_4 \times C_3 \\
		& \\
		\langle -1 \rangle & = \{ -1, 1 \} \\
		\langle 3 \rangle & = \{ 1, 3 \} \\
		\langle 1 + 2h \rangle & = \{ 1, 1 + 2h, 5, -3 + 2h \} \\
		(\mathcal{O}_K / \mathfrak{p}^3)^\times & \neq \langle -1 \rangle \cdot \langle 3 \rangle \cdot \langle 1 + 2h \rangle \cdot \langle h \rangle
		\end{align*}
	\end{enumerate}
	\item $N(\mathfrak{p}) = 4, t = 4$:
	\begin{enumerate}
		\item $\varphi_{\mathcal{O}_K}(\mathfrak{p}^3) = 2^6 \cdot 3$
		\item $\mathcal{O}_K / \mathfrak{p} = \operatorname{span}_{\mathbb{F}_2} \{ 1 + \mathfrak{p}, h + \mathfrak{p} \}$
		\item $h^2 \equiv h + 1 \pmod{\mathfrak{p}}$
		\item
		\begin{align*}
		\langle -1 \rangle & = \{ 1, -1 \} \\
		\langle 1 + 4h \rangle & = \{ 1, 1 + 4h, 1 + 8h, 1 - 4h \} \\
		\langle 1 + 2h \rangle & = \{ 1, 1 + 2h, 1 + 4h + 4h^2, 1 - 2h + 4h^2, 9, 9 + 2h, 9 + 4h + 4h^2, 9 - 2h + 4h^2 \} \\
		(\mathcal{O}_K / \mathfrak{p}^4)^\times & = \langle -1 \rangle \cdot \langle 1 + 4h \rangle \cdot \langle 1 + 2h \rangle \cdot \langle h \rangle \cong C_2 \times C_4 \times C_8 \times C_3
		\end{align*}
	\end{enumerate}
	\item $N(\mathfrak{p}) = 4$:
	\begin{enumerate}
		\item $\varphi_{\mathcal{O}_K}(\mathfrak{p}^t) = 2^{2(t - 1)} \cdot 3$
		\item $\mathcal{O}_K / \mathfrak{p} = \operatorname{span}_{\mathbb{F}_2} \{ 1 + \mathfrak{p}, h + \mathfrak{p} \} \cong \mathbb{F}_4$
		\item $h^3 \equiv 1, h^2 \equiv h + 1 \pmod{\mathfrak{p}}$
		\item
		\begin{align*}
		(\mathcal{O}_K / \mathfrak{p}^t)^\times & = \langle -1 \rangle \cdot \langle 1 + 4h \rangle \cdot \langle 1 + 2h \rangle \cdot \langle h \rangle \cong C_2 \times C_{2^{t - 2}} \times C_{2^{t - 1}} \times C_3
		(-1)^u (1 + 2^{r + 1} w (2^r w - 1) + 2^{r + 1} w h + 2^{r + 1} w (2^r w - 1) h)^{2^r w} \equiv 1 \pmod{\mathfrak{p}^{r + 2}}
		\end{align*}
	\end{enumerate}
	\item $N(\mathfrak{p}) = 8, t = 3$:
	\begin{enumerate}
		\item $\varphi_{\mathcal{O}_K}(\mathfrak{p}^3) = 2^6 \cdot 7$
		\item $\mathcal{O}_K / \mathfrak{p} = \operatorname{span}_{\mathbb{F}_2} \{ 1 + \mathfrak{p}, h + \mathfrak{p}, h^2 + \mathfrak{p} \} \cong \mathbb{F}_8 \cong \mathbb{F}_2 [h] / \langle h^3 + h + 1 \rangle$
		\item $(\mathcal{O}_K / \mathfrak{p})^\times = \langle h \rangle$
		\item
		\begin{align*}
		\langle -1 \rangle & = \{ 1, -1 \} \\
		\langle 3 \rangle & = \{ 1, 3 \} \\
		\langle 1 + 4h \rangle & = \{ 1, 1 + 4h \} \\
		\langle 1 + 2h \rangle & = \{ 1, 1 + 2h, 1 + 4h + 4h^2, 1 - 2h + 4h^2 \} \\
		\langle 1 + 4h^2 \rangle & = \{ 1, 1 + 4h^2 \} \\
		\langle 1 + 2h^2 \rangle & = \{ 1, 1 + 2h^2, 1 + 4h, 1 + 4h + 2h^2 \} \\
		(\mathcal{O}_K / \mathfrak{p}^3)^\times & = \langle -1 \rangle \cdot \langle 3 \rangle \cdot  \langle 1 + 2h \rangle \cdot \langle 1 + 2h^2 \rangle \\
		& \cong (C_2)^2 \times (C_4)^2 \times C_7
		\end{align*}
	\end{enumerate}
	\item $N(\mathfrak{p}) = 2^m$:
	\begin{enumerate}
		\item $\varphi_{\mathcal{O}_K}(\mathfrak{p}^t) = 2^{m(t - 1)} \cdot (2^m - 1)$
		\item $\mathcal{O}_K / \mathfrak{p} = \operatorname{span}_{\mathbb{F}_2} \{ h^i : 0 \leq i \leq m - 1 \} $
		\item $(\mathcal{O}_K / \mathfrak{p})^\times = \langle h \rangle$
		\item
		\begin{align*}
		\prod_{i = 1}^{m - 1} (1 + 2 h^i)^{2^w y_i} & \equiv 1 \pmod{\mathfrak{p}^{w + 2}} \\
		\sum_{i = 1}^{m - 1} y_i h^i + y_i (2^w y_i - 1) h^{2i}] & \equiv 0 \pmod{\mathfrak{p}}
		\end{align*}
	\end{enumerate}
\end{enumerate}
\end{proof}
\begin{proof}[Temp Idea]
*For $t \geq 3$, we can still obtain $g_0$ and $h_i$ from the case $t = 2$. However, instead of using the basis $\beta = \{ h_i + \mathfrak{p} : 1 \leq i \leq m \}$, we normalize it by multiply the inverse of $h_m$. Denote $e_i = h_i h_m^{-1}$, then $h_m^{-1} \beta = \{ e_i + \mathfrak{p} : 1 \leq i \leq m \} = \{ \mathfrak{e}_i : 1 \leq i \leq m \}$ is also a basis for $(\mathcal{O}_K / \mathfrak{p})^\times$ (over $\mathbb{F}_2$). Note that $e_i \not\equiv e_m = 1 \pmod{\mathfrak{p}}$ for all $1 \leq i \leq m - 1$ since $\mathfrak{e}_i$ must be linearly independent over $\mathbb{F}_2$.
\\
\\
Let $H_i$ be the subgroup of $1 + 2 e_i + \mathfrak{p}^t$ (for $1 \leq i \leq m - 1$). We prove that its order is $2^{t - 1}$. Indeed, since $2^{t - 1} \geq 2^{t - 2} \geq 2$, we can split the following sums
\begin{align*}
v_\mathfrak{p} \left( {2^{t - 1} \choose k} 2^k e_i^k \right) & \geq t - 1 - v_2 (k) + k \geq t + 1 \mbox{ for } k \geq 3 \\
(1 + 2 e_i)^{2^{t - 1}} & = \sum_{k = 0}^{2^{t - 2}} {2^{t - 2} \choose k} 2^k e_i^k \\
& = 1 + 2^t e_i + 2^t (2^{t - 1} - 1) e_i^2 + \sum_{k = 3}^{2^{t - 2}} {2^{t - 2} \choose k} 2^k e_i^k \\
& \equiv 1 \pmod{\mathfrak{p}^t} \\
& \\
v_\mathfrak{p} \left( {2^{t - 2} \choose k} 2^k e_i^k \right) & \geq t - 2 - v_2 (k) + k \geq t \mbox{ for } k \geq 3 \\
(1 + 2 e_i)^{2^{t - 2}} & = 1 + 2^{t - 1} e_i + 2^{t - 1} (2^{t - 2} - 1) e_i^2 + \sum_{k = 3}^{2^{t - 2}} {2^{t - 2} \choose k} 2^k e_i^k \\
& \equiv 1 + 2^{t - 1} e_i [1 + (2^{t - 2} - 1) e_i] \pmod{\mathfrak{p}^t}
\end{align*}
In the last congruence, we have $e_i \not\equiv e_m = 1\pmod{\mathfrak{p}}$, so $1 + (2^{t - 2} - 1) e_i \not\equiv 1 + (2^{t - 2} - 1) \equiv 0 \pmod{\mathfrak{p}}$. In other words, $v_\mathfrak{p} (1 + (2^{t - 2} - 1) e_i) = 0$, and thus
\begin{align*}
v_\mathfrak{p} \left( 2^{t - 1} e_i [1 + (2^{t - 2} - 1) e_i] \right) & = v_\mathfrak{p}(2) v_2 (2^{t - 1}) + v_\mathfrak{p}(e_i) + v_\mathfrak{p} (1 + (2^{t - 2} - 1) e_i) \\
& = t - 1 < t \\
(1 + 2 e_i)^{2^{t - 2}} & \equiv 1 + 2^{t - 1} e_i [1 + (2^{t - 2} - 1) e_i] \not\equiv 1 \pmod{\mathfrak{p}^t}
\end{align*}
\\
Let $E$ be the (exceptional) subgroup of $(\mathcal{O}_K / \mathfrak{p}^t)^\times$ generated by $2 e_m + 1 + \mathfrak{p}^t = 3 + \mathfrak{p}^t$. By \hyperref[2-3-LTE]{lemma \ref*{2-3-LTE}}, $v_2 \left( 3^{2^k} - 1 \right) = k + 2$, so $v_\mathfrak{p} \left( 3^{2^{t - 2}} - 1 \right) = v_\mathfrak{p}(2) v_2 \left( 3^{2^{t - 2}} - 1 \right) = t$ and $v_\mathfrak{p} \left( 3^{2^{t - 3}} - 1 \right) = t - 1 < t$. This should be enough to show that the order of 3 is $2^{t - 2}$ modulo $\mathfrak{p}^t$. Denote $S = \{ \pm 1 + \mathfrak{p}^t \}$ to be the (cylic) subgroup of $(\mathcal{O}_K / \mathfrak{p}^t)^\times$.
\\
\\
We show that the multiplication map $S \times E \times \prod_{i = 1}^{m - 1} H_i \to (\mathcal{O}_K / \mathfrak{p}^t)^\times$ is an embedding. Consider an element of the kernel: there exists some $0 \leq z \leq 1, 0 \leq y_m < 2^{t - 2}$ and $0 \leq x_i < 2^{t - 1}$ such that
\begin{align*}
(-1)^{-z} 3^{-y_m} \prod_{i = 1}^{m - 1} (1 + 2 e_i)^{x_i} & \equiv 1 \pmod{\mathfrak{p}^t} \\
\prod_{i = 1}^{m - 1} (1 + 2 e_i)^{x_i} & \equiv (-1)^z 3^{y_m} \pmod{\mathfrak{p}^t}
\end{align*}
Suppose $x_i$ are not simultaneously zero, then $w = v_2 (\gcd(x_1, x_2, \hdots, x_{m - 1})) \geq 0$ and $y_i$ are not simultaneously divisible by $2$, where $x_i = 2^w y_i$. Since $x_i < 2^{t - 1}$, $w < t - 1$, so we can reduce the power of the modulus from $t$ to $w + 2$.
\begin{align*}
\prod_{i = 1}^{m - 1} (1 + 2 e_i)^{x_i} & \equiv (-1)^z 3^{y_m} \pmod{\mathfrak{p}^{w + 2}} \\
\prod_{i = 1}^{m - 1} (1 + 2 e_i)^{2^w y_i} & \equiv (-1)^z 3^{y_m} \pmod{\mathfrak{p}^{w + 2}} \\
\prod_{i = 1}^{m - 1} \sum_{k = 0}^{2^w y_i} {2^w y_i \choose k} 2^k e_i^k & \equiv (-1)^z 3^{y_m} \pmod{\mathfrak{p}^{w + 2}}
\end{align*}
But $v_\mathfrak{p} \left( {2^w y_i \choose k} 2^k e_i^k \right) \geq w - v_2 (k) + k \geq w + 2$ for $k \geq 3$, so consider each factor on the left
\begin{enumerate}
	\item If $x_i = 2^w y_i = 0$: then $y_i = 0$, and so the sum turns into
	$$\sum_{k = 0}^{2^w y_i} {2^w y_i \choose k} 2^k e_i^k = 1 = 1 + 2^{w + 1} y_i e_i \left[ 1 + (2^w y_i - 1) e_i \right]$$
	\item If $x_i = 2^w y_i = 1$: then $w = 0$ and $y_i = 1$. The sum turns into
	$$\sum_{k = 0}^{2^w y_i} {2^w y_i \choose k} 2^k e_i^k = 1 + 2 e_i = 1 + 2^{w + 1} y_i e_i \left[ 1 + (2^w y_i - 1) e_i \right]$$
	\item If $x_i = 2^w y_i \geq 2$: then we split the sum into
	\begin{align*}
	\sum_{k = 0}^{2^w y_i} {2^w y_i \choose k} 2^k e_i^k & = \sum_{k = 0}^2 {2^w y_i \choose k} 2^k e_i^k + \sum_{k = 3}^{2^w y_i} {2^w y_i \choose k} 2^k e_i^k \\
	& \equiv 1 + 2^{w + 1} y_i e_i + 2^{w + 1} y_i (2^w y_i - 1) e_i^2 \\
	& \equiv 1 + 2^{w + 1} y_i e_i \left[ 1 + (2^w y_i - 1) e_i \right] \pmod{\mathfrak{p}^{w + 2}}
	\end{align*}
\end{enumerate}
In any case, the previous congruence turns into
\begin{align*}
\prod_{i = 1}^{m - 1} \left[ 1 + 2^{w + 1} y_i e_i \left( 1 + (2^w y_i - 1) e_i \right) \right] & \equiv (-1)^z 3^{y_m} \pmod{\mathfrak{p}^{w + 2}}
\end{align*}
Distributing the factors in the product on LHS, then each term with a factor of the form $(2^{w + 1} y_i e_i) (2^{w + 1} y_j e_j)$ (for $i \neq j$) will be cancelled modulo $\mathfrak{p}^{w + 2}$, since the $\mathfrak{p}$-adic valuation is at least $2(w + 1) \geq w + 2$ (note that $w \geq 0$). Therefore,
\begin{align*}
1 + 2^{w + 1} \sum_{i = 1}^{m - 1} y_i e_i \left[ 1 + (2^w y_i - 1) e_i \right] & \equiv (-1)^z 3^{y_m} \pmod{\mathfrak{p}^{w + 2}}
\end{align*}
\end{proof}
\end{shaded}

\newpage

\begin{shaded}

\chapter{Analytic Number Theory}
\begin{theorem}[MÃ¶bius inversion formula]
The MÃ¶bius function
\begin{align*}
\mu(n) = \begin{cases}
1 & \mbox{ if } n \mbox{ is square-free with an even number of prime factors}
\\
-1 & \mbox{ if } n \mbox{ is square-free with an odd number of prime factors}
\\
0 & \mbox{ otherwise}
\end{cases}
\end{align*}
is the multiplicative inverse of the identity function $1(n) = 1$, with respect to the Dirichlet convolution
\begin{align*}
	f * g (n) = \sum_{d \mid n} f(d) g(n/d)
\end{align*}
Note that $\varepsilon(n) = \begin{cases}
1 & \mbox{ if } n = 1 \\
0 & \mbox{ if } n > 1
\end{cases}$ is the multiplicative identity with respect to the convolution.
\end{theorem}

\chapter{Graph Theory}
\begin{theorem}[Kuratowski theorem]
A finite graph is planar if and only if it does not contain a subgraph that is a subdivision of $K_5$ or $K_{3, 3}$.
\end{theorem}
\begin{theorem}[Hall marriage theorem]
Let $G$ be a finite bipartite graph with bipartite sets $X$ and $Y$.
\begin{enumerate}
	\item An $X$-perfect matching (or saturated matching) is an injective map $f: X \to Y$ such that $x$ is adjacent to $f(x)$.
	\item For every subset $W$ of $X$, denote $N_G(W)$ to be the neighborhood of $W$ in $G$ (i.e. set of all vertices in $Y$ adjacent to some vertex in $W$).
\end{enumerate}
Then $G$ has an $X$-perfect matching if $|W| \leq |N_G(W)|$ for every subset $W$ of $X$.
\end{theorem}
\begin{theorem}[TurÃ¡n theorem]
\end{theorem}
\begin{theorem}[Tutte-Berge formula]
\end{theorem}
\begin{theorem}[Ramsey theorem]
\end{theorem}

\chapter{Combinatorics}
\begin{theorem}[Helly theorem]
\end{theorem}
\begin{theorem}[Pigeonhole principle]
If $f: A \to B$ is a function between 2 finite set $A, B$ such that $|A| = n > k = |B|$, then there exists some element $b$ of $B$ such that $f^{-1}(b)$ has at least $\lceil n/k \rceil$ elements.
\end{theorem}

\end{shaded}


\end{document}